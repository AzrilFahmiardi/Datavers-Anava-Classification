{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4cb422",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DATA_PATH = '/kaggle/input/ride-hailing-trip-classification-dataset/'\n",
    "    \n",
    "    N_FOLDS = 5\n",
    "    RANDOM_STATE = 42\n",
    "    TARGET_COL = 'Trip_Label'\n",
    "    ID_COL = 'Trip_ID'\n",
    "    \n",
    "    USE_TEMPORAL = True\n",
    "    USE_DISTANCE = True\n",
    "    USE_SENSOR_AGG = True\n",
    "    USE_ECONOMIC = True\n",
    "    USE_INTERACTION = True\n",
    "    \n",
    "    CATBOOST_PARAMS = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 6,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'eval_metric': 'TotalF1:average=Macro',\n",
    "        'auto_class_weights': 'Balanced',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 100,\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "    \n",
    "    LIGHTGBM_PARAMS = {\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    XGBOOST_PARAMS = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': 42,\n",
    "        'verbosity': 1\n",
    "    }\n",
    "\n",
    "config = Config()\n",
    "print(\"Configuration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134a05c",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37144dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"Loading data...\")\n",
    "    train = pd.read_csv(config.DATA_PATH + 'train.csv')\n",
    "    test = pd.read_csv(config.DATA_PATH + 'test.csv')\n",
    "    sample_submission = pd.read_csv(config.DATA_PATH + 'sample_submission.csv')\n",
    "    \n",
    "    print(f\"Train shape: {train.shape}\")\n",
    "    print(f\"Test shape: {test.shape}\")\n",
    "    print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "    \n",
    "    if config.TARGET_COL in train.columns:\n",
    "        print(f\"\\nTarget distribution:\")\n",
    "        print(train[config.TARGET_COL].value_counts())\n",
    "    \n",
    "    return train, test, sample_submission\n",
    "\n",
    "train, test, sample_submission = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    return df\n",
    "\n",
    "print(\"Optimizing memory...\")\n",
    "train = optimize_memory(train)\n",
    "test = optimize_memory(test)\n",
    "print(\"Memory optimization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7bf178",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb072add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    delta_lat = np.radians(lat2 - lat1)\n",
    "    delta_lon = np.radians(lon2 - lon1)\n",
    "    \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "def engineer_features(df, is_train=True):\n",
    "    print(f\"Engineering features for {'train' if is_train else 'test'} set...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    if config.USE_TEMPORAL and 'Timestamp' in df.columns:\n",
    "        print(\"  - Creating temporal features...\")\n",
    "        df['Timestamp_parsed'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Hour'] = df['Timestamp_parsed'].dt.hour.astype(np.int8)\n",
    "        df['DayOfWeek'] = df['Timestamp_parsed'].dt.dayofweek.astype(np.int8)\n",
    "        df['Month'] = df['Timestamp_parsed'].dt.month.astype(np.int8)\n",
    "        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(np.int8)\n",
    "        df['IsRushHour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9) | \n",
    "                            (df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(np.int8)\n",
    "        df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 5)).astype(np.int8)\n",
    "        df.drop('Timestamp_parsed', axis=1, inplace=True)\n",
    "    \n",
    "    if config.USE_DISTANCE:\n",
    "        print(\"  - Creating distance features...\")\n",
    "        if all(col in df.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n",
    "            df['Haversine_Distance'] = haversine_distance(\n",
    "                df['Pickup_Lat'], df['Pickup_Long'],\n",
    "                df['Dropoff_Lat'], df['Dropoff_Long']\n",
    "            )\n",
    "            \n",
    "            if 'Distance_KM' in df.columns:\n",
    "                df['Distance_Ratio'] = df['Distance_KM'] / (df['Haversine_Distance'] + 1e-6)\n",
    "                df['Distance_Difference'] = np.abs(df['Distance_KM'] - df['Haversine_Distance'])\n",
    "        \n",
    "        if 'Pickup_Zone' in df.columns and 'Dropoff_Zone' in df.columns:\n",
    "            df['Is_Same_Zone'] = (df['Pickup_Zone'] == df['Dropoff_Zone']).astype(np.int8)\n",
    "    \n",
    "    if config.USE_SENSOR_AGG:\n",
    "        print(\"  - Creating sensor aggregation features...\")\n",
    "        if all(col in df.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n",
    "            df['Accel_Magnitude'] = np.sqrt(df['Accel_X']**2 + df['Accel_Y']**2 + df['Accel_Z']**2)\n",
    "            df['Accel_Max'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].max(axis=1)\n",
    "            df['Accel_Min'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].min(axis=1)\n",
    "            df['Accel_Std'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].std(axis=1)\n",
    "            df['Accel_Range'] = df['Accel_Max'] - df['Accel_Min']\n",
    "        \n",
    "        if 'Gyro_Z' in df.columns:\n",
    "            df['Gyro_Abs'] = np.abs(df['Gyro_Z'])\n",
    "    \n",
    "    if config.USE_ECONOMIC:\n",
    "        print(\"  - Creating economic features...\")\n",
    "        if 'Est_Price_IDR' in df.columns and 'Distance_KM' in df.columns:\n",
    "            df['Price_per_KM'] = df['Est_Price_IDR'] / (df['Distance_KM'] + 1e-6)\n",
    "        \n",
    "        if 'Promo_Code' in df.columns:\n",
    "            df['Has_Promo'] = (df['Promo_Code'].notna()).astype(np.int8)\n",
    "        \n",
    "        if 'Surge_Multiplier' in df.columns:\n",
    "            df['Surge_Category'] = pd.cut(df['Surge_Multiplier'], \n",
    "                                          bins=[0, 1, 1.5, 2, 10], \n",
    "                                          labels=[0, 1, 2, 3]).astype(np.int8)\n",
    "    \n",
    "    if config.USE_INTERACTION:\n",
    "        print(\"  - Creating interaction features...\")\n",
    "        if 'Surge_Multiplier' in df.columns and 'Hour' in df.columns:\n",
    "            df['Surge_Hour_Interaction'] = df['Surge_Multiplier'] * df['Hour']\n",
    "        \n",
    "        if 'Distance_KM' in df.columns and 'Traffic' in df.columns:\n",
    "            traffic_map = {'Light': 1, 'Moderate': 2, 'Heavy': 3}\n",
    "            df['Traffic_Numeric'] = df['Traffic'].map(traffic_map).fillna(0).astype(np.int8)\n",
    "            df['Distance_Traffic'] = df['Distance_KM'] * df['Traffic_Numeric']\n",
    "    \n",
    "    print(f\"Feature engineering completed. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "train = engineer_features(train, is_train=True)\n",
    "test = engineer_features(test, is_train=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23f1e9",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445248f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, test):\n",
    "    print(\"Preprocessing data...\")\n",
    "    \n",
    "    cols_to_drop = [config.ID_COL, 'Timestamp']\n",
    "    if config.TARGET_COL in train.columns:\n",
    "        y = train[config.TARGET_COL].copy()\n",
    "        cols_to_drop.append(config.TARGET_COL)\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    cols_to_drop = [col for col in cols_to_drop if col in train.columns]\n",
    "    X_train = train.drop(cols_to_drop, axis=1)\n",
    "    X_test = test.drop([col for col in cols_to_drop if col in test.columns], axis=1)\n",
    "    \n",
    "    print(f\"\\nMissing values before imputation:\")\n",
    "    train_missing = X_train.isnull().sum()\n",
    "    if train_missing.sum() > 0:\n",
    "        print(train_missing[train_missing > 0])\n",
    "    else:\n",
    "        print(\"No missing values.\")\n",
    "    \n",
    "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        median_val = X_train[col].median()\n",
    "        X_train[col].fillna(median_val, inplace=True)\n",
    "        X_test[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        X_train[col].fillna('Unknown', inplace=True)\n",
    "        X_test[col].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        q99 = X_train[col].quantile(0.99)\n",
    "        q01 = X_train[col].quantile(0.01)\n",
    "        X_train[col] = X_train[col].clip(q01, q99)\n",
    "        X_test[col] = X_test[col].clip(q01, q99)\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "        X_test[col] = X_test[col].astype(str).apply(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "        )\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    if y is not None:\n",
    "        le_target = LabelEncoder()\n",
    "        y_encoded = le_target.fit_transform(y)\n",
    "        print(f\"\\nTarget encoding:\")\n",
    "        for i, label in enumerate(le_target.classes_):\n",
    "            print(f\"  {label}: {i}\")\n",
    "    else:\n",
    "        y_encoded = None\n",
    "        le_target = None\n",
    "    \n",
    "    print(f\"\\nPreprocessing completed.\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_encoded, le_target, label_encoders\n",
    "\n",
    "X_train, X_test, y_train, le_target, label_encoders = preprocess_data(train, test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd652a6",
   "metadata": {},
   "source": [
    "## 5. Model Training - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from catboost import CatBoostClassifier, Pool\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"CatBoost not available. Install with: pip install catboost\")\n",
    "    CATBOOST_AVAILABLE = False\n",
    "\n",
    "def train_catboost(X_train, y_train, X_test, n_folds=5):\n",
    "    if not CATBOOST_AVAILABLE:\n",
    "        return None, None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training CatBoost Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n",
    "    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n",
    "    \n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        print(f\"\\nFold {fold}/{n_folds}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        train_pool = Pool(X_tr, y_tr)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "        \n",
    "        model = CatBoostClassifier(**config.CATBOOST_PARAMS)\n",
    "        model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n",
    "        \n",
    "        oof_predictions[val_idx] = model.predict_proba(X_val)\n",
    "        test_predictions += model.predict_proba(X_test) / n_folds\n",
    "        \n",
    "        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n",
    "        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        print(f\"Fold {fold} Macro F1-Score: {fold_score:.6f}\")\n",
    "        \n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"CatBoost Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_predictions, models\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    catboost_test_pred, catboost_models = train_catboost(X_train, y_train, X_test, config.N_FOLDS)\n",
    "else:\n",
    "    catboost_test_pred, catboost_models = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ce325",
   "metadata": {},
   "source": [
    "## 6. Model Training - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"LightGBM not available. Install with: pip install lightgbm\")\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "\n",
    "def train_lightgbm(X_train, y_train, X_test, n_folds=5):\n",
    "    if not LIGHTGBM_AVAILABLE:\n",
    "        return None, None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training LightGBM Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n",
    "    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n",
    "    \n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    \n",
    "    params = config.LIGHTGBM_PARAMS.copy()\n",
    "    params['num_class'] = len(np.unique(y_train))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        print(f\"\\nFold {fold}/{n_folds}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            valid_names=['train', 'valid'],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    "        )\n",
    "        \n",
    "        oof_predictions[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        test_predictions += model.predict(X_test, num_iteration=model.best_iteration) / n_folds\n",
    "        \n",
    "        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n",
    "        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        print(f\"Fold {fold} Macro F1-Score: {fold_score:.6f}\")\n",
    "        \n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"LightGBM Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_predictions, models\n",
    "\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    lightgbm_test_pred, lightgbm_models = train_lightgbm(X_train, y_train, X_test, config.N_FOLDS)\n",
    "else:\n",
    "    lightgbm_test_pred, lightgbm_models = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80430d8d",
   "metadata": {},
   "source": [
    "## 7. Model Training - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_test, n_folds=5):\n",
    "    if not XGBOOST_AVAILABLE:\n",
    "        return None, None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training XGBoost Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n",
    "    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n",
    "    \n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    \n",
    "    params = config.XGBOOST_PARAMS.copy()\n",
    "    params['num_class'] = len(np.unique(y_train))\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "        print(f\"\\nFold {fold}/{n_folds}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "        \n",
    "        oof_predictions[val_idx] = model.predict(dval)\n",
    "        test_predictions += model.predict(dtest) / n_folds\n",
    "        \n",
    "        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n",
    "        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        print(f\"Fold {fold} Macro F1-Score: {fold_score:.6f}\")\n",
    "        \n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"XGBoost Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_predictions, models\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    xgboost_test_pred, xgboost_models = train_xgboost(X_train, y_train, X_test, config.N_FOLDS)\n",
    "else:\n",
    "    xgboost_test_pred, xgboost_models = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abb317",
   "metadata": {},
   "source": [
    "## 8. Ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a333a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(predictions_list, weights=None):\n",
    "    predictions_list = [p for p in predictions_list if p is not None]\n",
    "    \n",
    "    if len(predictions_list) == 0:\n",
    "        raise ValueError(\"No valid predictions available for ensemble\")\n",
    "    \n",
    "    if len(predictions_list) == 1:\n",
    "        return predictions_list[0]\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(predictions_list)] * len(predictions_list)\n",
    "    \n",
    "    ensemble_pred = np.zeros_like(predictions_list[0])\n",
    "    for pred, weight in zip(predictions_list, weights):\n",
    "        ensemble_pred += pred * weight\n",
    "    \n",
    "    return ensemble_pred\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Creating Ensemble Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "available_predictions = []\n",
    "model_names = []\n",
    "\n",
    "if catboost_test_pred is not None:\n",
    "    available_predictions.append(catboost_test_pred)\n",
    "    model_names.append(\"CatBoost\")\n",
    "\n",
    "if lightgbm_test_pred is not None:\n",
    "    available_predictions.append(lightgbm_test_pred)\n",
    "    model_names.append(\"LightGBM\")\n",
    "\n",
    "if xgboost_test_pred is not None:\n",
    "    available_predictions.append(xgboost_test_pred)\n",
    "    model_names.append(\"XGBoost\")\n",
    "\n",
    "print(f\"Ensembling {len(available_predictions)} models: {', '.join(model_names)}\")\n",
    "\n",
    "if len(available_predictions) > 1:\n",
    "    final_predictions = ensemble_predictions(available_predictions)\n",
    "    print(\"Using equal weights for ensemble\")\n",
    "else:\n",
    "    final_predictions = available_predictions[0]\n",
    "    print(f\"Using single model: {model_names[0]}\")\n",
    "\n",
    "final_pred_labels = np.argmax(final_predictions, axis=1)\n",
    "print(f\"\\nFinal predictions shape: {final_predictions.shape}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebc841",
   "metadata": {},
   "source": [
    "## 9. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd660f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n",
    "    pred_labels = le_target.inverse_transform(predictions)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        config.ID_COL: test_ids,\n",
    "        config.TARGET_COL: pred_labels\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission saved to: {filename}\")\n",
    "    print(f\"Submission shape: {submission.shape}\")\n",
    "    print(f\"\\nPrediction distribution:\")\n",
    "    print(submission[config.TARGET_COL].value_counts())\n",
    "    \n",
    "    return submission\n",
    "\n",
    "test_ids = test[config.ID_COL].values\n",
    "submission = create_submission(test_ids, final_pred_labels, le_target, 'submission.csv')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c9f05",
   "metadata": {},
   "source": [
    "## 10. Validation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final Validation Checks\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "assert submission.shape[0] == test.shape[0], \"Submission size mismatch!\"\n",
    "assert submission.columns.tolist() == [config.ID_COL, config.TARGET_COL], \"Column names mismatch!\"\n",
    "assert submission[config.TARGET_COL].isnull().sum() == 0, \"Null predictions found!\"\n",
    "\n",
    "expected_labels = set(le_target.classes_)\n",
    "submission_labels = set(submission[config.TARGET_COL].unique())\n",
    "assert submission_labels.issubset(expected_labels), \"Invalid labels in submission!\"\n",
    "\n",
    "print(\"All validation checks passed!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "if catboost_models and len(catboost_models) > 0:\n",
    "    print(\"\\nTop 20 Important Features (CatBoost):\")\n",
    "    feature_importance = catboost_models[0].get_feature_importance()\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(importance_df.head(20).to_string(index=False))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Feature Importances', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085cc1ae",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Training samples: {len(train):,}\")\n",
    "print(f\"  Test samples: {len(test):,}\")\n",
    "print(f\"  Features after engineering: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nModels Trained:\")\n",
    "if CATBOOST_AVAILABLE:\n",
    "    print(f\"  - CatBoost: {config.N_FOLDS} folds\")\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    print(f\"  - LightGBM: {config.N_FOLDS} folds\")\n",
    "if XGBOOST_AVAILABLE:\n",
    "    print(f\"  - XGBoost: {config.N_FOLDS} folds\")\n",
    "\n",
    "print(f\"\\nSubmission:\")\n",
    "print(f\"  File: submission.csv\")\n",
    "print(f\"  Predictions: {len(submission):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Pipeline completed successfully!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
