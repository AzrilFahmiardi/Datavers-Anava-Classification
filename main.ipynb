{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14452162,"sourceType":"datasetVersion","datasetId":9230974}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"2b4cb422","cell_type":"markdown","source":"## 1. Configuration & Setup","metadata":{}},{"id":"0ba4bde3","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom datetime import datetime\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nimport gc\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\n\nprint(\"Libraries imported successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"41cd27c8","cell_type":"code","source":"class Config:\n    DATA_PATH = '/kaggle/input/ride-hailing-trip-classification-dataset/'\n    \n    N_FOLDS = 5\n    RANDOM_STATE = 42\n    TARGET_COL = 'Trip_Label'\n    ID_COL = 'Trip_ID'\n    \n    USE_TEMPORAL = False\n    USE_DISTANCE = True\n    USE_SENSOR_AGG = True\n    USE_ECONOMIC = False\n    USE_INTERACTION = True\n    \n    CATBOOST_PARAMS = {\n        'iterations': 1000,\n        'learning_rate': 0.05,\n        'depth': 6,\n        'loss_function': 'MultiClass',\n        'eval_metric': 'TotalF1:average=Macro',\n        'auto_class_weights': 'Balanced',\n        'random_seed': 42,\n        'verbose': 100,\n        'early_stopping_rounds': 50\n    }\n    \n    LIGHTGBM_PARAMS = {\n        'objective': 'multiclass',\n        'metric': 'multi_logloss',\n        'boosting_type': 'gbdt',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'feature_fraction': 0.8,\n        'bagging_fraction': 0.8,\n        'bagging_freq': 5,\n        'random_state': 42,\n        'verbose': -1\n    }\n    \n    XGBOOST_PARAMS = {\n        'objective': 'multi:softprob',\n        'eval_metric': 'mlogloss',\n        'max_depth': 6,\n        'learning_rate': 0.05,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': 42,\n        'verbosity': 1\n    }\n\nconfig = Config()\nprint(\"Configuration loaded successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T13:08:32.516719Z","iopub.execute_input":"2026-01-10T13:08:32.517061Z","iopub.status.idle":"2026-01-10T13:08:32.525317Z","shell.execute_reply.started":"2026-01-10T13:08:32.517037Z","shell.execute_reply":"2026-01-10T13:08:32.524034Z"}},"outputs":[{"name":"stdout","text":"Configuration loaded successfully.\n","output_type":"stream"}],"execution_count":8},{"id":"3134a05c","cell_type":"markdown","source":"## 2. Data Loading & Validation","metadata":{}},{"id":"37144dad","cell_type":"code","source":"def load_data():\n    print(\"Loading data...\")\n    files = ['train.csv', 'test.csv', 'sample_submission.csv']\n    data = {}\n    \n    for file in tqdm(files, desc=\"Loading files\"):\n        data[file.replace('.csv', '')] = pd.read_csv(config.DATA_PATH + file)\n    \n    train = data['train']\n    test = data['test']\n    sample_submission = data['sample_submission']\n    \n    print(f\"Train shape: {train.shape}\")\n    print(f\"Test shape: {test.shape}\")\n    print(f\"Sample submission shape: {sample_submission.shape}\")\n    \n    if config.TARGET_COL in train.columns:\n        print(f\"\\nTarget distribution:\")\n        print(train[config.TARGET_COL].value_counts())\n    \n    return train, test, sample_submission\n\ntrain, test, sample_submission = load_data()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"74d1d42f","cell_type":"code","source":"def optimize_memory(df):\n    print(f\"Optimizing memory for dataframe with {len(df.columns)} columns...\")\n    for col in tqdm(df.columns, desc=\"Optimizing columns\"):\n        col_type = df[col].dtype\n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n    return df\n\nprint(\"Optimizing memory...\")\ntrain = optimize_memory(train)\ntest = optimize_memory(test)\nprint(\"Memory optimization completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:41:09.903123Z","iopub.status.idle":"2026-01-10T14:41:09.903410Z","shell.execute_reply.started":"2026-01-10T14:41:09.903273Z","shell.execute_reply":"2026-01-10T14:41:09.903287Z"}},"outputs":[],"execution_count":null},{"id":"2b7bf178","cell_type":"markdown","source":"## 3. Feature Engineering","metadata":{}},{"id":"bb072add","cell_type":"code","source":"def haversine_distance(lat1, lon1, lat2, lon2):\n    R = 6371\n    lat1_rad = np.radians(lat1)\n    lat2_rad = np.radians(lat2)\n    delta_lat = np.radians(lat2 - lat1)\n    delta_lon = np.radians(lon2 - lon1)\n    \n    a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    \n    return R * c\n\ndef engineer_features(df, is_train=True):\n    print(f\"Engineering features for {'train' if is_train else 'test'} set...\")\n    df = df.copy()\n    \n    if config.USE_TEMPORAL and 'Timestamp' in df.columns:\n        print(\"  - Creating temporal features...\")\n        df['Timestamp_parsed'] = pd.to_datetime(df['Timestamp'])\n        df['Hour'] = df['Timestamp_parsed'].dt.hour.astype(np.int8)\n        df['DayOfWeek'] = df['Timestamp_parsed'].dt.dayofweek.astype(np.int8)\n        df['Month'] = df['Timestamp_parsed'].dt.month.astype(np.int8)\n        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(np.int8)\n        df['IsRushHour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9) | \n                            (df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(np.int8)\n        df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 5)).astype(np.int8)\n        df.drop('Timestamp_parsed', axis=1, inplace=True)\n    \n    if config.USE_DISTANCE:\n        print(\"  - Creating distance features...\")\n        if all(col in df.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n            df['Haversine_Distance'] = haversine_distance(\n                df['Pickup_Lat'], df['Pickup_Long'],\n                df['Dropoff_Lat'], df['Dropoff_Long']\n            )\n            \n            if 'Distance_KM' in df.columns:\n                df['Distance_Ratio'] = df['Distance_KM'] / (df['Haversine_Distance'] + 1e-6)\n                df['Distance_Difference'] = np.abs(df['Distance_KM'] - df['Haversine_Distance'])\n        \n        if 'Pickup_Zone' in df.columns and 'Dropoff_Zone' in df.columns:\n            df['Is_Same_Zone'] = (df['Pickup_Zone'] == df['Dropoff_Zone']).astype(np.int8)\n    \n    if config.USE_SENSOR_AGG:\n        print(\"  - Creating sensor aggregation features...\")\n        if all(col in df.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n            df['Accel_Magnitude'] = np.sqrt(df['Accel_X']**2 + df['Accel_Y']**2 + df['Accel_Z']**2)\n            df['Accel_Max'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].max(axis=1)\n            df['Accel_Min'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].min(axis=1)\n            df['Accel_Std'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].std(axis=1)\n            df['Accel_Range'] = df['Accel_Max'] - df['Accel_Min']\n        \n        if 'Gyro_Z' in df.columns:\n            df['Gyro_Abs'] = np.abs(df['Gyro_Z'])\n    \n    if config.USE_ECONOMIC:\n        print(\"  - Creating economic features...\")\n        if 'Est_Price_IDR' in df.columns and 'Distance_KM' in df.columns:\n            df['Price_per_KM'] = df['Est_Price_IDR'] / (df['Distance_KM'] + 1e-6)\n        \n        if 'Promo_Code' in df.columns:\n            df['Has_Promo'] = (df['Promo_Code'].notna()).astype(np.int8)\n        \n        if 'Surge_Multiplier' in df.columns:\n            df['Surge_Category'] = pd.cut(df['Surge_Multiplier'], \n                                          bins=[0, 1, 1.5, 2, 10], \n                                          labels=[0, 1, 2, 3]).astype(np.int8)\n    \n    if config.USE_INTERACTION:\n        print(\"  - Creating interaction features...\")\n        if 'Surge_Multiplier' in df.columns and 'Hour' in df.columns:\n            df['Surge_Hour_Interaction'] = df['Surge_Multiplier'] * df['Hour']\n        \n        if 'Distance_KM' in df.columns and 'Traffic' in df.columns:\n            traffic_map = {'Light': 1, 'Moderate': 2, 'Heavy': 3}\n            df['Traffic_Numeric'] = df['Traffic'].map(traffic_map).fillna(0).astype(np.int8)\n            df['Distance_Traffic'] = df['Distance_KM'] * df['Traffic_Numeric']\n    \n    print(f\"Feature engineering completed. Shape: {df.shape}\")\n    return df\n\ntrain = engineer_features(train, is_train=True)\ntest = engineer_features(test, is_train=False)\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T13:08:35.951700Z","iopub.execute_input":"2026-01-10T13:08:35.952074Z","iopub.status.idle":"2026-01-10T13:08:47.394882Z","shell.execute_reply.started":"2026-01-10T13:08:35.952049Z","shell.execute_reply":"2026-01-10T13:08:47.393919Z"}},"outputs":[{"name":"stdout","text":"Engineering features for train set...\n  - Creating distance features...\n  - Creating sensor aggregation features...\n  - Creating interaction features...\nFeature engineering completed. Shape: (8000000, 37)\nEngineering features for test set...\n  - Creating distance features...\n  - Creating sensor aggregation features...\n  - Creating interaction features...\nFeature engineering completed. Shape: (4000000, 36)\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"14"},"metadata":{}}],"execution_count":9},{"id":"2d23f1e9","cell_type":"markdown","source":"## 4. Preprocessing","metadata":{}},{"id":"445248f0","cell_type":"code","source":"def preprocess_data(train, test):\n    print(\"Preprocessing data...\")\n    \n    cols_to_drop = [config.ID_COL, 'Timestamp']\n    if config.TARGET_COL in train.columns:\n        y = train[config.TARGET_COL].copy()\n        cols_to_drop.append(config.TARGET_COL)\n    else:\n        y = None\n    \n    cols_to_drop = [col for col in cols_to_drop if col in train.columns]\n    X_train = train.drop(cols_to_drop, axis=1)\n    X_test = test.drop([col for col in cols_to_drop if col in test.columns], axis=1)\n    \n    print(f\"\\nMissing values before imputation:\")\n    train_missing = X_train.isnull().sum()\n    if train_missing.sum() > 0:\n        print(train_missing[train_missing > 0])\n    else:\n        print(\"No missing values.\")\n    \n    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n    \n    print(\"\\nImputing missing values...\")\n    for col in tqdm(numeric_cols, desc=\"Numeric imputation\"):\n        median_val = X_train[col].median()\n        X_train[col].fillna(median_val, inplace=True)\n        X_test[col].fillna(median_val, inplace=True)\n    \n    for col in tqdm(categorical_cols, desc=\"Categorical imputation\"):\n        X_train[col].fillna('Unknown', inplace=True)\n        X_test[col].fillna('Unknown', inplace=True)\n    \n    print(\"\\nClipping outliers...\")\n    for col in tqdm(numeric_cols, desc=\"Outlier clipping\"):\n        q99 = X_train[col].quantile(0.99)\n        q01 = X_train[col].quantile(0.01)\n        X_train[col] = X_train[col].clip(q01, q99)\n        X_test[col] = X_test[col].clip(q01, q99)\n    \n    print(\"\\nEncoding categorical variables...\")\n    label_encoders = {}\n    for col in tqdm(categorical_cols, desc=\"Label encoding\"):\n        le = LabelEncoder()\n        X_train[col] = le.fit_transform(X_train[col].astype(str))\n        X_test[col] = X_test[col].astype(str).apply(\n            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n        )\n        label_encoders[col] = le\n    \n    if y is not None:\n        print(\"\\nEncoding target variable...\")\n        le_target = LabelEncoder()\n        y_encoded = le_target.fit_transform(y)\n        print(f\"Target encoding:\")\n        for i, label in enumerate(le_target.classes_):\n            print(f\"  {label}: {i}\")\n    else:\n        y_encoded = None\n        le_target = None\n    \n    print(f\"\\nPreprocessing completed.\")\n    print(f\"X_train shape: {X_train.shape}\")\n    print(f\"X_test shape: {X_test.shape}\")\n    \n    return X_train, X_test, y_encoded, le_target, label_encoders\n\nX_train, X_test, y_train, le_target, label_encoders = preprocess_data(train, test)\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:41:09.905550Z","iopub.status.idle":"2026-01-10T14:41:09.906052Z","shell.execute_reply.started":"2026-01-10T14:41:09.905832Z","shell.execute_reply":"2026-01-10T14:41:09.905853Z"}},"outputs":[],"execution_count":null},{"id":"edd652a6","cell_type":"markdown","source":"## 5. Model Training - CatBoost","metadata":{}},{"id":"33b7052f","cell_type":"code","source":"try:\n    from catboost import CatBoostClassifier, Pool\n    CATBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"CatBoost not available. Install with: pip install catboost\")\n    CATBOOST_AVAILABLE = False\n\ndef train_catboost(X_train, y_train, X_test, n_folds=5):\n    if not CATBOOST_AVAILABLE:\n        return None, None\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"Training CatBoost Models\")\n    print(\"=\"*80)\n    \n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n    \n    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n    \n    fold_scores = []\n    models = []\n    \n    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"CatBoost Folds\")\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"CatBoost Fold {fold}/{n_folds}\")\n        \n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n        \n        train_pool = Pool(X_tr, y_tr)\n        val_pool = Pool(X_val, y_val)\n        \n        model = CatBoostClassifier(**config.CATBOOST_PARAMS)\n        model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n        \n        oof_predictions[val_idx] = model.predict_proba(X_val)\n        test_predictions += model.predict_proba(X_test) / n_folds\n        \n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n        \n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n        \n        models.append(model)\n        gc.collect()\n    \n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n    \n    print(\"\\n\" + \"=\"*80)\n    print(f\"CatBoost Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n    print(\"=\"*80)\n    \n    return test_predictions, models\n\nif CATBOOST_AVAILABLE:\n    catboost_test_pred, catboost_models = train_catboost(X_train, y_train, X_test, config.N_FOLDS)\nelse:\n    catboost_test_pred, catboost_models = None, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:39:08.701423Z","iopub.status.idle":"2026-01-10T14:39:08.701871Z","shell.execute_reply.started":"2026-01-10T14:39:08.701683Z","shell.execute_reply":"2026-01-10T14:39:08.701702Z"}},"outputs":[],"execution_count":null},{"id":"3d7ce325","cell_type":"markdown","source":"## 6. Model Training - LightGBM","metadata":{}},{"id":"f3f4c0a9","cell_type":"code","source":"try:\n    import lightgbm as lgb\n    LIGHTGBM_AVAILABLE = True\nexcept ImportError:\n    print(\"LightGBM not available. Install with: pip install lightgbm\")\n    LIGHTGBM_AVAILABLE = False\n\ndef train_lightgbm(X_train, y_train, X_test, n_folds=5):\n    if not LIGHTGBM_AVAILABLE:\n        return None, None\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"Training LightGBM Models\")\n    print(\"=\"*80)\n    \n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n    \n    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n    \n    fold_scores = []\n    models = []\n    \n    params = config.LIGHTGBM_PARAMS.copy()\n    params['num_class'] = len(np.unique(y_train))\n    \n    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"LightGBM Folds\")\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"LightGBM Fold {fold}/{n_folds}\")\n        \n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n        \n        train_data = lgb.Dataset(X_tr, label=y_tr)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n        \n        model = lgb.train(\n            params,\n            train_data,\n            num_boost_round=1000,\n            valid_sets=[train_data, val_data],\n            valid_names=['train', 'valid'],\n            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n        )\n        \n        oof_predictions[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n        test_predictions += model.predict(X_test, num_iteration=model.best_iteration) / n_folds\n        \n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n        \n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n        \n        models.append(model)\n        gc.collect()\n    \n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n    \n    print(\"\\n\" + \"=\"*80)\n    print(f\"LightGBM Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n    print(\"=\"*80)\n    \n    return test_predictions, models\n\nif LIGHTGBM_AVAILABLE:\n    lightgbm_test_pred, lightgbm_models = train_lightgbm(X_train, y_train, X_test, config.N_FOLDS)\nelse:\n    lightgbm_test_pred, lightgbm_models = None, None","metadata":{},"outputs":[],"execution_count":null},{"id":"80430d8d","cell_type":"markdown","source":"## 7. Model Training - XGBoost","metadata":{}},{"id":"6340dc9b","cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\ndef train_xgboost(X_train, y_train, X_test, n_folds=5):\n    if not XGBOOST_AVAILABLE:\n        return None, None\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"Training XGBoost Models\")\n    print(\"=\"*80)\n    \n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n    \n    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n    \n    fold_scores = []\n    models = []\n    \n    params = config.XGBOOST_PARAMS.copy()\n    params['num_class'] = len(np.unique(y_train))\n    \n    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"XGBoost Folds\")\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n        \n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n        \n        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n        dval = xgb.DMatrix(X_val, label=y_val)\n        dtest = xgb.DMatrix(X_test)\n        \n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            evals=[(dtrain, 'train'), (dval, 'valid')],\n            early_stopping_rounds=50,\n            verbose_eval=100\n        )\n        \n        oof_predictions[val_idx] = model.predict(dval)\n        test_predictions += model.predict(dtest) / n_folds\n        \n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n        \n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n        \n        models.append(model)\n        gc.collect()\n    \n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n    \n    print(\"\\n\" + \"=\"*80)\n    print(f\"XGBoost Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n    print(\"=\"*80)\n    \n    return test_predictions, models\n\nif XGBOOST_AVAILABLE:\n    xgboost_test_pred, xgboost_models = train_xgboost(X_train, y_train, X_test, config.N_FOLDS)\nelse:\n    xgboost_test_pred, xgboost_models = None, None","metadata":{},"outputs":[],"execution_count":null},{"id":"69abb317","cell_type":"markdown","source":"## 8. Ensemble Predictions","metadata":{}},{"id":"a8a333a8","cell_type":"code","source":"def ensemble_predictions(predictions_list, weights=None):\n    predictions_list = [p for p in predictions_list if p is not None]\n    \n    if len(predictions_list) == 0:\n        raise ValueError(\"No valid predictions available for ensemble\")\n    \n    if len(predictions_list) == 1:\n        return predictions_list[0]\n    \n    if weights is None:\n        weights = [1.0 / len(predictions_list)] * len(predictions_list)\n    \n    ensemble_pred = np.zeros_like(predictions_list[0])\n    for pred, weight in zip(predictions_list, weights):\n        ensemble_pred += pred * weight\n    \n    return ensemble_pred\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Creating Ensemble Predictions\")\nprint(\"=\"*80)\n\navailable_predictions = []\nmodel_names = []\n\nif catboost_test_pred is not None:\n    available_predictions.append(catboost_test_pred)\n    model_names.append(\"CatBoost\")\n\nif lightgbm_test_pred is not None:\n    available_predictions.append(lightgbm_test_pred)\n    model_names.append(\"LightGBM\")\n\nif xgboost_test_pred is not None:\n    available_predictions.append(xgboost_test_pred)\n    model_names.append(\"XGBoost\")\n\nprint(f\"Ensembling {len(available_predictions)} models: {', '.join(model_names)}\")\n\nif len(available_predictions) > 1:\n    final_predictions = ensemble_predictions(available_predictions)\n    print(\"Using equal weights for ensemble\")\nelse:\n    final_predictions = available_predictions[0]\n    print(f\"Using single model: {model_names[0]}\")\n\nfinal_pred_labels = np.argmax(final_predictions, axis=1)\nprint(f\"\\nFinal predictions shape: {final_predictions.shape}\")\nprint(\"=\"*80)","metadata":{},"outputs":[],"execution_count":null},{"id":"f5ebc841","cell_type":"markdown","source":"## 9. Generate Submission","metadata":{}},{"id":"ebd660f5","cell_type":"code","source":"def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n    pred_labels = le_target.inverse_transform(predictions)\n    \n    submission = pd.DataFrame({\n        config.ID_COL: test_ids,\n        config.TARGET_COL: pred_labels\n    })\n    \n    submission.to_csv(filename, index=False)\n    \n    print(f\"\\nSubmission saved to: {filename}\")\n    print(f\"Submission shape: {submission.shape}\")\n    print(f\"\\nPrediction distribution:\")\n    print(submission[config.TARGET_COL].value_counts())\n    \n    return submission\n\ntest_ids = test[config.ID_COL].values\nsubmission = create_submission(test_ids, final_pred_labels, le_target, 'submission.csv')\nsubmission.head(10)","metadata":{},"outputs":[],"execution_count":null},{"id":"e64c9f05","cell_type":"markdown","source":"## 10. Validation & Analysis","metadata":{}},{"id":"18f7d50d","cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"Final Validation Checks\")\nprint(\"=\"*80)\n\nassert submission.shape[0] == test.shape[0], \"Submission size mismatch!\"\nassert submission.columns.tolist() == [config.ID_COL, config.TARGET_COL], \"Column names mismatch!\"\nassert submission[config.TARGET_COL].isnull().sum() == 0, \"Null predictions found!\"\n\nexpected_labels = set(le_target.classes_)\nsubmission_labels = set(submission[config.TARGET_COL].unique())\nassert submission_labels.issubset(expected_labels), \"Invalid labels in submission!\"\n\nprint(\"All validation checks passed!\")\nprint(\"=\"*80)","metadata":{},"outputs":[],"execution_count":null},{"id":"a0bc8087","cell_type":"code","source":"if catboost_models and len(catboost_models) > 0:\n    print(\"\\nTop 20 Important Features (CatBoost):\")\n    feature_importance = catboost_models[0].get_feature_importance()\n    feature_names = X_train.columns\n    \n    importance_df = pd.DataFrame({\n        'Feature': feature_names,\n        'Importance': feature_importance\n    }).sort_values('Importance', ascending=False)\n    \n    print(importance_df.head(20).to_string(index=False))\n    \n    plt.figure(figsize=(10, 8))\n    top_features = importance_df.head(20)\n    plt.barh(range(len(top_features)), top_features['Importance'])\n    plt.yticks(range(len(top_features)), top_features['Feature'])\n    plt.xlabel('Importance')\n    plt.title('Top 20 Feature Importances', fontweight='bold')\n    plt.gca().invert_yaxis()\n    plt.tight_layout()\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"id":"085cc1ae","cell_type":"markdown","source":"## 11. Summary","metadata":{}},{"id":"8f91cdd2","cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"PIPELINE EXECUTION SUMMARY\")\nprint(\"=\"*80)\nprint(f\"\\nData:\")\nprint(f\"  Training samples: {len(train):,}\")\nprint(f\"  Test samples: {len(test):,}\")\nprint(f\"  Features after engineering: {X_train.shape[1]}\")\n\nprint(f\"\\nModels Trained:\")\nif CATBOOST_AVAILABLE:\n    print(f\"  - CatBoost: {config.N_FOLDS} folds\")\nif LIGHTGBM_AVAILABLE:\n    print(f\"  - LightGBM: {config.N_FOLDS} folds\")\nif XGBOOST_AVAILABLE:\n    print(f\"  - XGBoost: {config.N_FOLDS} folds\")\n\nprint(f\"\\nSubmission:\")\nprint(f\"  File: submission.csv\")\nprint(f\"  Predictions: {len(submission):,}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"Pipeline completed successfully!\")\nprint(\"=\"*80)","metadata":{},"outputs":[],"execution_count":null}]}