{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14449944,"sourceType":"datasetVersion","datasetId":9229803},{"sourceId":14467043,"sourceType":"datasetVersion","datasetId":9240592}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nimport gc\nfrom tqdm.auto import tqdm\nimport os\nimport optuna\ntqdm.pandas()\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\n\nprint(\"Libraries imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:33:15.036560Z","iopub.execute_input":"2026-01-14T09:33:15.037238Z","iopub.status.idle":"2026-01-14T09:33:17.941623Z","shell.execute_reply.started":"2026-01-14T09:33:15.037207Z","shell.execute_reply":"2026-01-14T09:33:17.940897Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n  if entities is not ():\n","output_type":"stream"},{"name":"stdout","text":"Libraries imported successfully.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"USE_GPU = True  \n\ngpu_config = {\n    'xgboost_gpu': USE_GPU,\n    'lightgbm_gpu': USE_GPU,\n    'catboost_gpu': USE_GPU\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:33:17.942856Z","iopub.execute_input":"2026-01-14T09:33:17.943305Z","iopub.status.idle":"2026-01-14T09:33:17.947683Z","shell.execute_reply.started":"2026-01-14T09:33:17.943282Z","shell.execute_reply":"2026-01-14T09:33:17.947000Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Config:\n    DATA_PATH = '/kaggle/input/anava-dataset'\n    \n    N_FOLDS = 5\n    RANDOM_STATE = 42\n    TARGET_COL = 'Trip_Label'\n    ID_COL = 'Trip_ID'\n    \n    USE_TEMPORAL = False\n    USE_DISTANCE = False\n    USE_SENSOR_AGG = False\n    USE_ECONOMIC = False\n    USE_INTERACTION = False\n    \n    @staticmethod\n    def get_catboost_params(use_gpu=False):\n        params = {\n            'iterations': 1000,\n            'learning_rate': 0.05,\n            'depth': 6,\n            'loss_function': 'MultiClass',\n            'eval_metric': 'TotalF1:average=Macro',\n            'auto_class_weights': 'Balanced',\n            'random_seed': 42,\n            'verbose': 100,\n            'early_stopping_rounds': 50\n        }\n        if use_gpu:\n            params['task_type'] = 'GPU'\n            params['devices'] = '0'\n            print(\"  CatBoost: GPU mode activated\")\n        else:\n            params['task_type'] = 'CPU'\n            print(\"  CatBoost: CPU mode\")\n        return params\n    \n    @staticmethod\n    def get_lightgbm_params(use_gpu=False):\n        params = {\n            'objective': 'multiclass',\n            'metric': 'multi_logloss',\n            'boosting_type': 'gbdt',\n            'num_leaves': 31,\n            'learning_rate': 0.05,\n            'random_state': 42,\n            'verbose': 1,\n            'min_data_in_leaf': 200,\n            'min_sum_hessian_in_leaf': 1e-2,\n            'gpu_platform_id': 0,\n            'gpu_device_id': 0,\n            'max_bin': 255,\n            'force_col_wise': True\n        }\n        if use_gpu:\n            params['device'] = 'gpu'\n            print(\"  LightGBM: GPU mode activated\")\n        else:\n            params['device'] = 'cpu'\n            print(\"  LightGBM: CPU mode\")\n        return params\n    \n    @staticmethod\n    def get_xgboost_params(use_gpu=False):\n        params = {\n            'objective': 'multi:softprob',\n            'eval_metric': 'mlogloss',\n            'max_depth': 6,\n            'learning_rate': 0.05,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'random_state': 42,\n            'verbosity': 1\n        }\n        if use_gpu:\n            params['device'] = 'cuda'\n            print(\"  XGBoost: GPU mode activated\")\n        else:\n            params['device'] = 'cpu'\n            print(\"  XGBoost: CPU mode\")\n        return params\n\nconfig = Config()\nprint(\"\\nConfiguration loaded successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:33:18.726330Z","iopub.execute_input":"2026-01-14T09:33:18.726618Z","iopub.status.idle":"2026-01-14T09:33:18.735566Z","shell.execute_reply.started":"2026-01-14T09:33:18.726594Z","shell.execute_reply":"2026-01-14T09:33:18.734856Z"}},"outputs":[{"name":"stdout","text":"\nConfiguration loaded successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def load_data():\n    print(\"Loading data...\")\n\n    files = ['train.csv', 'test.csv', 'sample_submission.csv']\n    data = {}\n\n    for file in tqdm(files, desc=\"Loading files\"):\n        file_path = os.path.join(config.DATA_PATH, file)\n        data[file.replace('.csv', '')] = pd.read_csv(file_path)\n\n    train = data['train']\n    test = data['test']\n    sample_submission = data['sample_submission']\n\n    print(f\"Train shape: {train.shape}\")\n    print(f\"Test shape: {test.shape}\")\n    print(f\"Sample submission shape: {sample_submission.shape}\")\n\n    if config.TARGET_COL in train.columns:\n        print(\"\\nTarget distribution:\")\n        print(train[config.TARGET_COL].value_counts())\n\n    return train, test, sample_submission\n\ntrain, test, sample_submission = load_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:33:21.128474Z","iopub.execute_input":"2026-01-14T09:33:21.129174Z","iopub.status.idle":"2026-01-14T09:34:46.390953Z","shell.execute_reply.started":"2026-01-14T09:33:21.129121Z","shell.execute_reply":"2026-01-14T09:34:46.390344Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13dfe2399de6438e88d14664c439640a"}},"metadata":{}},{"name":"stdout","text":"Train shape: (8000000, 25)\nTest shape: (4000000, 24)\nSample submission shape: (4000000, 2)\n\nTarget distribution:\nTrip_Label\nPerfect_Trip         4397607\nSafety_Violation     1601595\nNavigation_Issue      801790\nService_Complaint     798695\nFraud_Indication      400313\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def optimize_memory(df):\n    print(f\"Optimizing memory for dataframe with {len(df.columns)} columns...\")\n    for col in tqdm(df.columns, desc=\"Optimizing columns\"):\n        col_type = df[col].dtype\n        if col_type != 'object':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n    return df\n\nprint(\"Optimizing memory...\")\ntrain = optimize_memory(train)\ntest = optimize_memory(test)\nprint(\"Memory optimization completed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:34:46.392266Z","iopub.execute_input":"2026-01-14T09:34:46.392522Z","iopub.status.idle":"2026-01-14T09:34:46.951795Z","shell.execute_reply.started":"2026-01-14T09:34:46.392500Z","shell.execute_reply":"2026-01-14T09:34:46.950916Z"}},"outputs":[{"name":"stdout","text":"Optimizing memory...\nOptimizing memory for dataframe with 25 columns...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Optimizing columns:   0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea8c52db3b8d45239c0aee667e1de9a5"}},"metadata":{}},{"name":"stdout","text":"Optimizing memory for dataframe with 24 columns...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Optimizing columns:   0%|          | 0/24 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cda5b8d92364884821a5fa779380470"}},"metadata":{}},{"name":"stdout","text":"Memory optimization completed.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# def haversine_distance(lat1, lon1, lat2, lon2):\n#     R = 6371\n#     lat1_rad = np.radians(lat1)\n#     lat2_rad = np.radians(lat2)\n#     delta_lat = np.radians(lat2 - lat1)\n#     delta_lon = np.radians(lon2 - lon1)\n    \n#     a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n#     c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    \n#     return R * c\n\n# def bearing(lat1, lon1, lat2, lon2):\n#     lat1, lat2 = np.radians(lat1), np.radians(lat2)\n#     diff = np.radians(lon2 - lon1)\n#     x = np.sin(diff) * np.cos(lat2)\n#     y = np.cos(lat1)*np.sin(lat2) - np.sin(lat1)*np.cos(lat2)*np.cos(diff)\n#     return np.degrees(np.arctan2(x, y))\n\n# def geo_bin(lat, lon, precision=2):\n#     return lat.round(precision).astype(str) + '_' + lon.round(precision).astype(str)\n    \n# def engineer_features(df, is_train=True):\n#     print(f\"Engineering features for {'train' if is_train else 'test'} set...\")\n#     df = df.copy()\n    \n#     if config.USE_TEMPORAL and 'Timestamp' in df.columns:\n#         print(\"  - Creating temporal features...\")\n#         df['Timestamp_parsed'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n#         df['Hour'] = df['Timestamp_parsed'].dt.hour\n#         df['DayOfWeek'] = df['Timestamp_parsed'].dt.dayofweek\n#         df['Month'] = df['Timestamp_parsed'].dt.month\n#         df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(float)\n#         df['IsRushHour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9) | \n#                             (df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(float)\n#         df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 5)).astype(float)\n#         df.drop('Timestamp_parsed', axis=1, inplace=True)\n    \n#     if config.USE_DISTANCE:\n#         print(\"  - Creating distance features...\")\n#         if all(col in df.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n#             df['Haversine_Distance'] = haversine_distance(\n#                 df['Pickup_Lat'], df['Pickup_Long'],\n#                 df['Dropoff_Lat'], df['Dropoff_Long']\n#             )\n#             df['Delta_Lat'] = df['Dropoff_Lat'] - df['Pickup_Lat']\n#             df['Bearing'] = bearing(df.Pickup_Lat, df.Pickup_Long, df.Dropoff_Lat, df.Dropoff_Long)\n#             df['pickup_grid'] = geo_bin(df['Pickup_Lat'], df['Pickup_Long'])\n            \n#             if 'Distance_KM' in df.columns:\n#                 df['Distance_Ratio'] = df['Distance_KM'] / (df['Haversine_Distance'] + 1e-6)\n#                 df['Distance_Difference'] = np.abs(df['Distance_KM'] - df['Haversine_Distance'])\n#                 df['Is_Ultra_Short_Distance'] = (df['Distance_KM'] < 0.024).astype(int)\n        \n#         if 'Pickup_Zone' in df.columns and 'Dropoff_Zone' in df.columns:\n#             df['Is_Same_Zone'] = (df['Pickup_Zone'] == df['Dropoff_Zone']).astype(np.int8)\n            \n#             pickup_freq = df['Pickup_Zone'].value_counts()\n#             dropoff_freq = df['Dropoff_Zone'].value_counts()\n            \n#             df['pickup_zone_count'] = df['Pickup_Zone'].map(pickup_freq).fillna(0)\n#             df['dropoff_zone_count'] = df['Dropoff_Zone'].map(dropoff_freq).fillna(0)\n            \n#     if config.USE_SENSOR_AGG:\n#         print(\"  - Creating sensor aggregation features...\")\n#         if all(col in df.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n#             df['Accel_Magnitude'] = np.sqrt(df['Accel_X']**2 + df['Accel_Y']**2 + df['Accel_Z']**2)\n#             df['Accel_Max'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].max(axis=1)\n#             df['Accel_Min'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].min(axis=1)\n#             df['Accel_Std'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].std(axis=1)\n#             df['Accel_Range'] = df['Accel_Max'] - df['Accel_Min']\n#             df['Is_Accel_Magnitude_Outlier'] = (df['Accel_Magnitude'].abs() >= 10.80)\n        \n#         if 'Gyro_Z' in df.columns:\n#             df['Gyro_Abs'] = np.abs(df['Gyro_Z'])\n#             df['Is_Gyro_Z_Outlier'] = (df['Gyro_Z'].abs() >= 0.672).astype(int)\n    \n#     if config.USE_ECONOMIC:\n#         print(\"  - Creating economic features...\")\n#         if 'Est_Price_IDR' in df.columns and 'Distance_KM' in df.columns:\n#             df['Price_per_KM'] = df['Est_Price_IDR'] / (df['Distance_KM'] + 1e-6)\n\n#         def encode_promo(x):\n#             if pd.isna(x):\n#                 return 0      # MISSING\n#             if x == 'NO VOUCHER':\n#                 return 1      # NO_VOUCHER\n#             return 2          # HAS_VOUCHER\n    \n#         if 'Promo_Code' in df.columns:\n#             df['Promo_Code_enc'] = df['Promo_Code'].apply(encode_promo).astype(np.int8)\n#         if 'Surge_Multiplier' in df.columns:\n#             surge_filled = df['Surge_Multiplier'].fillna(1.0)\n    \n#             df['Surge_Category'] = pd.cut(\n#                 surge_filled,\n#                 bins=[0, 1, 1.5, 2, 10],\n#                 labels=[0, 1, 2, 3]\n#             ).astype(np.int8)\n    \n#     if config.USE_INTERACTION:\n#         print(\"  - Creating interaction features...\")\n#         if 'Surge_Multiplier' in df.columns and 'Hour' in df.columns:\n#             df['Surge_Hour_Interaction'] = df['Surge_Multiplier'] * df['Hour']\n        \n#         if 'Distance_KM' in df.columns and 'Traffic' in df.columns:\n#             traffic_map = {'Light': 1, 'Moderate': 2, 'Heavy': 3}\n#             df['Traffic_Numeric'] = df['Traffic'].map(traffic_map).fillna(0).astype(np.int8)\n#             df['Distance_Traffic'] = df['Distance_KM'] * df['Traffic_Numeric']\n    \n#     print(f\"Feature engineering completed. Shape: {df.shape}\")\n#     return df\n    \n# config.USE_TEMPORAL = True\n# config.USE_DISTANCE = True\n# config.USE_SENSOR_AGG = True\n# config.USE_ECONOMIC = True\n# config.USE_INTERACTION = True\n\n# train = engineer_features(train, is_train=True)\n# test = engineer_features(test, is_train=False)\n\n# gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:44:11.298562Z","iopub.execute_input":"2026-01-13T17:44:11.298863Z","iopub.status.idle":"2026-01-13T17:44:54.560318Z","shell.execute_reply.started":"2026-01-13T17:44:11.298839Z","shell.execute_reply":"2026-01-13T17:44:54.559716Z"}},"outputs":[{"name":"stdout","text":"Engineering features for train set...\n  - Creating temporal features...\n  - Creating distance features...\n  - Creating sensor aggregation features...\n  - Creating economic features...\n  - Creating interaction features...\nFeature engineering completed. Shape: (8000000, 55)\nEngineering features for test set...\n  - Creating temporal features...\n  - Creating distance features...\n  - Creating sensor aggregation features...\n  - Creating economic features...\n  - Creating interaction features...\nFeature engineering completed. Shape: (4000000, 54)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def haversine_distance(lat1, lon1, lat2, lon2):\n    R = 6371\n    lat1_rad = np.radians(lat1)\n    lat2_rad = np.radians(lat2)\n    delta_lat = np.radians(lat2 - lat1)\n    delta_lon = np.radians(lon2 - lon1)\n    a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    return R * c\n\ndef bearing(lat1, lon1, lat2, lon2):\n    lat1, lat2 = np.radians(lat1), np.radians(lat2)\n    diff = np.radians(lon2 - lon1)\n    x = np.sin(diff) * np.cos(lat2)\n    y = np.cos(lat1)*np.sin(lat2) - np.sin(lat1)*np.cos(lat2)*np.cos(diff)\n    return np.degrees(np.arctan2(x, y))\n\ndef geo_bin(lat, lon, precision=2):\n    return lat.round(precision).astype(str) + '_' + lon.round(precision).astype(str)\n\ndef engineer_features(df, is_train=True):\n    print(f\"Engineering features for {'train' if is_train else 'test'} set...\")\n    df = df.copy()\n\n    df['null_count'] = df.isnull().sum(axis=1)\n\n    if config.USE_TEMPORAL and 'Timestamp' in df.columns:\n        temporal_cols = ['Timestamp']\n        df['null_count_temporal'] = df[temporal_cols].isnull().sum(axis=1)\n\n        df['Timestamp_parsed'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n        df['Hour'] = df['Timestamp_parsed'].dt.hour\n        df['DayOfWeek'] = df['Timestamp_parsed'].dt.dayofweek\n        df['Month'] = df['Timestamp_parsed'].dt.month\n        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(float)\n        df['IsRushHour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9) | \n                            (df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(float)\n        df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 5)).astype(float)\n        df.drop('Timestamp_parsed', axis=1, inplace=True)\n\n    if config.USE_DISTANCE:\n        distance_cols = [c for c in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long', 'Distance_KM'] if c in df.columns]\n        if distance_cols:\n            df['null_count_distance'] = df[distance_cols].isnull().sum(axis=1)\n\n        if all(col in df.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n            df['Haversine_Distance'] = haversine_distance(\n                df['Pickup_Lat'], df['Pickup_Long'],\n                df['Dropoff_Lat'], df['Dropoff_Long']\n            )\n            df['Delta_Lat'] = df['Dropoff_Lat'] - df['Pickup_Lat']\n            df['Bearing'] = bearing(df.Pickup_Lat, df.Pickup_Long, df.Dropoff_Lat, df.Dropoff_Long)\n            df[\"bearing_sin\"] = np.sin(np.radians(df[\"Bearing\"])) \n            df[\"bearing_cos\"] = np.cos(np.radians(df[\"Bearing\"]))\n            df['pickup_grid'] = geo_bin(df['Pickup_Lat'], df['Pickup_Long'])\n\n            if 'Distance_KM' in df.columns:\n                df['Distance_Ratio'] = df['Distance_KM'] / (df['Haversine_Distance'] + 1e-6)\n                df['Distance_Difference'] = np.abs(df['Distance_KM'] - df['Haversine_Distance'])\n                df['Is_Ultra_Short_Distance'] = (df['Distance_KM'] < 0.024).astype(int)\n\n        if 'Pickup_Zone' in df.columns and 'Dropoff_Zone' in df.columns:\n            df['Is_Same_Zone'] = (df['Pickup_Zone'] == df['Dropoff_Zone']).astype(np.int8)\n            pickup_freq = df['Pickup_Zone'].value_counts()\n            dropoff_freq = df['Dropoff_Zone'].value_counts()\n            df['pickup_zone_count'] = df['Pickup_Zone'].map(pickup_freq).fillna(0)\n            df['dropoff_zone_count'] = df['Dropoff_Zone'].map(dropoff_freq).fillna(0)\n\n    if config.USE_SENSOR_AGG:\n        sensor_cols = [c for c in ['Accel_X', 'Accel_Y', 'Accel_Z', 'Gyro_Z'] if c in df.columns]\n        if sensor_cols:\n            df['null_count_sensor_agg'] = df[sensor_cols].isnull().sum(axis=1)\n\n        if all(col in df.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n            df['Accel_Magnitude'] = np.sqrt(df['Accel_X']**2 + df['Accel_Y']**2 + df['Accel_Z']**2)\n            df['Accel_Max'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].max(axis=1)\n            df['Accel_Min'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].min(axis=1)\n            df['Accel_Std'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].std(axis=1)\n            df['Accel_Range'] = df['Accel_Max'] - df['Accel_Min']\n            df['Is_Accel_Magnitude_Outlier'] = (df['Accel_Magnitude'].abs() >= 10.80)\n\n        if 'Gyro_Z' in df.columns:\n            df['Gyro_Abs'] = np.abs(df['Gyro_Z'])\n            df['Is_Gyro_Z_Outlier'] = (df['Gyro_Z'].abs() >= 0.672).astype(int)\n\n    if config.USE_ECONOMIC:\n        econ_cols = [c for c in ['Est_Price_IDR', 'Distance_KM', 'Promo_Code', 'Surge_Multiplier'] if c in df.columns]\n        if econ_cols:\n            df['null_count_economic'] = df[econ_cols].isnull().sum(axis=1)\n\n        if 'Est_Price_IDR' in df.columns and 'Distance_KM' in df.columns:\n            df['Price_per_KM'] = df['Est_Price_IDR'] / (df['Distance_KM'] + 1e-6)\n\n        def encode_promo(x):\n            if pd.isna(x):\n                return 0\n            if x == 'NO VOUCHER':\n                return 1\n            return 2\n\n        if 'Promo_Code' in df.columns:\n            df['Promo_Code_enc'] = df['Promo_Code'].apply(encode_promo).astype(np.int8)\n\n        if 'Surge_Multiplier' in df.columns:\n            surge_filled = df['Surge_Multiplier'].fillna(1.0)\n            df['Surge_Category'] = pd.cut(\n                surge_filled,\n                bins=[0, 1, 1.5, 2, 10],\n                labels=[0, 1, 2, 3]\n            ).astype(np.int8)\n\n    if config.USE_INTERACTION:\n        interaction_cols = [c for c in ['Surge_Multiplier', 'Hour', 'Distance_KM', 'Traffic'] if c in df.columns]\n        if interaction_cols:\n            df['null_count_interaction'] = df[interaction_cols].isnull().sum(axis=1)\n\n        if 'Surge_Multiplier' in df.columns and 'Hour' in df.columns:\n            df['Surge_Hour_Interaction'] = df['Surge_Multiplier'] * df['Hour']\n\n        if 'Distance_KM' in df.columns and 'Traffic' in df.columns:\n            traffic_map = {'Light': 1, 'Moderate': 2, 'Heavy': 3}\n            df['Traffic_Numeric'] = df['Traffic'].map(traffic_map).fillna(0).astype(np.int8)\n            df['Distance_Traffic'] = df['Distance_KM'] * df['Traffic_Numeric']\n\n    print(f\"Feature engineering completed. Shape: {df.shape}\")\n    return df\n\nconfig.USE_TEMPORAL = True\nconfig.USE_DISTANCE = True\nconfig.USE_SENSOR_AGG = True\nconfig.USE_ECONOMIC = True\nconfig.USE_INTERACTION = True\n\ntrain = engineer_features(train, is_train=True)\ntest = engineer_features(test, is_train=False)\n\ngc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:34:46.952859Z","iopub.execute_input":"2026-01-14T09:34:46.953166Z","iopub.status.idle":"2026-01-14T09:35:45.794383Z","shell.execute_reply.started":"2026-01-14T09:34:46.953119Z","shell.execute_reply":"2026-01-14T09:35:45.793568Z"}},"outputs":[{"name":"stdout","text":"Engineering features for train set...\nFeature engineering completed. Shape: (8000000, 63)\nEngineering features for test set...\nFeature engineering completed. Shape: (4000000, 62)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# def haversine_distance(lat1, lon1, lat2, lon2):\n#     R = 6371\n#     lat1_rad = np.radians(lat1)\n#     lat2_rad = np.radians(lat2)\n#     delta_lat = np.radians(lat2 - lat1)\n#     delta_lon = np.radians(lon2 - lon1)\n\n#     a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n#     c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n\n#     return R * c\n\n# def bearing(lat1, lon1, lat2, lon2):\n#     lat1, lat2 = np.radians(lat1), np.radians(lat2)\n#     diff = np.radians(lon2 - lon1)\n#     x = np.sin(diff) * np.cos(lat2)\n#     y = np.cos(lat1)*np.sin(lat2) - np.sin(lat1)*np.cos(lat2)*np.cos(diff)\n#     return np.degrees(np.arctan2(x, y))\n\n# def geo_bin(lat, lon, precision=2):\n#     return lat.round(precision).astype(str) + '_' + lon.round(precision).astype(str)\n\n# def engineer_features(df, is_train=True):\n#     print(f\"Engineering features for {'train' if is_train else 'test'} set...\")\n#     df = df.copy()\n\n#     df['null_count'] = df.isnull().sum(axis=1)\n\n#     if config.USE_TEMPORAL and 'Timestamp' in df.columns:\n#         print(\"  - Creating temporal features...\")\n#         temporal_cols = ['Timestamp']\n#         df['null_count_temporal'] = df[temporal_cols].isnull().sum(axis=1)\n        \n#         df['Timestamp_parsed'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n#         df['Hour'] = df['Timestamp_parsed'].dt.hour\n#         df['DayOfWeek'] = df['Timestamp_parsed'].dt.dayofweek\n#         df['Month'] = df['Timestamp_parsed'].dt.month\n#         df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(float)\n#         df['IsRushHour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9) | \n#                             (df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(float)\n#         df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 5)).astype(float)\n#         df.drop('Timestamp_parsed', axis=1, inplace=True)\n\n#     if config.USE_DISTANCE:\n#         print(\"  - Creating distance features...\")\n#         distance_cols = [c for c in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long', 'Distance_KM'] if c in df.columns]\n#         if distance_cols:\n#             df['null_count_distance'] = df[distance_cols].isnull().sum(axis=1)\n            \n#         if all(col in df.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n#             df['Haversine_Distance'] = haversine_distance(\n#                 df['Pickup_Lat'], df['Pickup_Long'],\n#                 df['Dropoff_Lat'], df['Dropoff_Long']\n#             )\n#             df['Delta_Lat'] = df['Dropoff_Lat'] - df['Pickup_Lat']\n#             df['Bearing'] = bearing(df.Pickup_Lat, df.Pickup_Long, df.Dropoff_Lat, df.Dropoff_Long)\n#             df[\"bearing_sin\"] = np.sin(np.radians(df[\"Bearing\"])) \n#             df[\"bearing_cos\"] = np.cos(np.radians(df[\"Bearing\"]))\n#             df['pickup_grid'] = geo_bin(df['Pickup_Lat'], df['Pickup_Long'])\n\n#             if 'Distance_KM' in df.columns:\n#                 df['Distance_Ratio'] = df['Distance_KM'] / (df['Haversine_Distance'] + 1e-6)\n#                 df['Distance_Difference'] = np.abs(df['Distance_KM'] - df['Haversine_Distance'])\n#                 df['Is_Ultra_Short_Distance'] = (df['Distance_KM'] < 0.024).astype(int)\n\n#         if 'Pickup_Zone' in df.columns and 'Dropoff_Zone' in df.columns:\n#             df['Is_Same_Zone'] = (df['Pickup_Zone'] == df['Dropoff_Zone']).astype(np.int8)\n\n#             pickup_freq = df['Pickup_Zone'].value_counts()\n#             dropoff_freq = df['Dropoff_Zone'].value_counts()\n\n#             df['pickup_zone_count'] = df['Pickup_Zone'].map(pickup_freq).fillna(0)\n#             df['dropoff_zone_count'] = df['Dropoff_Zone'].map(dropoff_freq).fillna(0)\n\n#     if config.USE_SENSOR_AGG:\n#         print(\"  - Creating sensor aggregation features...\")\n#         sensor_cols = [c for c in ['Accel_X', 'Accel_Y', 'Accel_Z', 'Gyro_Z'] if c in df.columns]\n#         if sensor_cols:\n#             df['null_count_sensor_agg'] = df[sensor_cols].isnull().sum(axis=1)\n            \n#         if all(col in df.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n#             df['Accel_Magnitude'] = np.sqrt(df['Accel_X']**2 + df['Accel_Y']**2 + df['Accel_Z']**2)\n#             df['Accel_Max'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].max(axis=1)\n#             df['Accel_Min'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].min(axis=1)\n#             df['Accel_Std'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].std(axis=1)\n#             df['Accel_Range'] = df['Accel_Max'] - df['Accel_Min']\n#             df['Is_Accel_Magnitude_Outlier'] = (df['Accel_Magnitude'].abs() >= 10.80)\n\n#         if 'Gyro_Z' in df.columns:\n#             df['Gyro_Abs'] = np.abs(df['Gyro_Z'])\n#             df['Is_Gyro_Z_Outlier'] = (df['Gyro_Z'].abs() >= 0.672).astype(int)\n\n#     if config.USE_ECONOMIC:\n#         print(\"  - Creating economic features...\")\n#         econ_cols = [c for c in ['Est_Price_IDR', 'Distance_KM', 'Promo_Code', 'Surge_Multiplier'] if c in df.columns]\n#         if econ_cols:\n#             df['null_count_economic'] = df[econ_cols].isnull().sum(axis=1)\n            \n#         if 'Est_Price_IDR' in df.columns and 'Distance_KM' in df.columns:\n#             df['Price_per_KM'] = df['Est_Price_IDR'] / (df['Distance_KM'] + 1e-6)\n\n#         def encode_promo(x):\n#             if pd.isna(x):\n#                 return 0\n#             if x == 'NO VOUCHER':\n#                 return 1\n#             return 2\n\n#         if 'Promo_Code' in df.columns:\n#             df['Promo_Code_enc'] = df['Promo_Code'].apply(encode_promo).astype(np.int8)\n\n#         if 'Surge_Multiplier' in df.columns:\n#             surge_filled = df['Surge_Multiplier'].fillna(1.0)\n#             df['Surge_Category'] = pd.cut(\n#                 surge_filled,\n#                 bins=[0, 1, 1.5, 2, 10],\n#                 labels=[0, 1, 2, 3]\n#             ).astype(np.int8)\n\n#     if config.USE_INTERACTION:\n#         print(\"  - Creating interaction features...\")\n#         interaction_cols = [c for c in ['Surge_Multiplier', 'Hour', 'Distance_KM', 'Traffic'] if c in df.columns]\n#         if interaction_cols:\n#             df['null_count_interaction'] = df[interaction_cols].isnull().sum(axis=1)\n            \n#         if 'Surge_Multiplier' in df.columns and 'Hour' in df.columns:\n#             df['Surge_Hour_Interaction'] = df['Surge_Multiplier'] * df['Hour']\n\n#         if 'Distance_KM' in df.columns and 'Traffic' in df.columns:\n#             traffic_map = {'Light': 1, 'Moderate': 2, 'Heavy': 3}\n#             df['Traffic_Numeric'] = df['Traffic'].map(traffic_map).fillna(0).astype(np.int8)\n#             df['Distance_Traffic'] = df['Distance_KM'] * df['Traffic_Numeric']\n\n#     print(f\"Feature engineering completed. Shape: {df.shape}\")\n#     return df\n\n# config.USE_TEMPORAL = True\n# config.USE_DISTANCE = True\n# config.USE_SENSOR_AGG = True\n# config.USE_ECONOMIC = True\n# config.USE_INTERACTION = True\n\n# train = engineer_features(train, is_train=True)\n# test = engineer_features(test, is_train=False)\n\n# pickup_price_mean = train.groupby('Pickup_Zone')['Est_Price_IDR'].mean()\n# pickup_dist_mean = train.groupby('Pickup_Zone')['Distance_KM'].mean()\n\n# train['pickup_zone_avg_price'] = train['Pickup_Zone'].map(pickup_price_mean).fillna(0)\n# test['pickup_zone_avg_price'] = test['Pickup_Zone'].map(pickup_price_mean).fillna(0)\n\n# train['pickup_zone_avg_distance'] = train['Pickup_Zone'].map(pickup_dist_mean).fillna(0)\n# test['pickup_zone_avg_distance'] = test['Pickup_Zone'].map(pickup_dist_mean).fillna(0)\n\n# train_route = train['Pickup_Zone'] + '__' + train['Dropoff_Zone']\n# test_route = test['Pickup_Zone'] + '__' + test['Dropoff_Zone']\n\n# route_freq = train_route.value_counts()\n\n# train['route_count'] = train_route.map(route_freq).fillna(0)\n# test['route_count'] = test_route.map(route_freq).fillna(0)\n\n# gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T21:55:03.618779Z","iopub.execute_input":"2026-01-13T21:55:03.619248Z","iopub.status.idle":"2026-01-13T21:56:48.722832Z","shell.execute_reply.started":"2026-01-13T21:55:03.619222Z","shell.execute_reply":"2026-01-13T21:56:48.722110Z"}},"outputs":[{"name":"stdout","text":"Engineering features for train set...\n  - Creating temporal features...\n  - Creating distance features...\n  - Creating sensor aggregation features...\n  - Creating economic features...\n  - Creating interaction features...\nFeature engineering completed. Shape: (8000000, 66)\nEngineering features for test set...\n  - Creating temporal features...\n  - Creating distance features...\n  - Creating sensor aggregation features...\n  - Creating economic features...\n  - Creating interaction features...\nFeature engineering completed. Shape: (4000000, 65)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"102"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def encode_categorical_frequency(train, test, categorical_cols):\n    \"\"\"\n    Encodes based on value frequency in training data\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"FREQUENCY ENCODING\")\n    print(\"=\"*80)\n    \n    encoders = {}\n    \n    for col in tqdm(categorical_cols, desc=\"Frequency encoding\"):\n        freq_map = train[col].value_counts(dropna=False).to_dict()\n        \n        train[col] = train[col].map(freq_map).fillna(0).astype(np.int32)\n        test[col] = test[col].map(freq_map).fillna(0).astype(np.int32)\n        \n        encoders[col] = {\n            'type': 'frequency',\n            'unique_values': len(freq_map),\n            'unseen_in_test': (test[col] == 0).sum()\n        }\n    \n    print(f\"\\nEncoded {len(categorical_cols)} categorical features\")\n    return train, test, encoders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:35:45.796400Z","iopub.execute_input":"2026-01-14T09:35:45.796606Z","iopub.status.idle":"2026-01-14T09:35:45.802183Z","shell.execute_reply.started":"2026-01-14T09:35:45.796588Z","shell.execute_reply":"2026-01-14T09:35:45.801394Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def encode_categorical_target(train, test, categorical_cols, y_train, smoothing=10):\n    \"\"\"\n    Encodes based on target mean, with smoothing to prevent overfitting\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"TARGET ENCODING\")\n    print(\"=\"*80)\n    \n    encoders = {}\n    global_mean = y_train.mean()\n    \n    for col in tqdm(categorical_cols, desc=\"Target encoding\"):\n        temp_df = pd.DataFrame({col: train[col], 'target': y_train})\n        \n        agg = temp_df.groupby(col)['target'].agg(['mean', 'count'])\n        smoothed_mean = (agg['mean'] * agg['count'] + global_mean * smoothing) / (agg['count'] + smoothing)\n        \n        encoding_map = smoothed_mean.to_dict()\n        \n        train[col] = train[col].map(encoding_map).fillna(global_mean).astype(np.float32)\n        test[col] = test[col].map(encoding_map).fillna(global_mean).astype(np.float32)\n        \n        encoders[col] = {\n            'type': 'target',\n            'unique_values': len(encoding_map),\n            'global_mean': global_mean\n        }\n    \n    print(f\"\\nEncoded {len(categorical_cols)} categorical features\")\n    return train, test, encoders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:35:45.803079Z","iopub.execute_input":"2026-01-14T09:35:45.803688Z","iopub.status.idle":"2026-01-14T09:35:45.819500Z","shell.execute_reply.started":"2026-01-14T09:35:45.803668Z","shell.execute_reply":"2026-01-14T09:35:45.818778Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def encode_categorical_label_optimized(train, test, categorical_cols):\n    print(\"\\n\" + \"=\"*80)\n    print(\"LABEL ENCODING\")\n    print(\"=\"*80)\n\n    label_encoders = {}\n\n    for col in tqdm(categorical_cols, desc=\"Label encoding\"):\n        train[col] = train[col].astype(str)\n        test[col] = test[col].astype(str)\n\n        le = LabelEncoder()\n        train[col] = le.fit_transform(train[col])\n\n        mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n        test[col] = test[col].map(mapping).fillna(-1).astype(int)\n\n        label_encoders[col] = le\n\n    print(f\"\\nEncoded {len(categorical_cols)} categorical features\")\n    return train, test, label_encoders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:35:45.820405Z","iopub.execute_input":"2026-01-14T09:35:45.820718Z","iopub.status.idle":"2026-01-14T09:35:45.833201Z","shell.execute_reply.started":"2026-01-14T09:35:45.820699Z","shell.execute_reply":"2026-01-14T09:35:45.832538Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# def preprocess_data(train, test, encoding_method='frequency'):\n#     \"\"\"\n#     Main preprocessing pipeline\n    \n#     Parameters:\n#     -----------\n#     train : pd.DataFrame\n#         Training dataset\n#     test : pd.DataFrame\n#         Test dataset\n#     encoding_method : str\n#         Encoding method to use: 'frequency', 'target', or 'label'\n#     Returns:\n#     --------\n#     X_train, X_test, y_train, le_target, encoders\n#     \"\"\"\n#     print(\"\\n\" + \"=\"*80)\n#     print(\"DATA PREPROCESSING PIPELINE\")\n#     print(\"=\"*80)\n#     print(f\"Encoding method: {encoding_method.upper()}\")\n    \n#     cols_to_drop = [config.ID_COL, 'Timestamp']\n#     if config.TARGET_COL in train.columns:\n#         y = train[config.TARGET_COL].copy()\n#         cols_to_drop.append(config.TARGET_COL)\n#     else:\n#         y = None\n    \n#     cols_to_drop = [col for col in cols_to_drop if col in train.columns]\n#     X_train = train.drop(cols_to_drop, axis=1).copy()\n#     X_test = test.drop([col for col in cols_to_drop if col in test.columns], axis=1).copy()\n    \n#     print(f\"\\nInitial shapes:\")\n#     print(f\"  X_train: {X_train.shape}\")\n#     print(f\"  X_test: {X_test.shape}\")\n    \n#     print(f\"\\nMissing values before imputation:\")\n#     train_missing = X_train.isnull().sum()\n#     if train_missing.sum() > 0:\n#         print(train_missing[train_missing > 0])\n#     else:\n#         print(\"  No missing values found\")\n    \n#     numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n#     categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n    \n#     print(f\"\\nFeature types detected:\")\n#     print(f\"  Numeric features: {len(numeric_cols)}\")\n#     print(f\"  Categorical features: {len(categorical_cols)}\")\n    \n#     print(\"\\n\" + \"=\"*80)\n#     print(\"STEP 1: Missing Value Imputation\")\n#     print(\"=\"*80)\n    \n#     for col in tqdm(numeric_cols, desc=\"Imputing numeric features\"):\n#         if X_train[col].isnull().sum() > 0:\n#             median_val = X_train[col].median()\n#             X_train[col].fillna(median_val, inplace=True)\n#             X_test[col].fillna(median_val, inplace=True)\n    \n#     for col in tqdm(categorical_cols, desc=\"Imputing categorical features\"):\n#         if X_train[col].isnull().sum() > 0:\n#             X_train[col].fillna('Unknown', inplace=True)\n#             X_test[col].fillna('Unknown', inplace=True)\n    \n#     print(\"\\n\" + \"=\"*80)\n#     print(\"STEP 2: Outlier Clipping\")\n#     print(\"=\"*80)\n    \n#     for col in tqdm(numeric_cols, desc=\"Clipping outliers\"):\n#         q99 = X_train[col].quantile(0.99)\n#         q01 = X_train[col].quantile(0.01)\n#         X_train[col] = X_train[col].clip(q01, q99)\n#         X_test[col] = X_test[col].clip(q01, q99)\n    \n#     print(\"\\n\" + \"=\"*80)\n#     print(\"STEP 3: Categorical Encoding\")\n#     print(\"=\"*80)\n    \n#     if len(categorical_cols) > 0:\n#         if encoding_method == 'frequency':\n#             X_train, X_test, encoders = encode_categorical_frequency(\n#                 X_train, X_test, categorical_cols\n#             )\n#         elif encoding_method == 'target':\n#             if y is None:\n#                 raise ValueError(\"Target encoding requires target variable\")\n#             le_target_temp = LabelEncoder()\n#             y_temp = le_target_temp.fit_transform(y)\n#             X_train, X_test, encoders = encode_categorical_target(\n#                 X_train, X_test, categorical_cols, y_temp\n#             )\n#         elif encoding_method == 'label':\n#             X_train, X_test, encoders = encode_categorical_label_optimized(\n#                 X_train, X_test, categorical_cols\n#             )\n#         else:\n#             raise ValueError(f\"Unknown encoding method: {encoding_method}\")\n#     else:\n#         encoders = {}\n#         print(\"No categorical features to encode\")\n    \n#     print(\"\\n\" + \"=\"*80)\n#     print(\"STEP 4: Target Encoding\")\n#     print(\"=\"*80)\n    \n#     if y is not None:\n#         le_target = LabelEncoder()\n#         y_encoded = le_target.fit_transform(y)\n#         print(f\"\\nTarget classes encoded:\")\n#         for i, label in enumerate(le_target.classes_):\n#             count = (y_encoded == i).sum()\n#             print(f\"  {i}: {label:20s} - {count:,} samples ({count/len(y_encoded)*100:.2f}%)\")\n#     else:\n#         y_encoded = None\n#         le_target = None\n    \n#     print(\"\\n\" + \"=\"*80)\n#     print(\"PREPROCESSING COMPLETED\")\n#     print(\"=\"*80)\n#     print(f\"Final shapes:\")\n#     print(f\"  X_train: {X_train.shape}\")\n#     print(f\"  X_test: {X_test.shape}\")\n#     if y_encoded is not None:\n#         print(f\"  y_train: {y_encoded.shape}\")\n#     print(\"=\"*80)\n    \n#     return X_train, X_test, y_encoded, le_target, encoders\n\n# X_train, X_test, y_train, le_target, encoders = preprocess_data(train, test, encoding_method='target')\n# gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:42:34.577958Z","iopub.execute_input":"2026-01-13T16:42:34.578231Z","iopub.status.idle":"2026-01-13T16:42:34.598004Z","shell.execute_reply.started":"2026-01-13T16:42:34.578210Z","shell.execute_reply":"2026-01-13T16:42:34.597371Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def preprocess_data(train, test, encoding_method='frequency'):\n    \"\"\"\n    Main preprocessing pipeline\n    \n    Parameters:\n    -----------\n    train : pd.DataFrame\n        Training dataset\n    test : pd.DataFrame\n        Test dataset\n    encoding_method : str\n        Encoding method to use: 'frequency', 'target', or 'label'\n    Returns:\n    --------\n    X_train, X_test, y_train, le_target, encoders\n    \"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"DATA PREPROCESSING PIPELINE\")\n    print(\"=\"*80)\n    print(f\"Encoding method: {encoding_method.upper()}\")\n    \n    cols_to_drop = [config.ID_COL, 'Timestamp']\n    if config.TARGET_COL in train.columns:\n        y = train[config.TARGET_COL].copy()\n        cols_to_drop.append(config.TARGET_COL)\n    else:\n        y = None\n    \n    cols_to_drop = [col for col in cols_to_drop if col in train.columns]\n    X_train = train.drop(cols_to_drop, axis=1).copy()\n    X_test = test.drop([col for col in cols_to_drop if col in test.columns], axis=1).copy()\n    \n    print(f\"\\nInitial shapes:\")\n    print(f\"  X_train: {X_train.shape}\")\n    print(f\"  X_test: {X_test.shape}\")\n    \n    print(f\"\\nMissing values before imputation:\")\n    train_missing = X_train.isnull().sum()\n    if train_missing.sum() > 0:\n        print(train_missing[train_missing > 0])\n    else:\n        print(\"  No missing values found\")\n    \n    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n    \n    print(f\"\\nFeature types detected:\")\n    print(f\"  Numeric features: {len(numeric_cols)}\")\n    print(f\"  Categorical features: {len(categorical_cols)}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STEP 1: Missing Value Imputation\")\n    print(\"=\"*80)\n    \n    mean_impute_cols = ['Accel_Y', 'Accel_Z', 'Dropoff_Lat', 'Dropoff_Long', 'Gyro_Z']\n    mean_impute_cols = [c for c in mean_impute_cols if c in numeric_cols]\n    median_impute_cols = [c for c in numeric_cols if c not in mean_impute_cols]\n    \n    for col in tqdm(mean_impute_cols, desc=\"Imputing numeric features (mean)\"):\n        mean_val = X_train[col].mean()\n        X_train[col].fillna(mean_val, inplace=True)\n        X_test[col].fillna(mean_val, inplace=True)\n    \n    for col in tqdm(median_impute_cols, desc=\"Imputing numeric features (median)\"):\n        if X_train[col].isnull().sum() > 0:\n            median_val = X_train[col].median()\n            X_train[col].fillna(median_val, inplace=True)\n            X_test[col].fillna(median_val, inplace=True)\n    \n    for col in tqdm(categorical_cols, desc=\"Imputing categorical features\"):\n        if X_train[col].isnull().sum() > 0:\n            X_train[col].fillna('Unknown', inplace=True)\n            X_test[col].fillna('Unknown', inplace=True)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STEP 2: Outlier Clipping\")\n    print(\"=\"*80)\n    \n    for col in tqdm(numeric_cols, desc=\"Clipping outliers\"):\n        q99 = X_train[col].quantile(0.99)\n        q01 = X_train[col].quantile(0.01)\n        X_train[col] = X_train[col].clip(q01, q99)\n        X_test[col] = X_test[col].clip(q01, q99)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STEP 3: Categorical Encoding\")\n    print(\"=\"*80)\n    \n    encoders = {}\n    \n    ordinal_cols = ['Weather', 'Traffic', 'Payment_Method', 'Signal_Strength', 'Car_Model']\n    ordinal_cols = [c for c in ordinal_cols if c in categorical_cols]\n    other_cat_cols = [c for c in categorical_cols if c not in ordinal_cols]\n    \n    if len(ordinal_cols) > 0:\n        from sklearn.preprocessing import OrdinalEncoder\n        oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n        X_train[ordinal_cols] = oe.fit_transform(X_train[ordinal_cols])\n        X_test[ordinal_cols] = oe.transform(X_test[ordinal_cols])\n        encoders['ordinal'] = oe\n    \n    if len(other_cat_cols) > 0:\n        if encoding_method == 'frequency':\n            X_train, X_test, enc = encode_categorical_frequency(\n                X_train, X_test, other_cat_cols\n            )\n            encoders.update(enc)\n        elif encoding_method == 'target':\n            if y is None:\n                raise ValueError(\"Target encoding requires target variable\")\n            le_target_temp = LabelEncoder()\n            y_temp = le_target_temp.fit_transform(y)\n            X_train, X_test, enc = encode_categorical_target(\n                X_train, X_test, other_cat_cols, y_temp\n            )\n            encoders.update(enc)\n        elif encoding_method == 'label':\n            X_train, X_test, enc = encode_categorical_label_optimized(\n                X_train, X_test, other_cat_cols\n            )\n            encoders.update(enc)\n        else:\n            raise ValueError(f\"Unknown encoding method: {encoding_method}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"STEP 4: Target Encoding\")\n    print(\"=\"*80)\n    \n    if y is not None:\n        le_target = LabelEncoder()\n        y_encoded = le_target.fit_transform(y)\n        print(f\"\\nTarget classes encoded:\")\n        for i, label in enumerate(le_target.classes_):\n            count = (y_encoded == i).sum()\n            print(f\"  {i}: {label:20s} - {count:,} samples ({count/len(y_encoded)*100:.2f}%)\")\n    else:\n        y_encoded = None\n        le_target = None\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"PREPROCESSING COMPLETED\")\n    print(\"=\"*80)\n    print(f\"Final shapes:\")\n    print(f\"  X_train: {X_train.shape}\")\n    print(f\"  X_test: {X_test.shape}\")\n    if y_encoded is not None:\n        print(f\"  y_train: {y_encoded.shape}\")\n    print(\"=\"*80)\n    \n    return X_train, X_test, y_encoded, le_target, encoders\n\nX_train, X_test, y_train, le_target, encoders = preprocess_data(train, test, encoding_method='target')\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:35:45.834062Z","iopub.execute_input":"2026-01-14T09:35:45.834337Z","iopub.status.idle":"2026-01-14T09:37:04.925034Z","shell.execute_reply.started":"2026-01-14T09:35:45.834311Z","shell.execute_reply":"2026-01-14T09:37:04.924468Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nDATA PREPROCESSING PIPELINE\n================================================================================\nEncoding method: TARGET\n\nInitial shapes:\n  X_train: (8000000, 60)\n  X_test: (4000000, 60)\n\nMissing values before imputation:\nPickup_Lat                 929348\nPickup_Long                611083\nDropoff_Lat               1914440\nDropoff_Long              1556029\nGPS_Accuracy_M            1504090\nDistance_KM                941317\nEst_Price_IDR             1151401\nSurge_Multiplier           612307\nAccel_X                   1608442\nAccel_Y                   1081337\nAccel_Z                   1840229\nGyro_Z                     701714\nPickup_Zone               1381274\nDropoff_Zone               765445\nDevice_FP                 1499497\nPromo_Code                1107810\nCar_Model                 1721777\nPayment_Method            1141190\nWeather                    514649\nTraffic                   1808403\nBattery_Level             1746399\nSignal_Strength            408588\nHour                      1637893\nDayOfWeek                 1637893\nMonth                     1637893\nHaversine_Distance        3998467\nDelta_Lat                 2621560\nBearing                   3998467\nbearing_sin               3998467\nbearing_cos               3998467\nDistance_Ratio            4469127\nDistance_Difference       4469127\nAccel_Magnitude           3744751\nAccel_Max                   50209\nAccel_Min                   50209\nAccel_Std                  735048\nAccel_Range                 50209\nGyro_Abs                   701714\nPrice_per_KM              1957077\nSurge_Hour_Interaction    2125355\nDistance_Traffic           941317\ndtype: int64\n\nFeature types detected:\n  Numeric features: 48\n  Categorical features: 11\n\n================================================================================\nSTEP 1: Missing Value Imputation\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Imputing numeric features (mean):   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d87c6fbbe07644aeb5d4e68cfcf4db1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Imputing numeric features (median):   0%|          | 0/43 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e54f4c1884914d0a896a2e8f0d056b5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Imputing categorical features:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b90111e634b480aad8e9d85384dafae"}},"metadata":{}},{"name":"stdout","text":"\n================================================================================\nSTEP 2: Outlier Clipping\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Clipping outliers:   0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ff6d05af6b4ee9871eee1b9cef2c68"}},"metadata":{}},{"name":"stdout","text":"\n================================================================================\nSTEP 3: Categorical Encoding\n================================================================================\n\n================================================================================\nTARGET ENCODING\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Target encoding:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6566ef8823534eda94350bed404c0e8e"}},"metadata":{}},{"name":"stdout","text":"\nEncoded 6 categorical features\n\n================================================================================\nSTEP 4: Target Encoding\n================================================================================\n\nTarget classes encoded:\n  0: Fraud_Indication     - 400,313 samples (5.00%)\n  1: Navigation_Issue     - 801,790 samples (10.02%)\n  2: Perfect_Trip         - 4,397,607 samples (54.97%)\n  3: Safety_Violation     - 1,601,595 samples (20.02%)\n  4: Service_Complaint    - 798,695 samples (9.98%)\n\n================================================================================\nPREPROCESSING COMPLETED\n================================================================================\nFinal shapes:\n  X_train: (8000000, 60)\n  X_test: (4000000, 60)\n  y_train: (8000000,)\n================================================================================\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"80"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def macro_f1_eval(preds, dtrain):\n    \"\"\"\n    Custom evaluation function for XGBoost to calculate Macro F1\n    \"\"\"\n    labels = dtrain.get_label()\n    preds_reshaped = preds.reshape(len(labels), -1)\n    pred_labels = np.argmax(preds_reshaped, axis=1)\n    # Calculate macro F1\n    score = f1_score(labels, pred_labels, average='macro')\n    return 'macro_f1', score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:37:04.925979Z","iopub.execute_input":"2026-01-14T09:37:04.926343Z","iopub.status.idle":"2026-01-14T09:37:04.930555Z","shell.execute_reply.started":"2026-01-14T09:37:04.926320Z","shell.execute_reply":"2026-01-14T09:37:04.929775Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def macro_f1_lgb(preds, dataset):\n    y_true = dataset.get_label()\n    num_class = len(np.unique(y_true))\n    preds_reshaped = preds.reshape(num_class, -1).T  # shape (n_samples, n_classes)\n    y_pred_labels = np.argmax(preds_reshaped, axis=1)\n    score = f1_score(y_true, y_pred_labels, average='macro')\n    return 'macro_f1', score, True  # True -> higher is better","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:37:04.931388Z","iopub.execute_input":"2026-01-14T09:37:04.931606Z","iopub.status.idle":"2026-01-14T09:37:04.943186Z","shell.execute_reply.started":"2026-01-14T09:37:04.931587Z","shell.execute_reply":"2026-01-14T09:37:04.942386Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Tuning","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom tqdm import trange\n\ndef tune_class_weights_optuna(X, y, X_test, n_trials=30):\n    def objective(trial):\n        w4 = trial.suggest_float(\"w4\", 1.0, 10.0)\n        w1 = trial.suggest_float(\"w1\", 1.0, 10.0)\n\n        sample_weight = np.ones(len(y))\n        sample_weight[y == 4] = w4\n        sample_weight[y == 1] = w1\n\n        _, _, score = train_xgboost(\n            X,\n            y,\n            X_test,\n            use_gpu=gpu_config['xgboost_gpu'],\n            sample_weight=sample_weight\n        )\n\n        print(f\"Trial F1 Macro: {score:.6f}\")\n        return score\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"Best Params:\", study.best_params)\n    print(\"Best F1:\", study.best_value)\n    return study.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:47:18.856334Z","iopub.execute_input":"2026-01-13T16:47:18.856627Z","iopub.status.idle":"2026-01-13T16:47:18.862373Z","shell.execute_reply.started":"2026-01-13T16:47:18.856604Z","shell.execute_reply":"2026-01-13T16:47:18.861649Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n    \ndef train_xgboost(X_train, y_train, X_test, use_gpu=False, sample_weight=None):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None\n\n    params = config.get_xgboost_params(use_gpu=use_gpu)\n    params['num_class'] = len(np.unique(y_train))\n\n    X_tr, X_val, y_tr, y_val, w_tr, w_val = train_test_split(\n        X_train,\n        y_train,\n        sample_weight,\n        test_size=0.2,\n        stratify=y_train,\n        random_state=config.RANDOM_STATE\n    )\n\n    dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n    dval = xgb.DMatrix(X_val, label=y_val, weight=w_val)\n    dtest = xgb.DMatrix(X_test)\n\n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=1000,\n        evals=[(dval, 'valid')],\n        custom_metric=macro_f1_eval,\n        early_stopping_rounds=50,\n        verbose_eval=False\n    )\n\n    val_preds = model.predict(dval)\n    val_labels = np.argmax(val_preds, axis=1)\n    score = f1_score(y_val, val_labels, average='macro')\n\n    test_preds = model.predict(dtest)\n\n    return test_preds, model, score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:33:26.544400Z","iopub.execute_input":"2026-01-13T17:33:26.545176Z","iopub.status.idle":"2026-01-13T17:33:26.551610Z","shell.execute_reply.started":"2026-01-13T17:33:26.545148Z","shell.execute_reply":"2026-01-13T17:33:26.550874Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"best_weights = tune_class_weights_optuna(X_train, y_train, X_test, n_trials=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T16:48:37.924708Z","iopub.execute_input":"2026-01-13T16:48:37.925014Z","iopub.status.idle":"2026-01-13T17:12:41.164470Z","shell.execute_reply.started":"2026-01-13T16:48:37.924990Z","shell.execute_reply":"2026-01-13T17:12:41.163861Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:48:37,926]\u001b[0m A new study created in memory with name: no-name-d54e8e47-5e2c-47bd-9952-fb36689a68f9\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:49:26,090]\u001b[0m Trial 0 finished with value: 0.5048238160889713 and parameters: {'w4': 8.786316835058415, 'w1': 5.128610516284762}. Best is trial 0 with value: 0.5048238160889713.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.504824\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:50:13,175]\u001b[0m Trial 1 finished with value: 0.5092455724423084 and parameters: {'w4': 8.04211571680899, 'w1': 3.367347839281938}. Best is trial 1 with value: 0.5092455724423084.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.509246\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:51:00,799]\u001b[0m Trial 2 finished with value: 0.6039350047914577 and parameters: {'w4': 5.5521572984537215, 'w1': 3.3261505036706596}. Best is trial 2 with value: 0.6039350047914577.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.603935\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:51:48,274]\u001b[0m Trial 3 finished with value: 0.49337621551118904 and parameters: {'w4': 2.884567263239298, 'w1': 7.516052216769225}. Best is trial 2 with value: 0.6039350047914577.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.493376\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:52:35,908]\u001b[0m Trial 4 finished with value: 0.48499956232322133 and parameters: {'w4': 3.802841877833811, 'w1': 9.164976359762656}. Best is trial 2 with value: 0.6039350047914577.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.485000\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:53:24,044]\u001b[0m Trial 5 finished with value: 0.503446917692371 and parameters: {'w4': 9.930015422368136, 'w1': 3.4999583734034525}. Best is trial 2 with value: 0.6039350047914577.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.503447\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:54:12,701]\u001b[0m Trial 6 finished with value: 0.4855161048057258 and parameters: {'w4': 9.842815782579578, 'w1': 7.22936856323649}. Best is trial 2 with value: 0.6039350047914577.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.485516\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:55:01,313]\u001b[0m Trial 7 finished with value: 0.6064542471629958 and parameters: {'w4': 5.555206925016396, 'w1': 4.502242662060139}. Best is trial 7 with value: 0.6064542471629958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.606454\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:55:49,680]\u001b[0m Trial 8 finished with value: 0.4907490763705032 and parameters: {'w4': 9.203102764600434, 'w1': 1.37750896700706}. Best is trial 7 with value: 0.6064542471629958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.490749\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:56:37,618]\u001b[0m Trial 9 finished with value: 0.47289037511127185 and parameters: {'w4': 1.0517747181694315, 'w1': 8.616131534501871}. Best is trial 7 with value: 0.6064542471629958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.472890\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:57:26,332]\u001b[0m Trial 10 finished with value: 0.5097710859326017 and parameters: {'w4': 6.782937104100356, 'w1': 5.73051679600232}. Best is trial 7 with value: 0.6064542471629958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.509771\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:58:14,818]\u001b[0m Trial 11 finished with value: 0.6118278465202109 and parameters: {'w4': 5.3303484543726665, 'w1': 3.136838209216872}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.611828\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:59:02,915]\u001b[0m Trial 12 finished with value: 0.6040014810882882 and parameters: {'w4': 4.889643914076228, 'w1': 1.1574590999087335}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.604001\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 16:59:51,406]\u001b[0m Trial 13 finished with value: 0.5105070923070041 and parameters: {'w4': 6.408760770604127, 'w1': 4.771647895411956}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.510507\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:00:38,781]\u001b[0m Trial 14 finished with value: 0.6072030125956516 and parameters: {'w4': 4.159616963722114, 'w1': 1.9840135671153627}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.607203\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:01:26,755]\u001b[0m Trial 15 finished with value: 0.6106570777240139 and parameters: {'w4': 3.5629193892081457, 'w1': 2.448772965356716}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.610657\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:02:14,905]\u001b[0m Trial 16 finished with value: 0.6071793308347965 and parameters: {'w4': 2.3924760642760456, 'w1': 2.5428053078992106}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.607179\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:03:02,755]\u001b[0m Trial 17 finished with value: 0.6072308829846319 and parameters: {'w4': 2.3829407844221, 'w1': 2.5069683542298087}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.607231\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:03:51,424]\u001b[0m Trial 18 finished with value: 0.5137269952407758 and parameters: {'w4': 6.7097230711444045, 'w1': 6.383722907958275}. Best is trial 11 with value: 0.6118278465202109.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.513727\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:04:39,379]\u001b[0m Trial 19 finished with value: 0.6305879321318663 and parameters: {'w4': 3.630655952726987, 'w1': 3.807835620718787}. Best is trial 19 with value: 0.6305879321318663.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.630588\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:05:27,122]\u001b[0m Trial 20 finished with value: 0.6059448307726603 and parameters: {'w4': 1.1485164411183693, 'w1': 4.238960336223336}. Best is trial 19 with value: 0.6305879321318663.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.605945\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:06:15,148]\u001b[0m Trial 21 finished with value: 0.6306816318989669 and parameters: {'w4': 3.6549319337554333, 'w1': 3.74434030000733}. Best is trial 21 with value: 0.6306816318989669.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.630682\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:07:02,954]\u001b[0m Trial 22 finished with value: 0.6319872416563699 and parameters: {'w4': 4.426994950459696, 'w1': 3.8708879966866836}. Best is trial 22 with value: 0.6319872416563699.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.631987\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:07:51,132]\u001b[0m Trial 23 finished with value: 0.6320343259141646 and parameters: {'w4': 4.421972938122566, 'w1': 4.071296588477645}. Best is trial 23 with value: 0.6320343259141646.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.632034\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:08:39,662]\u001b[0m Trial 24 finished with value: 0.5459843588277477 and parameters: {'w4': 4.283114789252029, 'w1': 5.768088553466638}. Best is trial 23 with value: 0.6320343259141646.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.545984\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:09:27,926]\u001b[0m Trial 25 finished with value: 0.6321125544027584 and parameters: {'w4': 4.653778039447037, 'w1': 4.429163940850082}. Best is trial 25 with value: 0.6321125544027584.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.632113\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:10:15,992]\u001b[0m Trial 26 finished with value: 0.632728986733007 and parameters: {'w4': 4.853138667206985, 'w1': 5.0323866556208205}. Best is trial 26 with value: 0.632728986733007.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.632729\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:11:04,217]\u001b[0m Trial 27 finished with value: 0.5065464074068262 and parameters: {'w4': 7.363714022672185, 'w1': 6.395523502273098}. Best is trial 26 with value: 0.632728986733007.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.506546\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:11:52,887]\u001b[0m Trial 28 finished with value: 0.577616994034096 and parameters: {'w4': 5.750477388290963, 'w1': 5.081686468357142}. Best is trial 26 with value: 0.632728986733007.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.577617\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:12:41,160]\u001b[0m Trial 29 finished with value: 0.6330866554432486 and parameters: {'w4': 4.863114750907993, 'w1': 5.305772729010983}. Best is trial 29 with value: 0.6330866554432486.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Trial F1 Macro: 0.633087\nBest Params: {'w4': 4.863114750907993, 'w1': 5.305772729010983}\nBest F1: 0.6330866554432486\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\ndef train_xgboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None, None\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"Training XGBoost Models\")\n    print(\"=\"*80)\n\n    params = config.get_xgboost_params(use_gpu=use_gpu)\n    params['num_class'] = len(np.unique(y_train))\n\n    sample_weight = np.ones(len(y_train))\n    sample_weight[y_train == 4] = best_weights[\"w4\"]\n    sample_weight[y_train == 1] = best_weights[\"w1\"]\n\n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n\n    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n\n    fold_scores = []\n    models = []\n\n    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"XGBoost Folds\")\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\n        dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=sample_weight[train_idx])\n        dval = xgb.DMatrix(X_val, label=y_val, weight=sample_weight[val_idx])\n        dtest = xgb.DMatrix(X_test)\n\n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            evals=[(dtrain, 'train'), (dval, 'valid')],\n            custom_metric=macro_f1_eval,\n            early_stopping_rounds=50,\n            verbose_eval=100\n        )\n\n        oof_predictions[val_idx] = model.predict(dval)\n        test_predictions += model.predict(dtest) / n_folds\n\n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n\n        print(f\"\\n{'='*60}\")\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(f\"{'='*60}\")\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.best_iteration}\")\n        print(f\"  Best Score (mlogloss): {model.best_score:.6f}\")\n\n        oof_fold_pred = np.argmax(oof_predictions[val_idx], axis=1)\n        print(f\"\\n  Per-Class F1 Scores:\")\n        from sklearn.metrics import classification_report\n        print(classification_report(\n            y_val,\n            oof_fold_pred,\n            target_names=[f\"Class_{i}\" for i in range(len(np.unique(y_train)))],\n            digits=4\n        ))\n        print(f\"{'='*60}\\n\")\n\n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n\n        models.append(model)\n        gc.collect()\n\n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"XGBOOST TRAINING SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n    print(f\"\\nFold-by-Fold Scores:\")\n    for i, score in enumerate(fold_scores, 1):\n        print(f\"  Fold {i}: {score:.6f}\")\n\n    print(f\"\\n\" + \"=\"*80)\n    print(\"OVERALL OUT-OF-FOLD PREDICTIONS REPORT\")\n    print(\"=\"*80)\n    print(classification_report(\n        y_train,\n        oof_pred_labels,\n        target_names=[f\"Class_{i}\" for i in range(len(np.unique(y_train)))],\n        digits=4\n    ))\n    print(\"=\"*80)\n\n    return oof_predictions, test_predictions, models, overall_score\n\n\nif XGBOOST_AVAILABLE:\n    oof_predictions, test_predictions, xgboost_models, xgboost_cv_score = train_xgboost(\n        X_train,\n        y_train,\n        X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config['xgboost_gpu']\n    )\nelse:\n    oof_predictions, test_predictions, xgboost_models, xgboost_cv_score = None, None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:13:33.533654Z","iopub.execute_input":"2026-01-13T17:13:33.534408Z","iopub.status.idle":"2026-01-13T17:19:43.006918Z","shell.execute_reply.started":"2026-01-13T17:13:33.534367Z","shell.execute_reply":"2026-01-13T17:19:43.006339Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining XGBoost Models\n================================================================================\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 1/5:   0%|          | 0/5 [00:01<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-mlogloss:1.51950\ttrain-macro_f1:0.20129\tvalid-mlogloss:1.51950\tvalid-macro_f1:0.20148\n[50]\ttrain-mlogloss:1.01235\ttrain-macro_f1:0.63319\tvalid-mlogloss:1.01237\tvalid-macro_f1:0.63343\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.633434\n  Best Iteration: 0\n  Best Score (mlogloss): 0.201484\n\n  Per-Class F1 Scores:\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 2/5:  20%|        | 1/5 [01:14<04:59, 74.82s/it, F1=0.633434]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9971    0.9794    0.9881     80062\n     Class_1     0.2147    0.1879    0.2004    160358\n     Class_2     0.7332    0.8257    0.7767    879522\n     Class_3     0.9956    0.9486    0.9715    320319\n     Class_4     0.3310    0.1767    0.2304    159739\n\n    accuracy                         0.7293   1600000\n   macro avg     0.6543    0.6237    0.6334   1600000\nweighted avg     0.7068    0.7293    0.7140   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51949\ttrain-macro_f1:0.20136\tvalid-mlogloss:1.51948\tvalid-macro_f1:0.20117\n[50]\ttrain-mlogloss:1.01241\ttrain-macro_f1:0.63326\tvalid-mlogloss:1.01224\tvalid-macro_f1:0.63322\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.633217\n  Best Iteration: 0\n  Best Score (mlogloss): 0.201174\n\n  Per-Class F1 Scores:\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 3/5:  40%|      | 2/5 [02:27<03:40, 73.49s/it, F1=0.633217]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9970    0.9793    0.9881     80062\n     Class_1     0.2287    0.1664    0.1926    160358\n     Class_2     0.7329    0.8454    0.7851    879522\n     Class_3     0.9960    0.9490    0.9719    320319\n     Class_4     0.3288    0.1749    0.2283    159739\n\n    accuracy                         0.7378   1600000\n   macro avg     0.6567    0.6230    0.6332   1600000\nweighted avg     0.7079    0.7378    0.7177   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51948\ttrain-macro_f1:0.20147\tvalid-mlogloss:1.51953\tvalid-macro_f1:0.20129\n[50]\ttrain-mlogloss:1.01217\ttrain-macro_f1:0.63317\tvalid-mlogloss:1.01301\tvalid-macro_f1:0.63293\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.632933\n  Best Iteration: 0\n  Best Score (mlogloss): 0.201289\n\n  Per-Class F1 Scores:\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 4/5:  60%|    | 3/5 [03:40<02:26, 73.47s/it, F1=0.632933]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9973    0.9796    0.9884     80063\n     Class_1     0.2101    0.1984    0.2041    160358\n     Class_2     0.7331    0.8158    0.7722    879521\n     Class_3     0.9956    0.9488    0.9716    320319\n     Class_4     0.3266    0.1755    0.2283    159739\n\n    accuracy                         0.7248   1600000\n   macro avg     0.6525    0.6236    0.6329   1600000\nweighted avg     0.7059    0.7248    0.7117   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51949\ttrain-macro_f1:0.20641\tvalid-mlogloss:1.51948\tvalid-macro_f1:0.20630\n[49]\ttrain-mlogloss:1.01526\ttrain-macro_f1:0.63329\tvalid-mlogloss:1.01540\tvalid-macro_f1:0.63292\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.632940\n  Best Iteration: 0\n  Best Score (mlogloss): 0.206298\n\n  Per-Class F1 Scores:\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 5/5:  80%|  | 4/5 [04:53<01:12, 72.98s/it, F1=0.632940]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9972    0.9808    0.9890     80063\n     Class_1     0.2132    0.1921    0.2021    160358\n     Class_2     0.7327    0.8217    0.7747    879521\n     Class_3     0.9957    0.9493    0.9719    320319\n     Class_4     0.3265    0.1740    0.2271    159739\n\n    accuracy                         0.7274   1600000\n   macro avg     0.6531    0.6236    0.6329   1600000\nweighted avg     0.7060    0.7274    0.7128   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51950\ttrain-macro_f1:0.20148\tvalid-mlogloss:1.51949\tvalid-macro_f1:0.20133\n[50]\ttrain-mlogloss:1.01230\ttrain-macro_f1:0.63278\tvalid-mlogloss:1.01230\tvalid-macro_f1:0.63225\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.632254\n  Best Iteration: 0\n  Best Score (mlogloss): 0.201330\n\n  Per-Class F1 Scores:\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 5/5: 100%|| 5/5 [06:06<00:00, 73.35s/it, F1=0.632254]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9975    0.9796    0.9885     80063\n     Class_1     0.2018    0.2129    0.2072    160358\n     Class_2     0.7330    0.8009    0.7654    879521\n     Class_3     0.9958    0.9487    0.9717    320319\n     Class_4     0.3263    0.1758    0.2285    159739\n\n    accuracy                         0.7181   1600000\n   macro avg     0.6509    0.6236    0.6323   1600000\nweighted avg     0.7050    0.7181    0.7083   1600000\n\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nXGBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.633021\nStandard Deviation: 0.000398\nMin F1 Score: 0.632254\nMax F1 Score: 0.633434\n\nFold-by-Fold Scores:\n  Fold 1: 0.633434\n  Fold 2: 0.633217\n  Fold 3: 0.632933\n  Fold 4: 0.632940\n  Fold 5: 0.632254\n\n================================================================================\nOVERALL OUT-OF-FOLD PREDICTIONS REPORT\n================================================================================\n              precision    recall  f1-score   support\n\n     Class_0     0.9972    0.9797    0.9884    400313\n     Class_1     0.2127    0.1915    0.2016    801790\n     Class_2     0.7330    0.8219    0.7749   4397607\n     Class_3     0.9958    0.9489    0.9717   1601595\n     Class_4     0.3279    0.1754    0.2285    798695\n\n    accuracy                         0.7275   8000000\n   macro avg     0.6533    0.6235    0.6330   8000000\nweighted avg     0.7062    0.7275    0.7130   8000000\n\n================================================================================\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"MODEL EVALUATION\")\nprint(\"=\"*80)\n\nif test_predictions is not None:\n    print(f\"\\n XGBoost Model Successfully Trained\")\n    print(f\"  Cross-Validation Score: {xgboost_cv_score:.6f}\")\n    print(f\"  Model Type: XGBoost with GPU acceleration\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"GENERATING PREDICTIONS ON TEST SET\")\n    print(\"=\"*80)\n\n    final_predictions = test_predictions\n    final_pred_labels = np.argmax(final_predictions, axis=1)\n\n    print(f\"\\n Predictions Generated Successfully\")\n    print(f\"  Total test samples: {len(final_pred_labels):,}\")\n    print(f\"  Prediction shape: {final_predictions.shape}\")\n    print(f\"  Classes predicted: {len(np.unique(final_pred_labels))}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"PREDICTION DISTRIBUTION\")\n    print(\"=\"*80)\n\n    unique, counts = np.unique(final_pred_labels, return_counts=True)\n    for class_idx, count in zip(unique, counts):\n        percentage = (count / len(final_pred_labels)) * 100\n        print(f\"  Class {class_idx}: {count:,} samples ({percentage:.2f}%)\")\n\nelse:\n    raise ValueError(\"XGBoost model training failed! Cannot generate predictions.\")\n\nprint(\"\\n\" + \"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:20:58.391481Z","iopub.execute_input":"2026-01-13T17:20:58.391877Z","iopub.status.idle":"2026-01-13T17:20:58.505814Z","shell.execute_reply.started":"2026-01-13T17:20:58.391849Z","shell.execute_reply":"2026-01-13T17:20:58.505156Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nMODEL EVALUATION\n================================================================================\n\n XGBoost Model Successfully Trained\n  Cross-Validation Score: 0.633021\n  Model Type: XGBoost with GPU acceleration\n\n================================================================================\nGENERATING PREDICTIONS ON TEST SET\n================================================================================\n\n Predictions Generated Successfully\n  Total test samples: 4,000,000\n  Prediction shape: (4000000, 5)\n  Classes predicted: 5\n\n================================================================================\nPREDICTION DISTRIBUTION\n================================================================================\n  Class 0: 198,096 samples (4.95%)\n  Class 1: 357,672 samples (8.94%)\n  Class 2: 2,424,532 samples (60.61%)\n  Class 3: 790,105 samples (19.75%)\n  Class 4: 229,595 samples (5.74%)\n\n================================================================================\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n    pred_labels = le_target.inverse_transform(predictions)\n    \n    submission = pd.DataFrame({\n        config.ID_COL: test_ids,\n        config.TARGET_COL: pred_labels\n    })\n    \n    submission.to_csv(filename, index=False)\n    \n    print(f\"\\nSubmission saved to: {filename}\")\n    print(f\"Submission shape: {submission.shape}\")\n    print(f\"\\nPrediction distribution:\")\n    print(submission[config.TARGET_COL].value_counts())\n    \n    return submission\n\ntest_ids = test[config.ID_COL].values\nsubmission = create_submission(test_ids, final_pred_labels, le_target, 'anava_deira_9.csv')\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:21:03.297302Z","iopub.execute_input":"2026-01-13T17:21:03.297844Z","iopub.status.idle":"2026-01-13T17:21:08.216040Z","shell.execute_reply.started":"2026-01-13T17:21:03.297818Z","shell.execute_reply":"2026-01-13T17:21:08.215311Z"}},"outputs":[{"name":"stdout","text":"\nSubmission saved to: anava_deira_9.csv\nSubmission shape: (4000000, 2)\n\nPrediction distribution:\nTrip_Label\nPerfect_Trip         2424532\nSafety_Violation      790105\nNavigation_Issue      357672\nService_Complaint     229595\nFraud_Indication      198096\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"               Trip_ID         Trip_Label\n0        TRIP-06583736       Perfect_Trip\n1        TRIP-11356251       Perfect_Trip\n2        TRIP-03320505  Service_Complaint\n3        TRIP-07188814       Perfect_Trip\n4        TRIP-06994869       Perfect_Trip\n...                ...                ...\n3999995  TRIP-02234490   Navigation_Issue\n3999996  TRIP-04304573       Perfect_Trip\n3999997  TRIP-10081352       Perfect_Trip\n3999998  TRIP-06550635       Perfect_Trip\n3999999  TRIP-06423389   Safety_Violation\n\n[4000000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Trip_ID</th>\n      <th>Trip_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRIP-06583736</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRIP-11356251</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRIP-03320505</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRIP-07188814</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRIP-06994869</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3999995</th>\n      <td>TRIP-02234490</td>\n      <td>Navigation_Issue</td>\n    </tr>\n    <tr>\n      <th>3999996</th>\n      <td>TRIP-04304573</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999997</th>\n      <td>TRIP-10081352</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999998</th>\n      <td>TRIP-06550635</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999999</th>\n      <td>TRIP-06423389</td>\n      <td>Safety_Violation</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000000 rows  2 columns</p>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"import optuna\nfrom tqdm import trange\n\ndef hyperparameter_tuning(X, y, X_test, n_trials=30):\n    def objective(trial):\n        w1 = trial.suggest_float(\"w1\", 1.0, 6.0)\n        w4 = trial.suggest_float(\"w4\", 1.0, 6.0)\n\n        max_depth = trial.suggest_int(\"max_depth\", 4, 8)\n        eta = trial.suggest_float(\"eta\", 0.02, 0.15, log=True)\n        subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n        min_child_weight = trial.suggest_float(\"min_child_weight\", 1.0, 10.0)\n\n        sample_weight = np.ones(len(y))\n        sample_weight[y == 1] = w1\n        sample_weight[y == 4] = w4\n\n        params = config.get_xgboost_params(use_gpu=gpu_config['xgboost_gpu'])\n        params.update({\n            \"max_depth\": max_depth,\n            \"eta\": eta,\n            \"subsample\": subsample,\n            \"colsample_bytree\": colsample_bytree,\n            \"min_child_weight\": min_child_weight,\n            \"num_class\": len(np.unique(y))\n        })\n\n        _, _, score = train_xgboost(\n            X,\n            y,\n            X_test,\n            use_gpu=gpu_config['xgboost_gpu'],\n            sample_weight=sample_weight,\n            override_params=params\n        )\n\n        print(\n            \"F1={:.6f} | \".format(score) +\n            \" | \".join([f\"{k}={v}\" for k, v in trial.params.items()])\n        )\n\n        return score\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"Best Params:\", study.best_params)\n    print(\"Best F1:\", study.best_value)\n\n    return study.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:46:13.068256Z","iopub.execute_input":"2026-01-13T17:46:13.068603Z","iopub.status.idle":"2026-01-13T17:46:13.987635Z","shell.execute_reply.started":"2026-01-13T17:46:13.068580Z","shell.execute_reply":"2026-01-13T17:46:13.986827Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\n\ndef train_xgboost(\n    X_train,\n    y_train,\n    X_test,\n    use_gpu=False,\n    sample_weight=None,\n    override_params=None\n):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None\n\n    # ===== PARAMS =====\n    if override_params is not None:\n        params = override_params.copy()\n    else:\n        params = config.get_xgboost_params(use_gpu=use_gpu)\n\n    params['num_class'] = len(np.unique(y_train))\n\n    # ===== SPLIT =====\n    if sample_weight is not None:\n        X_tr, X_val, y_tr, y_val, w_tr, w_val = train_test_split(\n            X_train,\n            y_train,\n            sample_weight,\n            test_size=0.2,\n            stratify=y_train,\n            random_state=config.RANDOM_STATE\n        )\n    else:\n        X_tr, X_val, y_tr, y_val = train_test_split(\n            X_train,\n            y_train,\n            test_size=0.2,\n            stratify=y_train,\n            random_state=config.RANDOM_STATE\n        )\n        w_tr = w_val = None\n\n    # ===== DMATRIX =====\n    dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n    dval = xgb.DMatrix(X_val, label=y_val, weight=w_val)\n    dtest = xgb.DMatrix(X_test)\n\n    # ===== TRAIN =====\n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=1000,\n        evals=[(dval, 'valid')],\n        custom_metric=macro_f1_eval,\n        early_stopping_rounds=50,\n        verbose_eval=False\n    )\n\n    # ===== VALID SCORE =====\n    val_preds = model.predict(dval)\n    val_labels = np.argmax(val_preds, axis=1)\n    score = f1_score(y_val, val_labels, average='macro')\n\n    # ===== TEST =====\n    test_preds = model.predict(dtest)\n\n    return test_preds, model, score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:46:53.018937Z","iopub.execute_input":"2026-01-13T17:46:53.019858Z","iopub.status.idle":"2026-01-13T17:46:53.573367Z","shell.execute_reply.started":"2026-01-13T17:46:53.019825Z","shell.execute_reply":"2026-01-13T17:46:53.572790Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"best_params = hyperparameter_tuning(X_train, y_train, X_test, n_trials=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T17:47:16.077361Z","iopub.execute_input":"2026-01-13T17:47:16.077989Z","iopub.status.idle":"2026-01-13T18:12:14.621596Z","shell.execute_reply.started":"2026-01-13T17:47:16.077934Z","shell.execute_reply":"2026-01-13T18:12:14.620734Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:47:16,079]\u001b[0m A new study created in memory with name: no-name-33e2e3b3-bdf0-4dad-b537-ea0d6574b16e\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:48:01,812]\u001b[0m Trial 0 finished with value: 0.6297697274934515 and parameters: {'w1': 4.489232692154786, 'w4': 3.3421817837598917, 'max_depth': 4, 'eta': 0.12454129916362668, 'subsample': 0.6217949553758664, 'colsample_bytree': 0.992390141665997, 'min_child_weight': 4.957760906440891}. Best is trial 0 with value: 0.6297697274934515.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.629770 | w1=4.489232692154786 | w4=3.3421817837598917 | max_depth=4 | eta=0.12454129916362668 | subsample=0.6217949553758664 | colsample_bytree=0.992390141665997 | min_child_weight=4.957760906440891\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:48:46,266]\u001b[0m Trial 1 finished with value: 0.6289767995930523 and parameters: {'w1': 4.515337948593942, 'w4': 3.052474988250123, 'max_depth': 4, 'eta': 0.06464710787634322, 'subsample': 0.6019107770034554, 'colsample_bytree': 0.7979694103068885, 'min_child_weight': 1.8980914057654275}. Best is trial 0 with value: 0.6297697274934515.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.628977 | w1=4.515337948593942 | w4=3.052474988250123 | max_depth=4 | eta=0.06464710787634322 | subsample=0.6019107770034554 | colsample_bytree=0.7979694103068885 | min_child_weight=1.8980914057654275\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:49:35,089]\u001b[0m Trial 2 finished with value: 0.6246626444047759 and parameters: {'w1': 4.340672066314238, 'w4': 2.160635706850255, 'max_depth': 7, 'eta': 0.052500692431450446, 'subsample': 0.6395026201559756, 'colsample_bytree': 0.7101955724607643, 'min_child_weight': 5.7995686213430355}. Best is trial 0 with value: 0.6297697274934515.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.624663 | w1=4.340672066314238 | w4=2.160635706850255 | max_depth=7 | eta=0.052500692431450446 | subsample=0.6395026201559756 | colsample_bytree=0.7101955724607643 | min_child_weight=5.7995686213430355\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:50:26,460]\u001b[0m Trial 3 finished with value: 0.6088907002316118 and parameters: {'w1': 5.094720879922772, 'w4': 1.3200755728433513, 'max_depth': 8, 'eta': 0.04064885861682889, 'subsample': 0.9882834626870374, 'colsample_bytree': 0.6286821825454694, 'min_child_weight': 4.631969814916518}. Best is trial 0 with value: 0.6297697274934515.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.608891 | w1=5.094720879922772 | w4=1.3200755728433513 | max_depth=8 | eta=0.04064885861682889 | subsample=0.9882834626870374 | colsample_bytree=0.6286821825454694 | min_child_weight=4.631969814916518\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:51:16,772]\u001b[0m Trial 4 finished with value: 0.6341884985218628 and parameters: {'w1': 5.11828448724458, 'w4': 4.710347234206637, 'max_depth': 7, 'eta': 0.14917133459423576, 'subsample': 0.8487521681236615, 'colsample_bytree': 0.6101253968127661, 'min_child_weight': 1.2757338320852298}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.634188 | w1=5.11828448724458 | w4=4.710347234206637 | max_depth=7 | eta=0.14917133459423576 | subsample=0.8487521681236615 | colsample_bytree=0.6101253968127661 | min_child_weight=1.2757338320852298\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:52:03,312]\u001b[0m Trial 5 finished with value: 0.6255427687737424 and parameters: {'w1': 3.1167276588724833, 'w4': 5.080253318116156, 'max_depth': 5, 'eta': 0.05828388203721841, 'subsample': 0.6049308280233519, 'colsample_bytree': 0.7355189060002807, 'min_child_weight': 8.98843650314895}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.625543 | w1=3.1167276588724833 | w4=5.080253318116156 | max_depth=5 | eta=0.05828388203721841 | subsample=0.6049308280233519 | colsample_bytree=0.7355189060002807 | min_child_weight=8.98843650314895\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:52:55,601]\u001b[0m Trial 6 finished with value: 0.5639735576152854 and parameters: {'w1': 5.7721968032947935, 'w4': 4.675692699593354, 'max_depth': 8, 'eta': 0.02924301205415152, 'subsample': 0.8199730936824162, 'colsample_bytree': 0.8501388534810002, 'min_child_weight': 8.7796472362148}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.563974 | w1=5.7721968032947935 | w4=4.675692699593354 | max_depth=8 | eta=0.02924301205415152 | subsample=0.8199730936824162 | colsample_bytree=0.8501388534810002 | min_child_weight=8.7796472362148\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:53:41,820]\u001b[0m Trial 7 finished with value: 0.6055544838907578 and parameters: {'w1': 1.845358884367628, 'w4': 3.165734069412558, 'max_depth': 5, 'eta': 0.02932366688110547, 'subsample': 0.7844728738164823, 'colsample_bytree': 0.8265717944026046, 'min_child_weight': 9.899824835276204}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.605554 | w1=1.845358884367628 | w4=3.165734069412558 | max_depth=5 | eta=0.02932366688110547 | subsample=0.7844728738164823 | colsample_bytree=0.8265717944026046 | min_child_weight=9.899824835276204\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:54:31,895]\u001b[0m Trial 8 finished with value: 0.6310327001945073 and parameters: {'w1': 4.249093014067573, 'w4': 3.6667073385874724, 'max_depth': 7, 'eta': 0.12999552906115192, 'subsample': 0.6121877319170661, 'colsample_bytree': 0.7828483939481344, 'min_child_weight': 1.0904447046464423}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631033 | w1=4.249093014067573 | w4=3.6667073385874724 | max_depth=7 | eta=0.12999552906115192 | subsample=0.6121877319170661 | colsample_bytree=0.7828483939481344 | min_child_weight=1.0904447046464423\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:55:18,761]\u001b[0m Trial 9 finished with value: 0.5038711881329802 and parameters: {'w1': 5.902796322508184, 'w4': 2.025132925834911, 'max_depth': 5, 'eta': 0.05344652236161666, 'subsample': 0.9506796328032608, 'colsample_bytree': 0.6466290548462686, 'min_child_weight': 2.669743627778355}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.503871 | w1=5.902796322508184 | w4=2.025132925834911 | max_depth=5 | eta=0.05344652236161666 | subsample=0.9506796328032608 | colsample_bytree=0.6466290548462686 | min_child_weight=2.669743627778355\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:56:09,480]\u001b[0m Trial 10 finished with value: 0.569701462314413 and parameters: {'w1': 2.972262119166113, 'w4': 5.814150631238736, 'max_depth': 7, 'eta': 0.08969339572928767, 'subsample': 0.8659500611739525, 'colsample_bytree': 0.9388815731143217, 'min_child_weight': 6.9238378855740335}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.569701 | w1=2.972262119166113 | w4=5.814150631238736 | max_depth=7 | eta=0.08969339572928767 | subsample=0.8659500611739525 | colsample_bytree=0.9388815731143217 | min_child_weight=6.9238378855740335\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:56:59,339]\u001b[0m Trial 11 finished with value: 0.6320718318023657 and parameters: {'w1': 3.769805787622463, 'w4': 4.284601074511991, 'max_depth': 7, 'eta': 0.1379192002075427, 'subsample': 0.7242003166129485, 'colsample_bytree': 0.731655924232047, 'min_child_weight': 1.0898598160036863}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632072 | w1=3.769805787622463 | w4=4.284601074511991 | max_depth=7 | eta=0.1379192002075427 | subsample=0.7242003166129485 | colsample_bytree=0.731655924232047 | min_child_weight=1.0898598160036863\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:57:47,772]\u001b[0m Trial 12 finished with value: 0.6034764407174406 and parameters: {'w1': 1.0423279617807721, 'w4': 4.287747503625092, 'max_depth': 6, 'eta': 0.14869390766501026, 'subsample': 0.7335030122894597, 'colsample_bytree': 0.6699418191653268, 'min_child_weight': 3.2720504909709587}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.603476 | w1=1.0423279617807721 | w4=4.287747503625092 | max_depth=6 | eta=0.14869390766501026 | subsample=0.7335030122894597 | colsample_bytree=0.6699418191653268 | min_child_weight=3.2720504909709587\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:58:36,728]\u001b[0m Trial 13 finished with value: 0.5840219370778793 and parameters: {'w1': 3.5419920052237233, 'w4': 5.6787748241428035, 'max_depth': 6, 'eta': 0.09336710551246093, 'subsample': 0.7315547319078749, 'colsample_bytree': 0.7108928907297869, 'min_child_weight': 3.4929602233299786}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.584022 | w1=3.5419920052237233 | w4=5.6787748241428035 | max_depth=6 | eta=0.09336710551246093 | subsample=0.7315547319078749 | colsample_bytree=0.7108928907297869 | min_child_weight=3.4929602233299786\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 17:59:27,132]\u001b[0m Trial 14 finished with value: 0.6132287107872708 and parameters: {'w1': 2.429695328505174, 'w4': 4.334746914638354, 'max_depth': 7, 'eta': 0.09584485948219532, 'subsample': 0.8753059580275463, 'colsample_bytree': 0.6017684316708457, 'min_child_weight': 1.0134404287243717}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.613229 | w1=2.429695328505174 | w4=4.334746914638354 | max_depth=7 | eta=0.09584485948219532 | subsample=0.8753059580275463 | colsample_bytree=0.6017684316708457 | min_child_weight=1.0134404287243717\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:00:19,083]\u001b[0m Trial 15 finished with value: 0.628720836795302 and parameters: {'w1': 5.077494262927358, 'w4': 5.02878055717396, 'max_depth': 8, 'eta': 0.11245167326951908, 'subsample': 0.7117424085797601, 'colsample_bytree': 0.8813901325839517, 'min_child_weight': 2.2945212997655173}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.628721 | w1=5.077494262927358 | w4=5.02878055717396 | max_depth=8 | eta=0.11245167326951908 | subsample=0.7117424085797601 | colsample_bytree=0.8813901325839517 | min_child_weight=2.2945212997655173\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:01:07,403]\u001b[0m Trial 16 finished with value: 0.6311462879131475 and parameters: {'w1': 3.7329693981030414, 'w4': 3.9281451980237767, 'max_depth': 6, 'eta': 0.07619456620186167, 'subsample': 0.8967847287768808, 'colsample_bytree': 0.7558241430819681, 'min_child_weight': 4.045437024808808}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631146 | w1=3.7329693981030414 | w4=3.9281451980237767 | max_depth=6 | eta=0.07619456620186167 | subsample=0.8967847287768808 | colsample_bytree=0.7558241430819681 | min_child_weight=4.045437024808808\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:01:58,203]\u001b[0m Trial 17 finished with value: 0.6178846630868857 and parameters: {'w1': 5.208157648158914, 'w4': 5.317464280423162, 'max_depth': 7, 'eta': 0.021844723697854826, 'subsample': 0.7937133938717962, 'colsample_bytree': 0.6893038764292385, 'min_child_weight': 6.76462666877461}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.617885 | w1=5.208157648158914 | w4=5.317464280423162 | max_depth=7 | eta=0.021844723697854826 | subsample=0.7937133938717962 | colsample_bytree=0.6893038764292385 | min_child_weight=6.76462666877461\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:02:50,244]\u001b[0m Trial 18 finished with value: 0.6328757106130907 and parameters: {'w1': 3.8796248374917135, 'w4': 4.521431526639901, 'max_depth': 8, 'eta': 0.13989276737048595, 'subsample': 0.8346776362621583, 'colsample_bytree': 0.6026350914067161, 'min_child_weight': 1.8812977824561465}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632876 | w1=3.8796248374917135 | w4=4.521431526639901 | max_depth=8 | eta=0.13989276737048595 | subsample=0.8346776362621583 | colsample_bytree=0.6026350914067161 | min_child_weight=1.8812977824561465\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:03:42,460]\u001b[0m Trial 19 finished with value: 0.6113814586736354 and parameters: {'w1': 5.428815389109895, 'w4': 2.64068759470937, 'max_depth': 8, 'eta': 0.1073700522330105, 'subsample': 0.9226742129590902, 'colsample_bytree': 0.6051881945115748, 'min_child_weight': 2.136416479527671}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.611381 | w1=5.428815389109895 | w4=2.64068759470937 | max_depth=8 | eta=0.1073700522330105 | subsample=0.9226742129590902 | colsample_bytree=0.6051881945115748 | min_child_weight=2.136416479527671\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:04:34,288]\u001b[0m Trial 20 finished with value: 0.6194486921676086 and parameters: {'w1': 2.6455107106598215, 'w4': 4.720814131722447, 'max_depth': 8, 'eta': 0.07496513471217316, 'subsample': 0.8321044840115375, 'colsample_bytree': 0.659351541841519, 'min_child_weight': 3.1570372694943636}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.619449 | w1=2.6455107106598215 | w4=4.720814131722447 | max_depth=8 | eta=0.07496513471217316 | subsample=0.8321044840115375 | colsample_bytree=0.659351541841519 | min_child_weight=3.1570372694943636\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:05:23,870]\u001b[0m Trial 21 finished with value: 0.6317157853798009 and parameters: {'w1': 4.017859123757502, 'w4': 4.128249247715729, 'max_depth': 7, 'eta': 0.14758232263185625, 'subsample': 0.7752875119066492, 'colsample_bytree': 0.6341240660818169, 'min_child_weight': 1.7552661258619136}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631716 | w1=4.017859123757502 | w4=4.128249247715729 | max_depth=7 | eta=0.14758232263185625 | subsample=0.7752875119066492 | colsample_bytree=0.6341240660818169 | min_child_weight=1.7552661258619136\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:06:14,092]\u001b[0m Trial 22 finished with value: 0.6324478721891931 and parameters: {'w1': 4.799917317706704, 'w4': 4.479333288672636, 'max_depth': 7, 'eta': 0.12378992279067709, 'subsample': 0.6834026533236668, 'colsample_bytree': 0.7450074035943371, 'min_child_weight': 1.0383912401398943}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632448 | w1=4.799917317706704 | w4=4.479333288672636 | max_depth=7 | eta=0.12378992279067709 | subsample=0.6834026533236668 | colsample_bytree=0.7450074035943371 | min_child_weight=1.0383912401398943\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:07:06,088]\u001b[0m Trial 23 finished with value: 0.6333034605611354 and parameters: {'w1': 4.7427478561465195, 'w4': 4.785572340517268, 'max_depth': 8, 'eta': 0.10914188957695009, 'subsample': 0.6849739745579614, 'colsample_bytree': 0.6805733634897837, 'min_child_weight': 1.6100286174123972}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.633303 | w1=4.7427478561465195 | w4=4.785572340517268 | max_depth=8 | eta=0.10914188957695009 | subsample=0.6849739745579614 | colsample_bytree=0.6805733634897837 | min_child_weight=1.6100286174123972\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:07:58,830]\u001b[0m Trial 24 finished with value: 0.6035968004251548 and parameters: {'w1': 4.7678449137306025, 'w4': 5.5434812264192805, 'max_depth': 8, 'eta': 0.10679428518207185, 'subsample': 0.8534838100362947, 'colsample_bytree': 0.6016661881756824, 'min_child_weight': 2.798310506716944}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.603597 | w1=4.7678449137306025 | w4=5.5434812264192805 | max_depth=8 | eta=0.10679428518207185 | subsample=0.8534838100362947 | colsample_bytree=0.6016661881756824 | min_child_weight=2.798310506716944\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:08:51,388]\u001b[0m Trial 25 finished with value: 0.6003302413289234 and parameters: {'w1': 5.449757879800522, 'w4': 5.059897110200802, 'max_depth': 8, 'eta': 0.08381061924294646, 'subsample': 0.7563575406234405, 'colsample_bytree': 0.6849474706434083, 'min_child_weight': 1.8774820212881391}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.600330 | w1=5.449757879800522 | w4=5.059897110200802 | max_depth=8 | eta=0.08381061924294646 | subsample=0.7563575406234405 | colsample_bytree=0.6849474706434083 | min_child_weight=1.8774820212881391\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:09:43,517]\u001b[0m Trial 26 finished with value: 0.6265711011611884 and parameters: {'w1': 3.3893096284210387, 'w4': 3.7263045403832, 'max_depth': 8, 'eta': 0.11740925413668445, 'subsample': 0.8282677928479628, 'colsample_bytree': 0.6360812457344771, 'min_child_weight': 3.843345148726579}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.626571 | w1=3.3893096284210387 | w4=3.7263045403832 | max_depth=8 | eta=0.11740925413668445 | subsample=0.8282677928479628 | colsample_bytree=0.6360812457344771 | min_child_weight=3.843345148726579\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:10:35,522]\u001b[0m Trial 27 finished with value: 0.6329542152473592 and parameters: {'w1': 4.125509919066976, 'w4': 4.8157166363206425, 'max_depth': 8, 'eta': 0.14990544316136173, 'subsample': 0.6626619925016584, 'colsample_bytree': 0.6677574359369572, 'min_child_weight': 2.5485444205479855}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632954 | w1=4.125509919066976 | w4=4.8157166363206425 | max_depth=8 | eta=0.14990544316136173 | subsample=0.6626619925016584 | colsample_bytree=0.6677574359369572 | min_child_weight=2.5485444205479855\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:11:25,726]\u001b[0m Trial 28 finished with value: 0.6333322129825054 and parameters: {'w1': 4.888735399706439, 'w4': 4.872760673174699, 'max_depth': 7, 'eta': 0.10205554754960605, 'subsample': 0.6653469876314761, 'colsample_bytree': 0.7710588843275792, 'min_child_weight': 5.876892547983603}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.633332 | w1=4.888735399706439 | w4=4.872760673174699 | max_depth=7 | eta=0.10205554754960605 | subsample=0.6653469876314761 | colsample_bytree=0.7710588843275792 | min_child_weight=5.876892547983603\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 18:12:14,617]\u001b[0m Trial 29 finished with value: 0.5419904378611194 and parameters: {'w1': 4.637845338910784, 'w4': 5.924073143027234, 'max_depth': 6, 'eta': 0.04411248792729391, 'subsample': 0.6710099547806788, 'colsample_bytree': 0.9938854475442027, 'min_child_weight': 5.543548811313759}. Best is trial 4 with value: 0.6341884985218628.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.541990 | w1=4.637845338910784 | w4=5.924073143027234 | max_depth=6 | eta=0.04411248792729391 | subsample=0.6710099547806788 | colsample_bytree=0.9938854475442027 | min_child_weight=5.543548811313759\nBest Params: {'w1': 5.11828448724458, 'w4': 4.710347234206637, 'max_depth': 7, 'eta': 0.14917133459423576, 'subsample': 0.8487521681236615, 'colsample_bytree': 0.6101253968127661, 'min_child_weight': 1.2757338320852298}\nBest F1: 0.6341884985218628\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\n\ndef train_xgboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None, None\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Training XGBoost Models\")\n    print(\"=\" * 80)\n\n    params = config.get_xgboost_params(use_gpu=use_gpu)\n    params[\"num_class\"] = len(np.unique(y_train))\n\n    params.update({\n        k: v for k, v in best_params.items()\n        if k not in [\"w1\", \"w4\"]\n    })\n\n    sample_weight = np.ones(len(y_train))\n    sample_weight[y_train == 1] = best_params[\"w1\"]\n    sample_weight[y_train == 4] = best_params[\"w4\"]\n\n    skf = StratifiedKFold(\n        n_splits=n_folds,\n        shuffle=True,\n        random_state=config.RANDOM_STATE\n    )\n\n    oof_predictions = np.zeros((len(X_train), params[\"num_class\"]))\n    test_predictions = np.zeros((len(X_test), params[\"num_class\"]))\n\n    fold_scores = []\n    models = []\n\n    pbar = tqdm(\n        enumerate(skf.split(X_train, y_train), 1),\n        total=n_folds,\n        desc=\"XGBoost Folds\"\n    )\n\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\n        dtrain = xgb.DMatrix(\n            X_tr,\n            label=y_tr,\n            weight=sample_weight[train_idx]\n        )\n        dval = xgb.DMatrix(\n            X_val,\n            label=y_val,\n            weight=sample_weight[val_idx]\n        )\n        dtest = xgb.DMatrix(X_test)\n\n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            evals=[(dtrain, \"train\"), (dval, \"valid\")],\n            custom_metric=macro_f1_eval,\n            early_stopping_rounds=50,\n            verbose_eval=100\n        )\n\n        oof_predictions[val_idx] = model.predict(dval)\n        test_predictions += model.predict(dtest) / n_folds\n\n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average=\"macro\")\n        fold_scores.append(fold_score)\n\n        print(\"\\n\" + \"=\" * 60)\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(\"=\" * 60)\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.best_iteration}\")\n        print(f\"  Best Score (mlogloss): {model.best_score:.6f}\")\n\n        print(\n            classification_report(\n                y_val,\n                oof_pred_labels,\n                target_names=[\n                    f\"Class_{i}\"\n                    for i in range(params[\"num_class\"])\n                ],\n                digits=4\n            )\n        )\n        print(\"=\" * 60 + \"\\n\")\n\n        pbar.set_postfix({\"F1\": f\"{fold_score:.6f}\"})\n\n        models.append(model)\n        gc.collect()\n\n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average=\"macro\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"XGBOOST TRAINING SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n\n    return oof_predictions, test_predictions, models, overall_score\n\n\nif XGBOOST_AVAILABLE:\n    oof_predictions, test_predictions, xgboost_models, xgboost_cv_score = train_xgboost(\n        X_train,\n        y_train,\n        X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config[\"xgboost_gpu\"]\n    )\nelse:\n    oof_predictions, test_predictions, xgboost_models, xgboost_cv_score = None, None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T18:15:54.991980Z","iopub.execute_input":"2026-01-13T18:15:54.992733Z","iopub.status.idle":"2026-01-13T18:22:11.171055Z","shell.execute_reply.started":"2026-01-13T18:15:54.992703Z","shell.execute_reply":"2026-01-13T18:22:11.170359Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining XGBoost Models\n================================================================================\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 1/5:   0%|          | 0/5 [00:01<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-mlogloss:1.52005\ttrain-macro_f1:0.20203\tvalid-mlogloss:1.52005\tvalid-macro_f1:0.20241\n[49]\ttrain-mlogloss:1.01544\ttrain-macro_f1:0.63411\tvalid-mlogloss:1.01555\tvalid-macro_f1:0.63396\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.634002\n  Best Iteration: 0\n  Best Score (mlogloss): 0.202409\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 1/5:  20%|        | 1/5 [01:16<05:05, 76.34s/it, F1=0.634002]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9982    0.9782    0.9881     80062\n     Class_1     0.2245    0.1691    0.1929    160358\n     Class_2     0.7340    0.8337    0.7807    879522\n     Class_3     0.9968    0.9488    0.9722    320319\n     Class_4     0.3127    0.1896    0.2361    159739\n\n    accuracy                         0.7331   1600000\n   macro avg     0.6533    0.6239    0.6340   1600000\nweighted avg     0.7067    0.7331    0.7161   1600000\n\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 2/5:  20%|        | 1/5 [01:16<05:05, 76.34s/it, F1=0.634002]","output_type":"stream"},{"name":"stdout","text":"[0]\ttrain-mlogloss:1.52007\ttrain-macro_f1:0.20211\tvalid-mlogloss:1.52006\tvalid-macro_f1:0.20195\n[50]\ttrain-mlogloss:1.01243\ttrain-macro_f1:0.63412\tvalid-mlogloss:1.01235\tvalid-macro_f1:0.63414\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.634144\n  Best Iteration: 0\n  Best Score (mlogloss): 0.201949\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 3/5:  40%|      | 2/5 [02:31<03:47, 75.75s/it, F1=0.634144]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9983    0.9784    0.9883     80062\n     Class_1     0.2288    0.1672    0.1932    160358\n     Class_2     0.7338    0.8386    0.7827    879522\n     Class_3     0.9971    0.9491    0.9725    320319\n     Class_4     0.3150    0.1861    0.2340    159739\n\n    accuracy                         0.7353   1600000\n   macro avg     0.6546    0.6239    0.6341   1600000\nweighted avg     0.7073    0.7353    0.7171   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.52004\ttrain-macro_f1:0.20744\tvalid-mlogloss:1.52009\tvalid-macro_f1:0.20710\n[49]\ttrain-mlogloss:1.01534\ttrain-macro_f1:0.63407\tvalid-mlogloss:1.01620\tvalid-macro_f1:0.63362\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.633639\n  Best Iteration: 0\n  Best Score (mlogloss): 0.207096\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 4/5:  60%|    | 3/5 [03:46<02:30, 75.31s/it, F1=0.633639]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9985    0.9781    0.9882     80063\n     Class_1     0.2365    0.1548    0.1871    160358\n     Class_2     0.7339    0.8458    0.7859    879521\n     Class_3     0.9968    0.9490    0.9723    320319\n     Class_4     0.3084    0.1894    0.2346    159739\n\n    accuracy                         0.7383   1600000\n   macro avg     0.6548    0.6234    0.6336   1600000\nweighted avg     0.7074    0.7383    0.7183   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.52005\ttrain-macro_f1:0.20743\tvalid-mlogloss:1.52005\tvalid-macro_f1:0.20726\n[50]\ttrain-mlogloss:1.01230\ttrain-macro_f1:0.63431\tvalid-mlogloss:1.01246\tvalid-macro_f1:0.63381\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.633806\n  Best Iteration: 0\n  Best Score (mlogloss): 0.207263\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 5/5:  80%|  | 4/5 [04:59<01:14, 74.53s/it, F1=0.633806]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9986    0.9796    0.9890     80063\n     Class_1     0.2281    0.1663    0.1924    160358\n     Class_2     0.7338    0.8351    0.7812    879521\n     Class_3     0.9970    0.9497    0.9728    320319\n     Class_4     0.3065    0.1888    0.2337    159739\n\n    accuracy                         0.7337   1600000\n   macro avg     0.6528    0.6239    0.6338   1600000\nweighted avg     0.7064    0.7337    0.7163   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.52006\ttrain-macro_f1:0.20204\tvalid-mlogloss:1.52006\tvalid-macro_f1:0.20206\n[50]\ttrain-mlogloss:1.01236\ttrain-macro_f1:0.63431\tvalid-mlogloss:1.01247\tvalid-macro_f1:0.63396\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.633957\n  Best Iteration: 0\n  Best Score (mlogloss): 0.202062\n","output_type":"stream"},{"name":"stderr","text":"XGBoost Fold 5/5: 100%|| 5/5 [06:15<00:00, 75.01s/it, F1=0.633957]","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n     Class_0     0.9985    0.9782    0.9883     80063\n     Class_1     0.2268    0.1682    0.1932    160358\n     Class_2     0.7342    0.8326    0.7803    879521\n     Class_3     0.9969    0.9492    0.9725    320319\n     Class_4     0.3057    0.1916    0.2356    159739\n\n    accuracy                         0.7327   1600000\n   macro avg     0.6524    0.6240    0.6340   1600000\nweighted avg     0.7064    0.7327    0.7159   1600000\n\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nXGBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.633920\nStandard Deviation: 0.000173\nMin F1 Score: 0.633639\nMax F1 Score: 0.634144\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"MODEL EVALUATION\")\nprint(\"=\"*80)\n\nif test_predictions is not None:\n    print(\"\\n XGBoost Model Successfully Trained\")\n    print(f\"  Cross-Validation Score: {xgboost_cv_score:.6f}\")\n    print(f\"  Model Type: XGBoost with GPU acceleration\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"GENERATING PREDICTIONS ON TEST SET\")\n    print(\"=\"*80)\n\n    final_predictions = test_predictions\n    final_pred_labels = np.argmax(final_predictions, axis=1)\n\n    print(\"\\n Predictions Generated Successfully\")\n    print(f\"  Total test samples: {len(final_pred_labels):,}\")\n    print(f\"  Prediction shape: {final_predictions.shape}\")\n    print(f\"  Classes predicted: {len(np.unique(final_pred_labels))}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"PREDICTION DISTRIBUTION\")\n    print(\"=\"*80)\n\n    unique, counts = np.unique(final_pred_labels, return_counts=True)\n    for class_idx, count in zip(unique, counts):\n        percentage = (count / len(final_pred_labels)) * 100\n        print(f\"  Class {class_idx}: {count:,} samples ({percentage:.2f}%)\")\nelse:\n    raise ValueError(\"XGBoost model training failed! Cannot generate predictions.\")\n\nprint(\"\\n\" + \"=\"*80)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T18:22:29.101406Z","iopub.execute_input":"2026-01-13T18:22:29.101706Z","iopub.status.idle":"2026-01-13T18:22:29.216522Z","shell.execute_reply.started":"2026-01-13T18:22:29.101684Z","shell.execute_reply":"2026-01-13T18:22:29.215693Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nMODEL EVALUATION\n================================================================================\n\n XGBoost Model Successfully Trained\n  Cross-Validation Score: 0.633920\n  Model Type: XGBoost with GPU acceleration\n\n================================================================================\nGENERATING PREDICTIONS ON TEST SET\n================================================================================\n\n Predictions Generated Successfully\n  Total test samples: 4,000,000\n  Prediction shape: (4000000, 5)\n  Classes predicted: 5\n\n================================================================================\nPREDICTION DISTRIBUTION\n================================================================================\n  Class 0: 197,396 samples (4.93%)\n  Class 1: 290,656 samples (7.27%)\n  Class 2: 2,458,818 samples (61.47%)\n  Class 3: 789,524 samples (19.74%)\n  Class 4: 263,606 samples (6.59%)\n\n================================================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n    pred_labels = le_target.inverse_transform(predictions)\n    \n    submission = pd.DataFrame({\n        config.ID_COL: test_ids,\n        config.TARGET_COL: pred_labels\n    })\n    \n    submission.to_csv(filename, index=False)\n    \n    print(f\"\\nSubmission saved to: {filename}\")\n    print(f\"Submission shape: {submission.shape}\")\n    print(f\"\\nPrediction distribution:\")\n    print(submission[config.TARGET_COL].value_counts())\n    \n    return submission\n\ntest_ids = test[config.ID_COL].values\nsubmission = create_submission(test_ids, final_pred_labels, le_target, 'anava_deira_10.csv')\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T18:22:57.345125Z","iopub.execute_input":"2026-01-13T18:22:57.345626Z","iopub.status.idle":"2026-01-13T18:23:02.147384Z","shell.execute_reply.started":"2026-01-13T18:22:57.345596Z","shell.execute_reply":"2026-01-13T18:23:02.146545Z"}},"outputs":[{"name":"stdout","text":"\nSubmission saved to: anava_deira_10.csv\nSubmission shape: (4000000, 2)\n\nPrediction distribution:\nTrip_Label\nPerfect_Trip         2458818\nSafety_Violation      789524\nNavigation_Issue      290656\nService_Complaint     263606\nFraud_Indication      197396\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"               Trip_ID         Trip_Label\n0        TRIP-06583736       Perfect_Trip\n1        TRIP-11356251       Perfect_Trip\n2        TRIP-03320505  Service_Complaint\n3        TRIP-07188814       Perfect_Trip\n4        TRIP-06994869       Perfect_Trip\n...                ...                ...\n3999995  TRIP-02234490   Navigation_Issue\n3999996  TRIP-04304573       Perfect_Trip\n3999997  TRIP-10081352       Perfect_Trip\n3999998  TRIP-06550635       Perfect_Trip\n3999999  TRIP-06423389   Safety_Violation\n\n[4000000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Trip_ID</th>\n      <th>Trip_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRIP-06583736</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRIP-11356251</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRIP-03320505</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRIP-07188814</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRIP-06994869</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3999995</th>\n      <td>TRIP-02234490</td>\n      <td>Navigation_Issue</td>\n    </tr>\n    <tr>\n      <th>3999996</th>\n      <td>TRIP-04304573</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999997</th>\n      <td>TRIP-10081352</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999998</th>\n      <td>TRIP-06550635</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999999</th>\n      <td>TRIP-06423389</td>\n      <td>Safety_Violation</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000000 rows  2 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"# add null_count","metadata":{}},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\ndef train_xgboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"Training XGBoost Models\")\n    print(\"=\"*80)\n    \n    params = config.get_xgboost_params(use_gpu=use_gpu)\n    params['num_class'] = len(np.unique(y_train))\n    \n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n    \n    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n    \n    fold_scores = []\n    models = []\n    \n    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"XGBoost Folds\")\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n        \n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n        \n        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n        dval = xgb.DMatrix(X_val, label=y_val)\n        dtest = xgb.DMatrix(X_test)\n        \n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            evals=[(dtrain, 'train'), (dval, 'valid')],\n            custom_metric=macro_f1_eval,\n            early_stopping_rounds=50,\n            verbose_eval=100\n        )\n        \n        oof_predictions[val_idx] = model.predict(dval)\n        test_predictions += model.predict(dtest) / n_folds\n        \n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n\n        print(f\"\\n{'='*60}\")\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(f\"{'='*60}\")\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.best_iteration}\")\n        print(f\"  Best Score (mlogloss): {model.best_score:.6f}\")\n        \n        # Detailed classification report\n        oof_fold_pred = np.argmax(oof_predictions[val_idx], axis=1)\n        print(f\"\\n  Per-Class F1 Scores:\")\n        from sklearn.metrics import classification_report\n        print(classification_report(y_val, oof_fold_pred, \n                                   target_names=[f\"Class_{i}\" for i in range(len(np.unique(y_train)))],\n                                   digits=4))\n        print(f\"{'='*60}\\n\")\n        \n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n        \n        models.append(model)\n        gc.collect()\n    \n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n    \n        \n    print(\"\\n\" + \"=\"*80)\n    print(\"XGBOOST TRAINING SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n    print(f\"\\nFold-by-Fold Scores:\")\n    for i, score in enumerate(fold_scores, 1):\n        print(f\"  Fold {i}: {score:.6f}\")\n    \n    # Overall classification report pada OOF predictions\n    print(f\"\\n\" + \"=\"*80)\n    print(\"OVERALL OUT-OF-FOLD PREDICTIONS REPORT\")\n    print(\"=\"*80)\n    print(classification_report(y_train, oof_pred_labels, \n                               target_names=[f\"Class_{i}\" for i in range(len(np.unique(y_train)))],\n                               digits=4))\n    print(\"=\"*80)\n\n    return test_predictions, models, overall_score\n\n\nif XGBOOST_AVAILABLE:\n    xgboost_test_pred, xgboost_models, xgboost_cv_score = train_xgboost(\n        X_train, y_train, X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config['xgboost_gpu']\n    )\nelse:\n    xgboost_test_pred, xgboost_models, xgboost_cv_score = None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T19:08:44.241296Z","iopub.execute_input":"2026-01-13T19:08:44.241554Z","iopub.status.idle":"2026-01-13T19:14:57.556676Z","shell.execute_reply.started":"2026-01-13T19:08:44.241518Z","shell.execute_reply":"2026-01-13T19:14:57.556121Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining XGBoost Models\n================================================================================\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"XGBoost Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"061b0aa721224b36ace9b6c2470d6247"}},"metadata":{}},{"name":"stdout","text":"[0]\ttrain-mlogloss:1.40426\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40428\tvalid-macro_f1:0.14189\n[49]\ttrain-mlogloss:0.67870\ttrain-macro_f1:0.57613\tvalid-mlogloss:0.67905\tvalid-macro_f1:0.57609\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576105\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9966    0.9787    0.9876     80062\n     Class_1     1.0000    0.0039    0.0078    160358\n     Class_2     0.7258    0.9949    0.8393    879522\n     Class_3     0.9963    0.9486    0.9719    320319\n     Class_4     0.6212    0.0393    0.0739    159739\n\n    accuracy                         0.7901   1600000\n   macro avg     0.8680    0.5931    0.5761   1600000\nweighted avg     0.8106    0.7901    0.7135   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40427\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40427\tvalid-macro_f1:0.14189\n[50]\ttrain-mlogloss:0.67572\ttrain-macro_f1:0.57618\tvalid-mlogloss:0.67565\tvalid-macro_f1:0.57611\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576106\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9967    0.9789    0.9877     80062\n     Class_1     1.0000    0.0040    0.0080    160358\n     Class_2     0.7258    0.9950    0.8393    879522\n     Class_3     0.9968    0.9489    0.9723    320319\n     Class_4     0.6149    0.0390    0.0733    159739\n\n    accuracy                         0.7902   1600000\n   macro avg     0.8668    0.5931    0.5761   1600000\nweighted avg     0.8100    0.7902    0.7136   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40426\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40428\tvalid-macro_f1:0.14189\n[49]\ttrain-mlogloss:0.67861\ttrain-macro_f1:0.57615\tvalid-mlogloss:0.67911\tvalid-macro_f1:0.57577\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.575876\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9968    0.9786    0.9876     80063\n     Class_1     1.0000    0.0041    0.0081    160358\n     Class_2     0.7258    0.9950    0.8393    879521\n     Class_3     0.9967    0.9490    0.9722    320319\n     Class_4     0.6132    0.0383    0.0721    159739\n\n    accuracy                         0.7901   1600000\n   macro avg     0.8665    0.5930    0.5759   1600000\nweighted avg     0.8098    0.7901    0.7135   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40429\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40426\tvalid-macro_f1:0.14189\n[50]\ttrain-mlogloss:0.67569\ttrain-macro_f1:0.57617\tvalid-mlogloss:0.67533\tvalid-macro_f1:0.57624\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576237\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9967    0.9802    0.9884     80063\n     Class_1     1.0000    0.0042    0.0083    160358\n     Class_2     0.7260    0.9950    0.8395    879521\n     Class_3     0.9966    0.9494    0.9724    320319\n     Class_4     0.6135    0.0385    0.0725    159739\n\n    accuracy                         0.7903   1600000\n   macro avg     0.8666    0.5935    0.5762   1600000\nweighted avg     0.8100    0.7903    0.7137   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40428\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40427\tvalid-macro_f1:0.14189\n[50]\ttrain-mlogloss:0.67563\ttrain-macro_f1:0.57610\tvalid-mlogloss:0.67561\tvalid-macro_f1:0.57646\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576455\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9969    0.9789    0.9878     80063\n     Class_1     1.0000    0.0044    0.0088    160358\n     Class_2     0.7259    0.9950    0.8394    879521\n     Class_3     0.9968    0.9487    0.9722    320319\n     Class_4     0.6173    0.0394    0.0741    159739\n\n    accuracy                         0.7903   1600000\n   macro avg     0.8674    0.5933    0.5765   1600000\nweighted avg     0.8103    0.7903    0.7138   1600000\n\n============================================================\n\n\n================================================================================\nXGBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.576156\nStandard Deviation: 0.000190\nMin F1 Score: 0.575876\nMax F1 Score: 0.576455\n\nFold-by-Fold Scores:\n  Fold 1: 0.576105\n  Fold 2: 0.576106\n  Fold 3: 0.575876\n  Fold 4: 0.576237\n  Fold 5: 0.576455\n\n================================================================================\nOVERALL OUT-OF-FOLD PREDICTIONS REPORT\n================================================================================\n              precision    recall  f1-score   support\n\n     Class_0     0.9967    0.9791    0.9878    400313\n     Class_1     1.0000    0.0041    0.0082    801790\n     Class_2     0.7259    0.9950    0.8394   4397607\n     Class_3     0.9966    0.9489    0.9722   1601595\n     Class_4     0.6161    0.0389    0.0732    798695\n\n    accuracy                         0.7902   8000000\n   macro avg     0.8671    0.5932    0.5762   8000000\nweighted avg     0.8101    0.7902    0.7136   8000000\n\n================================================================================\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\ndef train_xgboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"Training XGBoost Models\")\n    print(\"=\"*80)\n    \n    params = config.get_xgboost_params(use_gpu=use_gpu)\n    params['num_class'] = len(np.unique(y_train))\n    \n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n    \n    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n    \n    fold_scores = []\n    models = []\n    \n    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"XGBoost Folds\")\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n        \n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n        \n        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n        dval = xgb.DMatrix(X_val, label=y_val)\n        dtest = xgb.DMatrix(X_test)\n        \n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            evals=[(dtrain, 'train'), (dval, 'valid')],\n            custom_metric=macro_f1_eval,\n            early_stopping_rounds=50,\n            verbose_eval=100\n        )\n        \n        oof_predictions[val_idx] = model.predict(dval)\n        test_predictions += model.predict(dtest) / n_folds\n        \n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n\n        print(f\"\\n{'='*60}\")\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(f\"{'='*60}\")\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.best_iteration}\")\n        print(f\"  Best Score (mlogloss): {model.best_score:.6f}\")\n        \n        # Detailed classification report\n        oof_fold_pred = np.argmax(oof_predictions[val_idx], axis=1)\n        print(f\"\\n  Per-Class F1 Scores:\")\n        from sklearn.metrics import classification_report\n        print(classification_report(y_val, oof_fold_pred, \n                                   target_names=[f\"Class_{i}\" for i in range(len(np.unique(y_train)))],\n                                   digits=4))\n        print(f\"{'='*60}\\n\")\n        \n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n        \n        models.append(model)\n        gc.collect()\n    \n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n    \n        \n    print(\"\\n\" + \"=\"*80)\n    print(\"XGBOOST TRAINING SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n    print(f\"\\nFold-by-Fold Scores:\")\n    for i, score in enumerate(fold_scores, 1):\n        print(f\"  Fold {i}: {score:.6f}\")\n    \n    # Overall classification report pada OOF predictions\n    print(f\"\\n\" + \"=\"*80)\n    print(\"OVERALL OUT-OF-FOLD PREDICTIONS REPORT\")\n    print(\"=\"*80)\n    print(classification_report(y_train, oof_pred_labels, \n                               target_names=[f\"Class_{i}\" for i in range(len(np.unique(y_train)))],\n                               digits=4))\n    print(\"=\"*80)\n\n    return test_predictions, models, overall_score\n\n\nif XGBOOST_AVAILABLE:\n    xgboost_test_pred, xgboost_models, xgboost_cv_score = train_xgboost(\n        X_train, y_train, X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config['xgboost_gpu']\n    )\nelse:\n    xgboost_test_pred, xgboost_models, xgboost_cv_score = None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T22:07:47.632306Z","iopub.execute_input":"2026-01-13T22:07:47.632628Z","iopub.status.idle":"2026-01-13T22:14:00.503194Z","shell.execute_reply.started":"2026-01-13T22:07:47.632608Z","shell.execute_reply":"2026-01-13T22:14:00.502612Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining XGBoost Models\n================================================================================\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"XGBoost Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8aee9dd6078e4802a82e34a1c009e1a8"}},"metadata":{}},{"name":"stdout","text":"[0]\ttrain-mlogloss:1.40426\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40428\tvalid-macro_f1:0.14189\n[49]\ttrain-mlogloss:0.67856\ttrain-macro_f1:0.57618\tvalid-mlogloss:0.67890\tvalid-macro_f1:0.57614\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576146\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9967    0.9787    0.9876     80062\n     Class_1     1.0000    0.0039    0.0078    160358\n     Class_2     0.7258    0.9950    0.8394    879522\n     Class_3     0.9968    0.9486    0.9721    320319\n     Class_4     0.6207    0.0393    0.0739    159739\n\n    accuracy                         0.7902   1600000\n   macro avg     0.8680    0.5931    0.5761   1600000\nweighted avg     0.8106    0.7902    0.7136   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40427\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40427\tvalid-macro_f1:0.14189\n[50]\ttrain-mlogloss:0.67562\ttrain-macro_f1:0.57620\tvalid-mlogloss:0.67554\tvalid-macro_f1:0.57613\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576130\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9970    0.9786    0.9877     80062\n     Class_1     1.0000    0.0040    0.0080    160358\n     Class_2     0.7258    0.9950    0.8393    879522\n     Class_3     0.9970    0.9488    0.9723    320319\n     Class_4     0.6143    0.0390    0.0734    159739\n\n    accuracy                         0.7902   1600000\n   macro avg     0.8668    0.5931    0.5761   1600000\nweighted avg     0.8100    0.7902    0.7136   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40427\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40428\tvalid-macro_f1:0.14189\n[50]\ttrain-mlogloss:0.67536\ttrain-macro_f1:0.57616\tvalid-mlogloss:0.67585\tvalid-macro_f1:0.57578\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.575775\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9966    0.9784    0.9874     80063\n     Class_1     1.0000    0.0041    0.0081    160358\n     Class_2     0.7258    0.9951    0.8393    879521\n     Class_3     0.9967    0.9489    0.9722    320319\n     Class_4     0.6152    0.0381    0.0718    159739\n\n    accuracy                         0.7901   1600000\n   macro avg     0.8669    0.5929    0.5758   1600000\nweighted avg     0.8100    0.7901    0.7134   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40429\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40426\tvalid-macro_f1:0.14189\n[50]\ttrain-mlogloss:0.67558\ttrain-macro_f1:0.57617\tvalid-mlogloss:0.67522\tvalid-macro_f1:0.57623\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576231\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9970    0.9797    0.9883     80063\n     Class_1     1.0000    0.0042    0.0083    160358\n     Class_2     0.7260    0.9951    0.8395    879521\n     Class_3     0.9969    0.9492    0.9725    320319\n     Class_4     0.6130    0.0386    0.0726    159739\n\n    accuracy                         0.7903   1600000\n   macro avg     0.8666    0.5934    0.5762   1600000\nweighted avg     0.8100    0.7903    0.7137   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.40428\ttrain-macro_f1:0.14189\tvalid-mlogloss:1.40428\tvalid-macro_f1:0.14189\n[49]\ttrain-mlogloss:0.67870\ttrain-macro_f1:0.57607\tvalid-mlogloss:0.67869\tvalid-macro_f1:0.57641\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.576449\n  Best Iteration: 0\n  Best Score (mlogloss): 0.141886\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9967    0.9787    0.9876     80063\n     Class_1     1.0000    0.0044    0.0088    160358\n     Class_2     0.7259    0.9951    0.8394    879521\n     Class_3     0.9970    0.9486    0.9722    320319\n     Class_4     0.6178    0.0395    0.0742    159739\n\n    accuracy                         0.7903   1600000\n   macro avg     0.8675    0.5933    0.5764   1600000\nweighted avg     0.8104    0.7903    0.7138   1600000\n\n============================================================\n\n\n================================================================================\nXGBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.576146\nStandard Deviation: 0.000218\nMin F1 Score: 0.575775\nMax F1 Score: 0.576449\n\nFold-by-Fold Scores:\n  Fold 1: 0.576146\n  Fold 2: 0.576130\n  Fold 3: 0.575775\n  Fold 4: 0.576231\n  Fold 5: 0.576449\n\n================================================================================\nOVERALL OUT-OF-FOLD PREDICTIONS REPORT\n================================================================================\n              precision    recall  f1-score   support\n\n     Class_0     0.9968    0.9788    0.9877    400313\n     Class_1     1.0000    0.0041    0.0082    801790\n     Class_2     0.7258    0.9951    0.8394   4397607\n     Class_3     0.9969    0.9488    0.9723   1601595\n     Class_4     0.6162    0.0389    0.0732    798695\n\n    accuracy                         0.7902   8000000\n   macro avg     0.8671    0.5931    0.5761   8000000\nweighted avg     0.8102    0.7902    0.7136   8000000\n\n================================================================================\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import optuna\nfrom tqdm import trange\n\ndef hyperparameter_tuning(X, y, X_test, n_trials=30):\n    def objective(trial):\n        w1 = trial.suggest_float(\"w1\", 1.0, 6.0)\n        w4 = trial.suggest_float(\"w4\", 1.0, 6.0)\n\n        max_depth = trial.suggest_int(\"max_depth\", 4, 8)\n        eta = trial.suggest_float(\"eta\", 0.02, 0.15, log=True)\n        subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n        min_child_weight = trial.suggest_float(\"min_child_weight\", 1.0, 10.0)\n\n        sample_weight = np.ones(len(y))\n        sample_weight[y == 1] = w1\n        sample_weight[y == 4] = w4\n\n        params = config.get_xgboost_params(use_gpu=gpu_config['xgboost_gpu'])\n        params.update({\n            \"max_depth\": max_depth,\n            \"eta\": eta,\n            \"subsample\": subsample,\n            \"colsample_bytree\": colsample_bytree,\n            \"min_child_weight\": min_child_weight,\n            \"num_class\": len(np.unique(y))\n        })\n\n        _, _, score = train_xgboost(\n            X,\n            y,\n            X_test,\n            use_gpu=gpu_config['xgboost_gpu'],\n            sample_weight=sample_weight,\n            override_params=params\n        )\n\n        print(\n            \"F1={:.6f} | \".format(score) +\n            \" | \".join([f\"{k}={v}\" for k, v in trial.params.items()])\n        )\n\n        return score\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"Best Params:\", study.best_params)\n    print(\"Best F1:\", study.best_value)\n\n    return study.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T22:14:16.215108Z","iopub.execute_input":"2026-01-13T22:14:16.215407Z","iopub.status.idle":"2026-01-13T22:14:16.222922Z","shell.execute_reply.started":"2026-01-13T22:14:16.215381Z","shell.execute_reply":"2026-01-13T22:14:16.222172Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\n\ndef train_xgboost(\n    X_train,\n    y_train,\n    X_test,\n    use_gpu=False,\n    sample_weight=None,\n    override_params=None\n):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None\n\n    # ===== PARAMS =====\n    if override_params is not None:\n        params = override_params.copy()\n    else:\n        params = config.get_xgboost_params(use_gpu=use_gpu)\n\n    params['num_class'] = len(np.unique(y_train))\n\n    # ===== SPLIT =====\n    if sample_weight is not None:\n        X_tr, X_val, y_tr, y_val, w_tr, w_val = train_test_split(\n            X_train,\n            y_train,\n            sample_weight,\n            test_size=0.2,\n            stratify=y_train,\n            random_state=config.RANDOM_STATE\n        )\n    else:\n        X_tr, X_val, y_tr, y_val = train_test_split(\n            X_train,\n            y_train,\n            test_size=0.2,\n            stratify=y_train,\n            random_state=config.RANDOM_STATE\n        )\n        w_tr = w_val = None\n\n    # ===== DMATRIX =====\n    dtrain = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n    dval = xgb.DMatrix(X_val, label=y_val, weight=w_val)\n    dtest = xgb.DMatrix(X_test)\n\n    # ===== TRAIN =====\n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=1000,\n        evals=[(dval, 'valid')],\n        custom_metric=macro_f1_eval,\n        early_stopping_rounds=50,\n        verbose_eval=False\n    )\n\n    # ===== VALID SCORE =====\n    val_preds = model.predict(dval)\n    val_labels = np.argmax(val_preds, axis=1)\n    score = f1_score(y_val, val_labels, average='macro')\n\n    # ===== TEST =====\n    test_preds = model.predict(dtest)\n\n    return test_preds, model, score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T22:14:18.599162Z","iopub.execute_input":"2026-01-13T22:14:18.599856Z","iopub.status.idle":"2026-01-13T22:14:18.607276Z","shell.execute_reply.started":"2026-01-13T22:14:18.599828Z","shell.execute_reply":"2026-01-13T22:14:18.606631Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"best_params = hyperparameter_tuning(X_train, y_train, X_test, n_trials=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T22:15:20.904418Z","iopub.execute_input":"2026-01-13T22:15:20.904724Z","iopub.status.idle":"2026-01-13T22:58:11.278458Z","shell.execute_reply.started":"2026-01-13T22:15:20.904698Z","shell.execute_reply":"2026-01-13T22:58:11.277774Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:15:20,905]\u001b[0m A new study created in memory with name: no-name-15fe8728-2271-4d59-857b-33d598ef369d\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:16:09,909]\u001b[0m Trial 0 finished with value: 0.6310361917783958 and parameters: {'w1': 3.2634612952353637, 'w4': 4.504920105872557, 'max_depth': 4, 'eta': 0.1493074963196003, 'subsample': 0.7299641417876529, 'colsample_bytree': 0.9043154815585304, 'min_child_weight': 9.6461653118132}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631036 | w1=3.2634612952353637 | w4=4.504920105872557 | max_depth=4 | eta=0.1493074963196003 | subsample=0.7299641417876529 | colsample_bytree=0.9043154815585304 | min_child_weight=9.6461653118132\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:17:02,952]\u001b[0m Trial 1 finished with value: 0.6027736028402632 and parameters: {'w1': 1.166506394404956, 'w4': 3.5812803934614603, 'max_depth': 7, 'eta': 0.0920367449628818, 'subsample': 0.6683530682518063, 'colsample_bytree': 0.9989251940166395, 'min_child_weight': 2.2649097720211886}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.602774 | w1=1.166506394404956 | w4=3.5812803934614603 | max_depth=7 | eta=0.0920367449628818 | subsample=0.6683530682518063 | colsample_bytree=0.9989251940166395 | min_child_weight=2.2649097720211886\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:17:55,412]\u001b[0m Trial 2 finished with value: 0.5235128778120128 and parameters: {'w1': 5.870076128304332, 'w4': 5.665509710095495, 'max_depth': 6, 'eta': 0.13447219862263976, 'subsample': 0.6098291916970305, 'colsample_bytree': 0.9949096266819522, 'min_child_weight': 5.927271110840055}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.523513 | w1=5.870076128304332 | w4=5.665509710095495 | max_depth=6 | eta=0.13447219862263976 | subsample=0.6098291916970305 | colsample_bytree=0.9949096266819522 | min_child_weight=5.927271110840055\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:18:47,896]\u001b[0m Trial 3 finished with value: 0.522840179366597 and parameters: {'w1': 2.032388967379236, 'w4': 5.927771512250932, 'max_depth': 6, 'eta': 0.06565689638131818, 'subsample': 0.9037141447742103, 'colsample_bytree': 0.7791775366318417, 'min_child_weight': 6.115180089793013}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.522840 | w1=2.032388967379236 | w4=5.927771512250932 | max_depth=6 | eta=0.06565689638131818 | subsample=0.9037141447742103 | colsample_bytree=0.7791775366318417 | min_child_weight=6.115180089793013\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:19:43,511]\u001b[0m Trial 4 finished with value: 0.6264216370644266 and parameters: {'w1': 3.7123570375626875, 'w4': 2.806912264307962, 'max_depth': 8, 'eta': 0.035842141854274596, 'subsample': 0.6107647653148798, 'colsample_bytree': 0.6779056163953048, 'min_child_weight': 9.385214564182935}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.626422 | w1=3.7123570375626875 | w4=2.806912264307962 | max_depth=8 | eta=0.035842141854274596 | subsample=0.6107647653148798 | colsample_bytree=0.6779056163953048 | min_child_weight=9.385214564182935\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:20:39,214]\u001b[0m Trial 5 finished with value: 0.5365236313609479 and parameters: {'w1': 5.966281361913346, 'w4': 1.7773803559167924, 'max_depth': 8, 'eta': 0.023318611866921104, 'subsample': 0.6982433414730397, 'colsample_bytree': 0.8506327819374757, 'min_child_weight': 3.114482896232655}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.536524 | w1=5.966281361913346 | w4=1.7773803559167924 | max_depth=8 | eta=0.023318611866921104 | subsample=0.6982433414730397 | colsample_bytree=0.8506327819374757 | min_child_weight=3.114482896232655\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:21:29,564]\u001b[0m Trial 6 finished with value: 0.5917138301879253 and parameters: {'w1': 1.1378374555105437, 'w4': 2.0309568694098887, 'max_depth': 5, 'eta': 0.04579460845167218, 'subsample': 0.8614072081824484, 'colsample_bytree': 0.7342131220024933, 'min_child_weight': 9.635784956218806}. Best is trial 0 with value: 0.6310361917783958.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.591714 | w1=1.1378374555105437 | w4=2.0309568694098887 | max_depth=5 | eta=0.04579460845167218 | subsample=0.8614072081824484 | colsample_bytree=0.7342131220024933 | min_child_weight=9.635784956218806\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:22:25,676]\u001b[0m Trial 7 finished with value: 0.6317411968475768 and parameters: {'w1': 4.201065973080283, 'w4': 3.955359832093476, 'max_depth': 8, 'eta': 0.10132451362211677, 'subsample': 0.7123871366959939, 'colsample_bytree': 0.6857483250707322, 'min_child_weight': 9.417237380976824}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631741 | w1=4.201065973080283 | w4=3.955359832093476 | max_depth=8 | eta=0.10132451362211677 | subsample=0.7123871366959939 | colsample_bytree=0.6857483250707322 | min_child_weight=9.417237380976824\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:23:19,711]\u001b[0m Trial 8 finished with value: 0.6046739468736987 and parameters: {'w1': 2.2704070911292167, 'w4': 2.6742000046740317, 'max_depth': 7, 'eta': 0.027507173816369034, 'subsample': 0.8528063392877834, 'colsample_bytree': 0.6624770761464854, 'min_child_weight': 7.148253433444054}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.604674 | w1=2.2704070911292167 | w4=2.6742000046740317 | max_depth=7 | eta=0.027507173816369034 | subsample=0.8528063392877834 | colsample_bytree=0.6624770761464854 | min_child_weight=7.148253433444054\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:24:13,668]\u001b[0m Trial 9 finished with value: 0.6043028444238686 and parameters: {'w1': 1.3011932938039719, 'w4': 5.0286387576159175, 'max_depth': 7, 'eta': 0.07031464894037465, 'subsample': 0.9516503984174662, 'colsample_bytree': 0.8163674253331221, 'min_child_weight': 4.449819955233}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.604303 | w1=1.3011932938039719 | w4=5.0286387576159175 | max_depth=7 | eta=0.07031464894037465 | subsample=0.9516503984174662 | colsample_bytree=0.8163674253331221 | min_child_weight=4.449819955233\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:25:09,543]\u001b[0m Trial 10 finished with value: 0.6022162828242241 and parameters: {'w1': 4.818721593284698, 'w4': 1.002933845114507, 'max_depth': 8, 'eta': 0.10235349336625517, 'subsample': 0.7784908907000352, 'colsample_bytree': 0.611921650102232, 'min_child_weight': 7.690363562591623}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.602216 | w1=4.818721593284698 | w4=1.002933845114507 | max_depth=8 | eta=0.10235349336625517 | subsample=0.7784908907000352 | colsample_bytree=0.611921650102232 | min_child_weight=7.690363562591623\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:25:58,184]\u001b[0m Trial 11 finished with value: 0.6312010061067455 and parameters: {'w1': 3.6486625670201014, 'w4': 4.236867329405054, 'max_depth': 4, 'eta': 0.14621185070590412, 'subsample': 0.7491136113477305, 'colsample_bytree': 0.8923147234534722, 'min_child_weight': 8.385806291578042}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631201 | w1=3.6486625670201014 | w4=4.236867329405054 | max_depth=4 | eta=0.14621185070590412 | subsample=0.7491136113477305 | colsample_bytree=0.8923147234534722 | min_child_weight=8.385806291578042\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:26:47,034]\u001b[0m Trial 12 finished with value: 0.6297486133930976 and parameters: {'w1': 4.198767500349208, 'w4': 3.912891770880121, 'max_depth': 4, 'eta': 0.09812297972989276, 'subsample': 0.7760311256230303, 'colsample_bytree': 0.9025124683962594, 'min_child_weight': 7.591203113047178}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.629749 | w1=4.198767500349208 | w4=3.912891770880121 | max_depth=4 | eta=0.09812297972989276 | subsample=0.7760311256230303 | colsample_bytree=0.9025124683962594 | min_child_weight=7.591203113047178\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:27:37,540]\u001b[0m Trial 13 finished with value: 0.631673274021269 and parameters: {'w1': 4.823477363123409, 'w4': 4.4356078057389645, 'max_depth': 5, 'eta': 0.119308114708005, 'subsample': 0.7321530490948521, 'colsample_bytree': 0.9090869498369193, 'min_child_weight': 8.609391536205628}. Best is trial 7 with value: 0.6317411968475768.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631673 | w1=4.823477363123409 | w4=4.4356078057389645 | max_depth=5 | eta=0.119308114708005 | subsample=0.7321530490948521 | colsample_bytree=0.9090869498369193 | min_child_weight=8.609391536205628\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:28:28,252]\u001b[0m Trial 14 finished with value: 0.631772672226434 and parameters: {'w1': 4.934218075840067, 'w4': 4.927471135720822, 'max_depth': 5, 'eta': 0.07382062186009859, 'subsample': 0.6759481668144001, 'colsample_bytree': 0.7396424635811837, 'min_child_weight': 8.537500809100885}. Best is trial 14 with value: 0.631772672226434.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631773 | w1=4.934218075840067 | w4=4.927471135720822 | max_depth=5 | eta=0.07382062186009859 | subsample=0.6759481668144001 | colsample_bytree=0.7396424635811837 | min_child_weight=8.537500809100885\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:29:18,855]\u001b[0m Trial 15 finished with value: 0.6321050742132439 and parameters: {'w1': 5.048006752330751, 'w4': 5.066341958895126, 'max_depth': 5, 'eta': 0.06775184316043484, 'subsample': 0.6645644837523211, 'colsample_bytree': 0.729445030650721, 'min_child_weight': 6.684057776500144}. Best is trial 15 with value: 0.6321050742132439.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632105 | w1=5.048006752330751 | w4=5.066341958895126 | max_depth=5 | eta=0.06775184316043484 | subsample=0.6645644837523211 | colsample_bytree=0.729445030650721 | min_child_weight=6.684057776500144\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:30:09,698]\u001b[0m Trial 16 finished with value: 0.6326100044180505 and parameters: {'w1': 5.241971394584772, 'w4': 5.217392774885659, 'max_depth': 5, 'eta': 0.04829634626518371, 'subsample': 0.6583495463269837, 'colsample_bytree': 0.7422343411250392, 'min_child_weight': 4.531142787052159}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632610 | w1=5.241971394584772 | w4=5.217392774885659 | max_depth=5 | eta=0.04829634626518371 | subsample=0.6583495463269837 | colsample_bytree=0.7422343411250392 | min_child_weight=4.531142787052159\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:31:00,615]\u001b[0m Trial 17 finished with value: 0.6240581116467994 and parameters: {'w1': 5.5060693407452455, 'w4': 5.250965005250145, 'max_depth': 5, 'eta': 0.04880341727033419, 'subsample': 0.6517197563102891, 'colsample_bytree': 0.7327205144357926, 'min_child_weight': 4.492482540317658}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.624058 | w1=5.5060693407452455 | w4=5.250965005250145 | max_depth=5 | eta=0.04880341727033419 | subsample=0.6517197563102891 | colsample_bytree=0.7327205144357926 | min_child_weight=4.492482540317658\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:31:53,828]\u001b[0m Trial 18 finished with value: 0.6075384736324445 and parameters: {'w1': 5.296782283250055, 'w4': 5.483103347451214, 'max_depth': 6, 'eta': 0.057341758980332405, 'subsample': 0.6424873679093083, 'colsample_bytree': 0.6134181552808892, 'min_child_weight': 4.133017387890277}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.607538 | w1=5.296782283250055 | w4=5.483103347451214 | max_depth=6 | eta=0.057341758980332405 | subsample=0.6424873679093083 | colsample_bytree=0.6134181552808892 | min_child_weight=4.133017387890277\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:32:44,386]\u001b[0m Trial 19 finished with value: 0.6181711281119724 and parameters: {'w1': 3.000999645032007, 'w4': 4.877579673859218, 'max_depth': 5, 'eta': 0.03567689049021843, 'subsample': 0.8302728515289797, 'colsample_bytree': 0.7836396070319408, 'min_child_weight': 1.294546811388714}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.618171 | w1=3.000999645032007 | w4=4.877579673859218 | max_depth=5 | eta=0.03567689049021843 | subsample=0.8302728515289797 | colsample_bytree=0.7836396070319408 | min_child_weight=1.294546811388714\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:33:36,959]\u001b[0m Trial 20 finished with value: 0.5409539295899713 and parameters: {'w1': 4.487995212390628, 'w4': 5.9580374428830165, 'max_depth': 6, 'eta': 0.035558451216142824, 'subsample': 0.8065174560473964, 'colsample_bytree': 0.8322317150169937, 'min_child_weight': 6.68952317876904}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.540954 | w1=4.487995212390628 | w4=5.9580374428830165 | max_depth=6 | eta=0.035558451216142824 | subsample=0.8065174560473964 | colsample_bytree=0.8322317150169937 | min_child_weight=6.68952317876904\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:34:27,516]\u001b[0m Trial 21 finished with value: 0.6324443218239352 and parameters: {'w1': 5.176567320293337, 'w4': 4.746355534943041, 'max_depth': 5, 'eta': 0.06390849973103116, 'subsample': 0.6579054395327114, 'colsample_bytree': 0.7378068392222956, 'min_child_weight': 5.228940639431791}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632444 | w1=5.176567320293337 | w4=4.746355534943041 | max_depth=5 | eta=0.06390849973103116 | subsample=0.6579054395327114 | colsample_bytree=0.7378068392222956 | min_child_weight=5.228940639431791\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:35:18,039]\u001b[0m Trial 22 finished with value: 0.6323587805544626 and parameters: {'w1': 5.41033964351144, 'w4': 4.626073892416916, 'max_depth': 5, 'eta': 0.05625825401907308, 'subsample': 0.6335571384912523, 'colsample_bytree': 0.7155793063708, 'min_child_weight': 5.179753962598876}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632359 | w1=5.41033964351144 | w4=4.626073892416916 | max_depth=5 | eta=0.05625825401907308 | subsample=0.6335571384912523 | colsample_bytree=0.7155793063708 | min_child_weight=5.179753962598876\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:36:06,824]\u001b[0m Trial 23 finished with value: 0.6316866572210592 and parameters: {'w1': 5.570489943438006, 'w4': 4.627048178818186, 'max_depth': 4, 'eta': 0.04563823635084686, 'subsample': 0.6247139436844309, 'colsample_bytree': 0.759351696911801, 'min_child_weight': 4.883305041842073}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631687 | w1=5.570489943438006 | w4=4.627048178818186 | max_depth=4 | eta=0.04563823635084686 | subsample=0.6247139436844309 | colsample_bytree=0.759351696911801 | min_child_weight=4.883305041842073\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:36:57,450]\u001b[0m Trial 24 finished with value: 0.6302597454128778 and parameters: {'w1': 4.42505736919741, 'w4': 3.642650808439703, 'max_depth': 5, 'eta': 0.054405865831892615, 'subsample': 0.6908423768360559, 'colsample_bytree': 0.7002255592781621, 'min_child_weight': 5.230594425713356}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630260 | w1=4.42505736919741 | w4=3.642650808439703 | max_depth=5 | eta=0.054405865831892615 | subsample=0.6908423768360559 | colsample_bytree=0.7002255592781621 | min_child_weight=5.230594425713356\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:37:50,607]\u001b[0m Trial 25 finished with value: 0.601029424909974 and parameters: {'w1': 5.409368828827243, 'w4': 5.439035255994305, 'max_depth': 6, 'eta': 0.08342378065655624, 'subsample': 0.6341687217108526, 'colsample_bytree': 0.6394922151858462, 'min_child_weight': 3.644526297791015}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.601029 | w1=5.409368828827243 | w4=5.439035255994305 | max_depth=6 | eta=0.08342378065655624 | subsample=0.6341687217108526 | colsample_bytree=0.6394922151858462 | min_child_weight=3.644526297791015\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:38:39,389]\u001b[0m Trial 26 finished with value: 0.5012369425279968 and parameters: {'w1': 5.983585130210681, 'w4': 3.193896174612225, 'max_depth': 4, 'eta': 0.040897803867277094, 'subsample': 0.605479222551155, 'colsample_bytree': 0.7112706282803118, 'min_child_weight': 5.7091598882377905}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.501237 | w1=5.983585130210681 | w4=3.193896174612225 | max_depth=4 | eta=0.040897803867277094 | subsample=0.605479222551155 | colsample_bytree=0.7112706282803118 | min_child_weight=5.7091598882377905\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:39:29,696]\u001b[0m Trial 27 finished with value: 0.6321214000385736 and parameters: {'w1': 5.15460363552739, 'w4': 4.2660279928786204, 'max_depth': 5, 'eta': 0.056737802713908846, 'subsample': 0.755830078688972, 'colsample_bytree': 0.7700369033847289, 'min_child_weight': 2.971990735044179}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632121 | w1=5.15460363552739 | w4=4.2660279928786204 | max_depth=5 | eta=0.056737802713908846 | subsample=0.755830078688972 | colsample_bytree=0.7700369033847289 | min_child_weight=2.971990735044179\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:40:22,116]\u001b[0m Trial 28 finished with value: 0.63202666316167 and parameters: {'w1': 3.9194302408993664, 'w4': 4.669952961244473, 'max_depth': 6, 'eta': 0.030474878695424444, 'subsample': 0.7073661374249622, 'colsample_bytree': 0.6531495782702275, 'min_child_weight': 5.195926036210768}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632027 | w1=3.9194302408993664 | w4=4.669952961244473 | max_depth=6 | eta=0.030474878695424444 | subsample=0.7073661374249622 | colsample_bytree=0.6531495782702275 | min_child_weight=5.195926036210768\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:41:10,672]\u001b[0m Trial 29 finished with value: 0.6295128876682323 and parameters: {'w1': 3.2442465863955503, 'w4': 4.037649355844107, 'max_depth': 4, 'eta': 0.08006771401908623, 'subsample': 0.7326231875939058, 'colsample_bytree': 0.8085500764158234, 'min_child_weight': 3.7110979205922803}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.629513 | w1=3.2442465863955503 | w4=4.037649355844107 | max_depth=4 | eta=0.08006771401908623 | subsample=0.7326231875939058 | colsample_bytree=0.8085500764158234 | min_child_weight=3.7110979205922803\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:42:01,033]\u001b[0m Trial 30 finished with value: 0.6301360824260499 and parameters: {'w1': 4.605859533304163, 'w4': 3.122429854137785, 'max_depth': 5, 'eta': 0.05847132731000839, 'subsample': 0.6485901722061717, 'colsample_bytree': 0.8674634628706996, 'min_child_weight': 2.3464886624432335}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630136 | w1=4.605859533304163 | w4=3.122429854137785 | max_depth=5 | eta=0.05847132731000839 | subsample=0.6485901722061717 | colsample_bytree=0.8674634628706996 | min_child_weight=2.3464886624432335\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:42:51,504]\u001b[0m Trial 31 finished with value: 0.6322459531345721 and parameters: {'w1': 5.164492506900609, 'w4': 4.372459517944603, 'max_depth': 5, 'eta': 0.05154545523311127, 'subsample': 0.7661632029860125, 'colsample_bytree': 0.7672557407648055, 'min_child_weight': 2.7121219178954026}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632246 | w1=5.164492506900609 | w4=4.372459517944603 | max_depth=5 | eta=0.05154545523311127 | subsample=0.7661632029860125 | colsample_bytree=0.7672557407648055 | min_child_weight=2.7121219178954026\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:43:42,343]\u001b[0m Trial 32 finished with value: 0.5825254268570558 and parameters: {'w1': 5.608099712665592, 'w4': 4.622746086240981, 'max_depth': 5, 'eta': 0.050451199365333356, 'subsample': 0.6792816145229408, 'colsample_bytree': 0.7574050899694075, 'min_child_weight': 1.1871949617659099}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.582525 | w1=5.608099712665592 | w4=4.622746086240981 | max_depth=5 | eta=0.050451199365333356 | subsample=0.6792816145229408 | colsample_bytree=0.7574050899694075 | min_child_weight=1.1871949617659099\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:44:31,011]\u001b[0m Trial 33 finished with value: 0.63194322470066 and parameters: {'w1': 5.27091838085031, 'w4': 5.316400168830366, 'max_depth': 4, 'eta': 0.04001129549762587, 'subsample': 0.9739718353617474, 'colsample_bytree': 0.7204404372082827, 'min_child_weight': 2.828776272379225}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631943 | w1=5.27091838085031 | w4=5.316400168830366 | max_depth=4 | eta=0.04001129549762587 | subsample=0.9739718353617474 | colsample_bytree=0.7204404372082827 | min_child_weight=2.828776272379225\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:45:24,017]\u001b[0m Trial 34 finished with value: 0.5242114324299672 and parameters: {'w1': 5.657177139901723, 'w4': 5.674313872645634, 'max_depth': 6, 'eta': 0.06279403530944064, 'subsample': 0.662146460498933, 'colsample_bytree': 0.7849972890339592, 'min_child_weight': 1.9730457859946204}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.524211 | w1=5.657177139901723 | w4=5.674313872645634 | max_depth=6 | eta=0.06279403530944064 | subsample=0.662146460498933 | colsample_bytree=0.7849972890339592 | min_child_weight=1.9730457859946204\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:46:14,451]\u001b[0m Trial 35 finished with value: 0.6315539271541539 and parameters: {'w1': 4.7669497365811395, 'w4': 4.405775135884358, 'max_depth': 5, 'eta': 0.041847320417589845, 'subsample': 0.8983606518762068, 'colsample_bytree': 0.6955128558242735, 'min_child_weight': 3.949508388398648}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631554 | w1=4.7669497365811395 | w4=4.405775135884358 | max_depth=5 | eta=0.041847320417589845 | subsample=0.8983606518762068 | colsample_bytree=0.6955128558242735 | min_child_weight=3.949508388398648\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:47:08,054]\u001b[0m Trial 36 finished with value: 0.6309979208208402 and parameters: {'w1': 4.160369860613624, 'w4': 3.5741649446999553, 'max_depth': 7, 'eta': 0.052120364320251696, 'subsample': 0.6224841383736425, 'colsample_bytree': 0.7948841595466253, 'min_child_weight': 6.205898420103487}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630998 | w1=4.160369860613624 | w4=3.5741649446999553 | max_depth=7 | eta=0.052120364320251696 | subsample=0.6224841383736425 | colsample_bytree=0.7948841595466253 | min_child_weight=6.205898420103487\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:47:59,075]\u001b[0m Trial 37 finished with value: 0.5209106996853403 and parameters: {'w1': 5.763408132935656, 'w4': 5.735698464803263, 'max_depth': 5, 'eta': 0.06115356512582554, 'subsample': 0.6995180211274353, 'colsample_bytree': 0.7479312317753651, 'min_child_weight': 4.8384617557737295}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.520911 | w1=5.763408132935656 | w4=5.735698464803263 | max_depth=5 | eta=0.06115356512582554 | subsample=0.6995180211274353 | colsample_bytree=0.7479312317753651 | min_child_weight=4.8384617557737295\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:48:48,004]\u001b[0m Trial 38 finished with value: 0.6306178017190174 and parameters: {'w1': 5.0721703326849354, 'w4': 4.804650618172677, 'max_depth': 4, 'eta': 0.0863856668226954, 'subsample': 0.7216867292426776, 'colsample_bytree': 0.6703873400309112, 'min_child_weight': 3.4297757744341486}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630618 | w1=5.0721703326849354 | w4=4.804650618172677 | max_depth=4 | eta=0.0863856668226954 | subsample=0.7216867292426776 | colsample_bytree=0.6703873400309112 | min_child_weight=3.4297757744341486\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:49:40,284]\u001b[0m Trial 39 finished with value: 0.6185634550150183 and parameters: {'w1': 2.769387601057631, 'w4': 5.1459895190171725, 'max_depth': 6, 'eta': 0.04293700234735639, 'subsample': 0.7955036097707422, 'colsample_bytree': 0.9413763688790319, 'min_child_weight': 5.778959702668393}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.618563 | w1=2.769387601057631 | w4=5.1459895190171725 | max_depth=6 | eta=0.04293700234735639 | subsample=0.7955036097707422 | colsample_bytree=0.9413763688790319 | min_child_weight=5.778959702668393\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:50:30,602]\u001b[0m Trial 40 finished with value: 0.6302478898478789 and parameters: {'w1': 3.954262750572078, 'w4': 3.8046747256964886, 'max_depth': 5, 'eta': 0.07519992151396059, 'subsample': 0.6046157225395064, 'colsample_bytree': 0.8259904787245838, 'min_child_weight': 1.867042806063049}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630248 | w1=3.954262750572078 | w4=3.8046747256964886 | max_depth=5 | eta=0.07519992151396059 | subsample=0.6046157225395064 | colsample_bytree=0.8259904787245838 | min_child_weight=1.867042806063049\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:51:21,318]\u001b[0m Trial 41 finished with value: 0.632296226106282 and parameters: {'w1': 5.1817181673254336, 'w4': 4.1678931029351745, 'max_depth': 5, 'eta': 0.053939038993666276, 'subsample': 0.7507878460711165, 'colsample_bytree': 0.7647346144586497, 'min_child_weight': 3.0449775099672514}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632296 | w1=5.1817181673254336 | w4=4.1678931029351745 | max_depth=5 | eta=0.053939038993666276 | subsample=0.7507878460711165 | colsample_bytree=0.7647346144586497 | min_child_weight=3.0449775099672514\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:52:11,890]\u001b[0m Trial 42 finished with value: 0.6324959387179694 and parameters: {'w1': 5.315492615024744, 'w4': 4.25020983855618, 'max_depth': 5, 'eta': 0.04752972960941869, 'subsample': 0.7626046169077842, 'colsample_bytree': 0.7653702222870157, 'min_child_weight': 2.490471415078507}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.632496 | w1=5.315492615024744 | w4=4.25020983855618 | max_depth=5 | eta=0.04752972960941869 | subsample=0.7626046169077842 | colsample_bytree=0.7653702222870157 | min_child_weight=2.490471415078507\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:53:02,709]\u001b[0m Trial 43 finished with value: 0.6315247526758019 and parameters: {'w1': 4.668636243056076, 'w4': 4.199804935778347, 'max_depth': 5, 'eta': 0.020089773620902238, 'subsample': 0.8093564991102744, 'colsample_bytree': 0.7090357069465815, 'min_child_weight': 4.308769668232788}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631525 | w1=4.668636243056076 | w4=4.199804935778347 | max_depth=5 | eta=0.020089773620902238 | subsample=0.8093564991102744 | colsample_bytree=0.7090357069465815 | min_child_weight=4.308769668232788\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:53:53,270]\u001b[0m Trial 44 finished with value: 0.523298718290476 and parameters: {'w1': 5.849506401897447, 'w4': 4.0228497364547495, 'max_depth': 5, 'eta': 0.047141728432421225, 'subsample': 0.7396085837082872, 'colsample_bytree': 0.6858597635693552, 'min_child_weight': 3.1690140514145626}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.523299 | w1=5.849506401897447 | w4=4.0228497364547495 | max_depth=5 | eta=0.047141728432421225 | subsample=0.7396085837082872 | colsample_bytree=0.6858597635693552 | min_child_weight=3.1690140514145626\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:54:45,647]\u001b[0m Trial 45 finished with value: 0.63086491681776 and parameters: {'w1': 5.3726820854301245, 'w4': 3.2835933253653256, 'max_depth': 6, 'eta': 0.031007653834959945, 'subsample': 0.6814193311106744, 'colsample_bytree': 0.7477959436162727, 'min_child_weight': 6.218294689315112}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630865 | w1=5.3726820854301245 | w4=3.2835933253653256 | max_depth=6 | eta=0.031007653834959945 | subsample=0.6814193311106744 | colsample_bytree=0.7477959436162727 | min_child_weight=6.218294689315112\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:55:34,260]\u001b[0m Trial 46 finished with value: 0.6312237053219116 and parameters: {'w1': 4.95685461962278, 'w4': 4.7671737187944405, 'max_depth': 4, 'eta': 0.062444072668916696, 'subsample': 0.8338979131521731, 'colsample_bytree': 0.8008345266514092, 'min_child_weight': 2.5193691310001207}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.631224 | w1=4.95685461962278 | w4=4.7671737187944405 | max_depth=4 | eta=0.062444072668916696 | subsample=0.8338979131521731 | colsample_bytree=0.8008345266514092 | min_child_weight=2.5193691310001207\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:56:26,398]\u001b[0m Trial 47 finished with value: 0.6031762238014081 and parameters: {'w1': 1.7976865910387194, 'w4': 2.6284488193451976, 'max_depth': 6, 'eta': 0.06686447348107966, 'subsample': 0.7834397302620884, 'colsample_bytree': 0.8434209541956927, 'min_child_weight': 4.827620932660679}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.603176 | w1=1.7976865910387194 | w4=2.6284488193451976 | max_depth=6 | eta=0.06686447348107966 | subsample=0.7834397302620884 | colsample_bytree=0.8434209541956927 | min_child_weight=4.827620932660679\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:57:16,995]\u001b[0m Trial 48 finished with value: 0.6303912082904253 and parameters: {'w1': 4.405517165672065, 'w4': 3.7433829274117842, 'max_depth': 5, 'eta': 0.03797687434784198, 'subsample': 0.8803335455858771, 'colsample_bytree': 0.717401583735417, 'min_child_weight': 5.29918251991441}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.630391 | w1=4.405517165672065 | w4=3.7433829274117842 | max_depth=5 | eta=0.03797687434784198 | subsample=0.8803335455858771 | colsample_bytree=0.717401583735417 | min_child_weight=5.29918251991441\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-13 22:58:11,274]\u001b[0m Trial 49 finished with value: 0.5632284500456928 and parameters: {'w1': 5.791964743784782, 'w4': 4.139639209114184, 'max_depth': 7, 'eta': 0.047200594222630225, 'subsample': 0.6620192774558664, 'colsample_bytree': 0.7798403154807716, 'min_child_weight': 1.711705316836877}. Best is trial 16 with value: 0.6326100044180505.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.563228 | w1=5.791964743784782 | w4=4.139639209114184 | max_depth=7 | eta=0.047200594222630225 | subsample=0.6620192774558664 | colsample_bytree=0.7798403154807716 | min_child_weight=1.711705316836877\nBest Params: {'w1': 5.241971394584772, 'w4': 5.217392774885659, 'max_depth': 5, 'eta': 0.04829634626518371, 'subsample': 0.6583495463269837, 'colsample_bytree': 0.7422343411250392, 'min_child_weight': 4.531142787052159}\nBest F1: 0.6326100044180505\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"try:\n    import xgboost as xgb\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available. Install with: pip install xgboost\")\n    XGBOOST_AVAILABLE = False\n\n\ndef train_xgboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    if not XGBOOST_AVAILABLE:\n        return None, None, None, None\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Training XGBoost Models\")\n    print(\"=\" * 80)\n\n    params = config.get_xgboost_params(use_gpu=use_gpu)\n    params[\"num_class\"] = len(np.unique(y_train))\n\n    params.update({\n        k: v for k, v in best_params.items()\n        if k not in [\"w1\", \"w4\"]\n    })\n\n    sample_weight = np.ones(len(y_train))\n    sample_weight[y_train == 1] = best_params[\"w1\"]\n    sample_weight[y_train == 4] = best_params[\"w4\"]\n\n    skf = StratifiedKFold(\n        n_splits=n_folds,\n        shuffle=True,\n        random_state=config.RANDOM_STATE\n    )\n\n    oof_predictions = np.zeros((len(X_train), params[\"num_class\"]))\n    test_predictions = np.zeros((len(X_test), params[\"num_class\"]))\n\n    fold_scores = []\n    models = []\n\n    pbar = tqdm(\n        enumerate(skf.split(X_train, y_train), 1),\n        total=n_folds,\n        desc=\"XGBoost Folds\"\n    )\n\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\n        dtrain = xgb.DMatrix(\n            X_tr,\n            label=y_tr,\n            weight=sample_weight[train_idx]\n        )\n        dval = xgb.DMatrix(\n            X_val,\n            label=y_val,\n            weight=sample_weight[val_idx]\n        )\n        dtest = xgb.DMatrix(X_test)\n\n        model = xgb.train(\n            params,\n            dtrain,\n            num_boost_round=1000,\n            evals=[(dtrain, \"train\"), (dval, \"valid\")],\n            custom_metric=macro_f1_eval,\n            early_stopping_rounds=50,\n            verbose_eval=100\n        )\n\n        oof_predictions[val_idx] = model.predict(dval)\n        test_predictions += model.predict(dtest) / n_folds\n\n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average=\"macro\")\n        fold_scores.append(fold_score)\n\n        print(\"\\n\" + \"=\" * 60)\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(\"=\" * 60)\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.best_iteration}\")\n        print(f\"  Best Score (mlogloss): {model.best_score:.6f}\")\n\n        print(\n            classification_report(\n                y_val,\n                oof_pred_labels,\n                target_names=[\n                    f\"Class_{i}\"\n                    for i in range(params[\"num_class\"])\n                ],\n                digits=4\n            )\n        )\n        print(\"=\" * 60 + \"\\n\")\n\n        pbar.set_postfix({\"F1\": f\"{fold_score:.6f}\"})\n\n        models.append(model)\n        gc.collect()\n\n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average=\"macro\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"XGBOOST TRAINING SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n\n    return oof_predictions, test_predictions, models, overall_score\n\n\nif XGBOOST_AVAILABLE:\n    oof_predictions, test_predictions, xgboost_models, xgboost_cv_score = train_xgboost(\n        X_train,\n        y_train,\n        X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config[\"xgboost_gpu\"]\n    )\nelse:\n    oof_predictions, test_predictions, xgboost_models, xgboost_cv_score = None, None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T22:58:11.279769Z","iopub.execute_input":"2026-01-13T22:58:11.280034Z","iopub.status.idle":"2026-01-13T23:04:26.299480Z","shell.execute_reply.started":"2026-01-13T22:58:11.280012Z","shell.execute_reply":"2026-01-13T23:04:26.298874Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining XGBoost Models\n================================================================================\n  XGBoost: GPU mode activated\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"XGBoost Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f8a841de8c04b47b078a067d7553d53"}},"metadata":{}},{"name":"stdout","text":"[0]\ttrain-mlogloss:1.51942\ttrain-macro_f1:0.21046\tvalid-mlogloss:1.51942\tvalid-macro_f1:0.21103\n[50]\ttrain-mlogloss:1.01971\ttrain-macro_f1:0.63201\tvalid-mlogloss:1.01974\tvalid-macro_f1:0.63236\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.632360\n  Best Iteration: 0\n  Best Score (mlogloss): 0.211031\n              precision    recall  f1-score   support\n\n     Class_0     0.9965    0.9780    0.9871     80062\n     Class_1     0.2529    0.1378    0.1784    160358\n     Class_2     0.7348    0.8163    0.7734    879522\n     Class_3     0.9960    0.9474    0.9711    320319\n     Class_4     0.2579    0.2458    0.2517    159739\n\n    accuracy                         0.7257   1600000\n   macro avg     0.6476    0.6251    0.6324   1600000\nweighted avg     0.7043    0.7257    0.7120   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51941\ttrain-macro_f1:0.21046\tvalid-mlogloss:1.51940\tvalid-macro_f1:0.21036\n[50]\ttrain-mlogloss:1.01974\ttrain-macro_f1:0.63186\tvalid-mlogloss:1.01944\tvalid-macro_f1:0.63212\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.632123\n  Best Iteration: 0\n  Best Score (mlogloss): 0.210359\n              precision    recall  f1-score   support\n\n     Class_0     0.9968    0.9777    0.9872     80062\n     Class_1     0.2503    0.1393    0.1790    160358\n     Class_2     0.7348    0.8081    0.7697    879522\n     Class_3     0.9964    0.9479    0.9716    320319\n     Class_4     0.2529    0.2535    0.2532    159739\n\n    accuracy                         0.7222   1600000\n   macro avg     0.6462    0.6253    0.6321   1600000\nweighted avg     0.7036    0.7222    0.7102   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51936\ttrain-macro_f1:0.21053\tvalid-mlogloss:1.51941\tvalid-macro_f1:0.21007\n[49]\ttrain-mlogloss:1.02253\ttrain-macro_f1:0.63206\tvalid-mlogloss:1.02332\tvalid-macro_f1:0.63157\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.631553\n  Best Iteration: 0\n  Best Score (mlogloss): 0.210067\n              precision    recall  f1-score   support\n\n     Class_0     0.9970    0.9773    0.9870     80063\n     Class_1     0.2511    0.1375    0.1777    160358\n     Class_2     0.7346    0.8096    0.7703    879521\n     Class_3     0.9961    0.9477    0.9713    320319\n     Class_4     0.2516    0.2513    0.2514    159739\n\n    accuracy                         0.7225   1600000\n   macro avg     0.6461    0.6247    0.6316   1600000\nweighted avg     0.7034    0.7225    0.7102   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51941\ttrain-macro_f1:0.21041\tvalid-mlogloss:1.51940\tvalid-macro_f1:0.21023\n[49]\ttrain-mlogloss:1.02271\ttrain-macro_f1:0.63232\tvalid-mlogloss:1.02279\tvalid-macro_f1:0.63186\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.631702\n  Best Iteration: 0\n  Best Score (mlogloss): 0.210226\n              precision    recall  f1-score   support\n\n     Class_0     0.9964    0.9790    0.9876     80063\n     Class_1     0.2482    0.1422    0.1808    160358\n     Class_2     0.7341    0.8077    0.7691    879521\n     Class_3     0.9961    0.9482    0.9716    320319\n     Class_4     0.2518    0.2471    0.2494    159739\n\n    accuracy                         0.7217   1600000\n   macro avg     0.6453    0.6248    0.6317   1600000\nweighted avg     0.7028    0.7217    0.7097   1600000\n\n============================================================\n\n[0]\ttrain-mlogloss:1.51939\ttrain-macro_f1:0.21056\tvalid-mlogloss:1.51938\tvalid-macro_f1:0.21061\n[50]\ttrain-mlogloss:1.01967\ttrain-macro_f1:0.63185\tvalid-mlogloss:1.01953\tvalid-macro_f1:0.63162\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.631625\n  Best Iteration: 0\n  Best Score (mlogloss): 0.210612\n              precision    recall  f1-score   support\n\n     Class_0     0.9966    0.9780    0.9872     80063\n     Class_1     0.2500    0.1392    0.1788    160358\n     Class_2     0.7348    0.8059    0.7687    879521\n     Class_3     0.9962    0.9479    0.9714    320319\n     Class_4     0.2498    0.2542    0.2520    159739\n\n    accuracy                         0.7211   1600000\n   macro avg     0.6454    0.6251    0.6316   1600000\nweighted avg     0.7032    0.7211    0.7095   1600000\n\n============================================================\n\n\n================================================================================\nXGBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.631876\nStandard Deviation: 0.000314\nMin F1 Score: 0.631553\nMax F1 Score: 0.632360\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"MODEL EVALUATION\")\nprint(\"=\"*80)\n\nif test_predictions is not None:\n    print(\"\\n XGBoost Model Successfully Trained\")\n    print(f\"  Cross-Validation Score: {xgboost_cv_score:.6f}\")\n    print(f\"  Model Type: XGBoost with GPU acceleration\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"GENERATING PREDICTIONS ON TEST SET\")\n    print(\"=\"*80)\n\n    final_predictions = test_predictions\n    final_pred_labels = np.argmax(final_predictions, axis=1)\n\n    print(\"\\n Predictions Generated Successfully\")\n    print(f\"  Total test samples: {len(final_pred_labels):,}\")\n    print(f\"  Prediction shape: {final_predictions.shape}\")\n    print(f\"  Classes predicted: {len(np.unique(final_pred_labels))}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"PREDICTION DISTRIBUTION\")\n    print(\"=\"*80)\n\n    unique, counts = np.unique(final_pred_labels, return_counts=True)\n    for class_idx, count in zip(unique, counts):\n        percentage = (count / len(final_pred_labels)) * 100\n        print(f\"  Class {class_idx}: {count:,} samples ({percentage:.2f}%)\")\nelse:\n    raise ValueError(\"XGBoost model training failed! Cannot generate predictions.\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T23:04:26.300691Z","iopub.execute_input":"2026-01-13T23:04:26.300928Z","iopub.status.idle":"2026-01-13T23:04:26.411222Z","shell.execute_reply.started":"2026-01-13T23:04:26.300907Z","shell.execute_reply":"2026-01-13T23:04:26.410520Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nMODEL EVALUATION\n================================================================================\n\n XGBoost Model Successfully Trained\n  Cross-Validation Score: 0.631876\n  Model Type: XGBoost with GPU acceleration\n\n================================================================================\nGENERATING PREDICTIONS ON TEST SET\n================================================================================\n\n Predictions Generated Successfully\n  Total test samples: 4,000,000\n  Prediction shape: (4000000, 5)\n  Classes predicted: 5\n\n================================================================================\nPREDICTION DISTRIBUTION\n================================================================================\n  Class 0: 198,092 samples (4.95%)\n  Class 1: 211,865 samples (5.30%)\n  Class 2: 2,366,351 samples (59.16%)\n  Class 3: 789,866 samples (19.75%)\n  Class 4: 433,826 samples (10.85%)\n\n================================================================================\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n    pred_labels = le_target.inverse_transform(predictions)\n    \n    submission = pd.DataFrame({\n        config.ID_COL: test_ids,\n        config.TARGET_COL: pred_labels\n    })\n    \n    submission.to_csv(filename, index=False)\n    \n    print(f\"\\nSubmission saved to: {filename}\")\n    print(f\"Submission shape: {submission.shape}\")\n    print(f\"\\nPrediction distribution:\")\n    print(submission[config.TARGET_COL].value_counts())\n    \n    return submission\n\ntest_ids = test[config.ID_COL].values\nsubmission = create_submission(test_ids, final_pred_labels, le_target, 'anava_deira_11.csv')\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T23:04:26.412741Z","iopub.execute_input":"2026-01-13T23:04:26.413235Z","iopub.status.idle":"2026-01-13T23:04:31.160738Z","shell.execute_reply.started":"2026-01-13T23:04:26.413211Z","shell.execute_reply":"2026-01-13T23:04:31.160187Z"}},"outputs":[{"name":"stdout","text":"\nSubmission saved to: anava_deira_11.csv\nSubmission shape: (4000000, 2)\n\nPrediction distribution:\nTrip_Label\nPerfect_Trip         2366351\nSafety_Violation      789866\nService_Complaint     433826\nNavigation_Issue      211865\nFraud_Indication      198092\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"               Trip_ID         Trip_Label\n0        TRIP-06583736       Perfect_Trip\n1        TRIP-11356251       Perfect_Trip\n2        TRIP-03320505  Service_Complaint\n3        TRIP-07188814       Perfect_Trip\n4        TRIP-06994869       Perfect_Trip\n...                ...                ...\n3999995  TRIP-02234490       Perfect_Trip\n3999996  TRIP-04304573       Perfect_Trip\n3999997  TRIP-10081352       Perfect_Trip\n3999998  TRIP-06550635  Service_Complaint\n3999999  TRIP-06423389   Safety_Violation\n\n[4000000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Trip_ID</th>\n      <th>Trip_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRIP-06583736</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRIP-11356251</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRIP-03320505</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRIP-07188814</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRIP-06994869</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3999995</th>\n      <td>TRIP-02234490</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999996</th>\n      <td>TRIP-04304573</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999997</th>\n      <td>TRIP-10081352</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999998</th>\n      <td>TRIP-06550635</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3999999</th>\n      <td>TRIP-06423389</td>\n      <td>Safety_Violation</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000000 rows  2 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## catboost","metadata":{}},{"cell_type":"code","source":"try:\n    from catboost import CatBoostClassifier\n    CATBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"CatBoost not available. Install with: pip install catboost\")\n    CATBOOST_AVAILABLE = False\n\n\ndef train_catboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    if not CATBOOST_AVAILABLE:\n        return None, None, 0.0\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"Training CatBoost Models\")\n    print(\"=\"*80)\n\n    params = config.get_catboost_params(use_gpu=use_gpu)\n    num_class = len(np.unique(y_train))\n\n    skf = StratifiedKFold(\n        n_splits=n_folds,\n        shuffle=True,\n        random_state=config.RANDOM_STATE\n    )\n\n    oof_predictions = np.zeros((len(X_train), num_class))\n    test_predictions = np.zeros((len(X_test), num_class))\n\n    fold_scores = []\n    models = []\n\n    pbar = tqdm(\n        enumerate(skf.split(X_train, y_train), 1),\n        total=n_folds,\n        desc=\"CatBoost Folds\"\n    )\n\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"CatBoost Fold {fold}/{n_folds}\")\n\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\n        model = CatBoostClassifier(**params)\n\n        model.fit(\n            X_tr,\n            y_tr,\n            eval_set=(X_val, y_val),\n            use_best_model=True\n        )\n\n        oof_predictions[val_idx] = model.predict_proba(X_val)\n        test_predictions += model.predict_proba(X_test) / n_folds\n\n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n        fold_scores.append(fold_score)\n\n        print(f\"\\n{'='*60}\")\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(f\"{'='*60}\")\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.get_best_iteration()}\")\n\n        oof_fold_pred = np.argmax(oof_predictions[val_idx], axis=1)\n        print(f\"\\n  Per-Class F1 Scores:\")\n        print(classification_report(\n            y_val,\n            oof_fold_pred,\n            target_names=[f\"Class_{i}\" for i in range(num_class)],\n            digits=4\n        ))\n        print(f\"{'='*60}\\n\")\n\n        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n        models.append(model)\n        gc.collect()\n\n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"CATBOOST TRAINING SUMMARY\")\n    print(\"=\"*80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n    print(\"\\nFold-by-Fold Scores:\")\n    for i, score in enumerate(fold_scores, 1):\n        print(f\"  Fold {i}: {score:.6f}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"OVERALL OUT-OF-FOLD PREDICTIONS REPORT\")\n    print(\"=\"*80)\n    print(classification_report(\n        y_train,\n        oof_pred_labels,\n        target_names=[f\"Class_{i}\" for i in range(num_class)],\n        digits=4\n    ))\n    print(\"=\"*80)\n\n    return test_predictions, models, overall_score\n\n\nif CATBOOST_AVAILABLE:\n    cb_test_pred, cb_models, cb_cv_score = train_catboost(\n        X_train,\n        y_train,\n        X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config['catboost_gpu']\n    )\nelse:\n    cb_test_pred, cb_models, cb_cv_score = None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:26:27.119018Z","iopub.execute_input":"2026-01-14T09:26:27.119577Z","iopub.status.idle":"2026-01-14T09:29:14.142511Z","shell.execute_reply.started":"2026-01-14T09:26:27.119551Z","shell.execute_reply":"2026-01-14T09:29:14.141703Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining CatBoost Models\n================================================================================\n  CatBoost: GPU mode activated\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"CatBoost Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29342ab13ab04eb383089070fdbc8d2b"}},"metadata":{}},{"name":"stdout","text":"0:\tlearn: 0.5353753\ttest: 0.5356663\tbest: 0.5356663 (0)\ttotal: 397ms\tremaining: 6m 36s\n100:\tlearn: 0.6336824\ttest: 0.6332246\tbest: 0.6332246 (100)\ttotal: 11.7s\tremaining: 1m 44s\nbestTest = 0.6349589593\nbestIteration = 118\nShrink model to first 119 iterations.\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.582352\n  Best Iteration: 118\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9315    0.9821    0.9561     80062\n     Class_1     0.1707    0.3783    0.2353    160358\n     Class_2     0.7457    0.3563    0.4822    879522\n     Class_3     0.9840    0.9517    0.9676    320319\n     Class_4     0.1855    0.4995    0.2705    159739\n\n    accuracy                         0.5233   1600000\n   macro avg     0.6035    0.6336    0.5824   1600000\nweighted avg     0.6892    0.5233    0.5572   1600000\n\n============================================================\n\n0:\tlearn: 0.5300420\ttest: 0.5299114\tbest: 0.5299114 (0)\ttotal: 148ms\tremaining: 2m 28s\n100:\tlearn: 0.6314820\ttest: 0.6316985\tbest: 0.6316985 (100)\ttotal: 11.6s\tremaining: 1m 43s\nbestTest = 0.634621679\nbestIteration = 128\nShrink model to first 129 iterations.\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.580426\n  Best Iteration: 128\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9317    0.9829    0.9566     80062\n     Class_1     0.1696    0.3870    0.2359    160358\n     Class_2     0.7453    0.3463    0.4729    879522\n     Class_3     0.9822    0.9503    0.9660    320319\n     Class_4     0.1855    0.5007    0.2708    159739\n\n    accuracy                         0.5186   1600000\n   macro avg     0.6029    0.6335    0.5804   1600000\nweighted avg     0.6885    0.5186    0.5519   1600000\n\n============================================================\n\n0:\tlearn: 0.5309428\ttest: 0.5305660\tbest: 0.5305660 (0)\ttotal: 147ms\tremaining: 2m 26s\n100:\tlearn: 0.6331931\ttest: 0.6328788\tbest: 0.6328788 (100)\ttotal: 11.6s\tremaining: 1m 43s\nbestTest = 0.6339737393\nbestIteration = 128\nShrink model to first 129 iterations.\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.579498\n  Best Iteration: 128\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9317    0.9829    0.9567     80063\n     Class_1     0.1705    0.3871    0.2367    160358\n     Class_2     0.7467    0.3438    0.4708    879521\n     Class_3     0.9767    0.9522    0.9643    320319\n     Class_4     0.1840    0.5001    0.2690    159739\n\n    accuracy                         0.5175   1600000\n   macro avg     0.6019    0.6332    0.5795   1600000\nweighted avg     0.6881    0.5175    0.5503   1600000\n\n============================================================\n\n0:\tlearn: 0.5454378\ttest: 0.5455470\tbest: 0.5455470 (0)\ttotal: 148ms\tremaining: 2m 27s\n100:\tlearn: 0.6322880\ttest: 0.6320860\tbest: 0.6320860 (100)\ttotal: 11.6s\tremaining: 1m 43s\nbestTest = 0.6352133722\nbestIteration = 122\nShrink model to first 123 iterations.\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.581976\n  Best Iteration: 122\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9304    0.9833    0.9561     80063\n     Class_1     0.1701    0.3872    0.2363    160358\n     Class_2     0.7466    0.3544    0.4806    879521\n     Class_3     0.9814    0.9509    0.9659    320319\n     Class_4     0.1866    0.4936    0.2708    159739\n\n    accuracy                         0.5225   1600000\n   macro avg     0.6030    0.6339    0.5820   1600000\nweighted avg     0.6891    0.5225    0.5562   1600000\n\n============================================================\n\n0:\tlearn: 0.5342115\ttest: 0.5344226\tbest: 0.5344226 (0)\ttotal: 153ms\tremaining: 2m 33s\n100:\tlearn: 0.6342320\ttest: 0.6341402\tbest: 0.6341402 (100)\ttotal: 11.5s\tremaining: 1m 42s\nbestTest = 0.6350461219\nbestIteration = 107\nShrink model to first 108 iterations.\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.589576\n  Best Iteration: 107\n\n  Per-Class F1 Scores:\n              precision    recall  f1-score   support\n\n     Class_0     0.9311    0.9825    0.9561     80063\n     Class_1     0.1729    0.3563    0.2328    160358\n     Class_2     0.7436    0.4014    0.5213    879521\n     Class_3     0.9838    0.9527    0.9680    320319\n     Class_4     0.1886    0.4724    0.2696    159739\n\n    accuracy                         0.5434   1600000\n   macro avg     0.6040    0.6331    0.5896   1600000\nweighted avg     0.6885    0.5434    0.5785   1600000\n\n============================================================\n\n\n================================================================================\nCATBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.582844\nStandard Deviation: 0.003559\nMin F1 Score: 0.579498\nMax F1 Score: 0.589576\n\nFold-by-Fold Scores:\n  Fold 1: 0.582352\n  Fold 2: 0.580426\n  Fold 3: 0.579498\n  Fold 4: 0.581976\n  Fold 5: 0.589576\n\n================================================================================\nOVERALL OUT-OF-FOLD PREDICTIONS REPORT\n================================================================================\n              precision    recall  f1-score   support\n\n     Class_0     0.9313    0.9828    0.9563    400313\n     Class_1     0.1707    0.3792    0.2354    801790\n     Class_2     0.7455    0.3604    0.4859   4397607\n     Class_3     0.9816    0.9516    0.9664   1601595\n     Class_4     0.1860    0.4933    0.2701    798695\n\n    accuracy                         0.5251   8000000\n   macro avg     0.6030    0.6334    0.5828   8000000\nweighted avg     0.6886    0.5251    0.5590   8000000\n\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import optuna\nfrom tqdm import trange\n\ndef hyperparameter_tuning(X, y, X_test, n_trials=30):\n    def objective(trial):\n        w1 = trial.suggest_float(\"w1\", 1.0, 6.0)\n        w4 = trial.suggest_float(\"w4\", 1.0, 6.0)\n\n        depth = trial.suggest_int(\"depth\", 5, 9)\n        learning_rate = trial.suggest_float(\"learning_rate\", 0.03, 0.15, log=True)\n        l2_leaf_reg = trial.suggest_float(\"l2_leaf_reg\", 2.0, 10.0)\n        bagging_temperature = trial.suggest_float(\"bagging_temperature\", 0.0, 1.0)\n\n        sample_weight = np.ones(len(y))\n        sample_weight[y == 1] = w1\n        sample_weight[y == 4] = w4\n\n        params = config.get_catboost_params(use_gpu=gpu_config['catboost_gpu'])\n        params.update({\n            \"depth\": depth,\n            \"learning_rate\": learning_rate,\n            \"l2_leaf_reg\": l2_leaf_reg,\n            \"bagging_temperature\": bagging_temperature\n        })\n\n        _, _, score = train_catboost(\n            X,\n            y,\n            X_test,\n            use_gpu=gpu_config['catboost_gpu'],\n            sample_weight=sample_weight,\n            override_params=params\n        )\n\n        print(\n            \"F1={:.6f} | \".format(score) +\n            \" | \".join([f\"{k}={v}\" for k, v in trial.params.items()])\n        )\n\n        return score\n\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"Best Params:\", study.best_params)\n    print(\"Best F1:\", study.best_value)\n\n    return study.best_params\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:46:05.917710Z","iopub.execute_input":"2026-01-14T09:46:05.917982Z","iopub.status.idle":"2026-01-14T09:46:05.925209Z","shell.execute_reply.started":"2026-01-14T09:46:05.917959Z","shell.execute_reply":"2026-01-14T09:46:05.924472Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"try:\n    from catboost import CatBoostClassifier\n    CATBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"CatBoost not available. Install with: pip install catboost\")\n    CATBOOST_AVAILABLE = False\n\n\ndef train_catboost(\n    X_train,\n    y_train,\n    X_test,\n    use_gpu=False,\n    sample_weight=None,\n    override_params=None\n):\n    if not CATBOOST_AVAILABLE:\n        return None, None, None\n\n    if override_params is not None:\n        params = override_params.copy()\n    else:\n        params = config.get_catboost_params(use_gpu=use_gpu)\n\n    if sample_weight is not None:\n        X_tr, X_val, y_tr, y_val, w_tr, w_val = train_test_split(\n            X_train,\n            y_train,\n            sample_weight,\n            test_size=0.2,\n            stratify=y_train,\n            random_state=config.RANDOM_STATE\n        )\n    else:\n        X_tr, X_val, y_tr, y_val = train_test_split(\n            X_train,\n            y_train,\n            test_size=0.2,\n            stratify=y_train,\n            random_state=config.RANDOM_STATE\n        )\n        w_tr = w_val = None\n\n    model = CatBoostClassifier(**params)\n\n    model.fit(\n        X_tr,\n        y_tr,\n        sample_weight=w_tr,\n        eval_set=(X_val, y_val),\n        use_best_model=True\n    )\n\n    val_preds = model.predict_proba(X_val)\n    val_labels = np.argmax(val_preds, axis=1)\n    score = f1_score(y_val, val_labels, average='macro')\n\n    test_preds = model.predict_proba(X_test)\n\n    return test_preds, model, score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:46:08.864711Z","iopub.execute_input":"2026-01-14T09:46:08.865004Z","iopub.status.idle":"2026-01-14T09:46:08.873025Z","shell.execute_reply.started":"2026-01-14T09:46:08.864979Z","shell.execute_reply":"2026-01-14T09:46:08.872185Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"best_params = hyperparameter_tuning(X_train, y_train, X_test, n_trials=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T09:46:11.715825Z","iopub.execute_input":"2026-01-14T09:46:11.716620Z","iopub.status.idle":"2026-01-14T10:01:51.433759Z","shell.execute_reply.started":"2026-01-14T09:46:11.716589Z","shell.execute_reply":"2026-01-14T10:01:51.433020Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:46:11,717]\u001b[0m A new study created in memory with name: no-name-366ff937-d1fb-47fa-83eb-adf4eba1dca4\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"  CatBoost: GPU mode activated\n0:\tlearn: 0.5863739\ttest: 0.6209939\tbest: 0.6209939 (0)\ttotal: 213ms\tremaining: 3m 32s\nbestTest = 0.6286664048\nbestIteration = 46\nShrink model to first 47 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:46:45,618]\u001b[0m Trial 0 finished with value: 0.6205408097407379 and parameters: {'w1': 4.210444733453039, 'w4': 3.2328810908559182, 'depth': 8, 'learning_rate': 0.04675687260969071, 'l2_leaf_reg': 4.971140172994592, 'bagging_temperature': 0.30986099765143993}. Best is trial 0 with value: 0.6205408097407379.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.620541 | w1=4.210444733453039 | w4=3.2328810908559182 | depth=8 | learning_rate=0.04675687260969071 | l2_leaf_reg=4.971140172994592 | bagging_temperature=0.30986099765143993\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6022778\tbest: 0.6022778 (0)\ttotal: 197ms\tremaining: 3m 16s\nbestTest = 0.6328935357\nbestIteration = 28\nShrink model to first 29 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:47:16,659]\u001b[0m Trial 1 finished with value: 0.6072397562194156 and parameters: {'w1': 3.2709275408378122, 'w4': 1.0636383004237544, 'depth': 8, 'learning_rate': 0.0943727061496995, 'l2_leaf_reg': 2.2040992786698643, 'bagging_temperature': 0.5298138141788649}. Best is trial 0 with value: 0.6205408097407379.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.607240 | w1=3.2709275408378122 | w4=1.0636383004237544 | depth=8 | learning_rate=0.0943727061496995 | l2_leaf_reg=2.2040992786698643 | bagging_temperature=0.5298138141788649\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6182566\tbest: 0.6182566 (0)\ttotal: 215ms\tremaining: 3m 34s\nbestTest = 0.6266800144\nbestIteration = 33\nShrink model to first 34 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:47:48,529]\u001b[0m Trial 2 finished with value: 0.6074665032908138 and parameters: {'w1': 2.2434435637123893, 'w4': 2.6724832423090454, 'depth': 8, 'learning_rate': 0.08269553628982862, 'l2_leaf_reg': 4.72935963621157, 'bagging_temperature': 0.5353397662220359}. Best is trial 0 with value: 0.6205408097407379.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.607467 | w1=2.2434435637123893 | w4=2.6724832423090454 | depth=8 | learning_rate=0.08269553628982862 | l2_leaf_reg=4.72935963621157 | bagging_temperature=0.5353397662220359\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5305889\ttest: 0.4785294\tbest: 0.4785294 (0)\ttotal: 150ms\tremaining: 2m 30s\n100:\tlearn: 0.6355536\ttest: 0.5950736\tbest: 0.6267057 (56)\ttotal: 11.3s\tremaining: 1m 40s\nbestTest = 0.6267057291\nbestIteration = 56\nShrink model to first 57 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:48:20,499]\u001b[0m Trial 3 finished with value: 0.6203649006589211 and parameters: {'w1': 5.010092123446122, 'w4': 3.8639818693183408, 'depth': 6, 'learning_rate': 0.061414105987794475, 'l2_leaf_reg': 5.544021672622345, 'bagging_temperature': 0.2943921515512147}. Best is trial 0 with value: 0.6205408097407379.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.620365 | w1=5.010092123446122 | w4=3.8639818693183408 | depth=6 | learning_rate=0.061414105987794475 | l2_leaf_reg=5.544021672622345 | bagging_temperature=0.2943921515512147\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5869356\ttest: 0.6243643\tbest: 0.6243643 (0)\ttotal: 240ms\tremaining: 3m 59s\nbestTest = 0.6264220825\nbestIteration = 34\nShrink model to first 35 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:48:54,286]\u001b[0m Trial 4 finished with value: 0.6222763046956766 and parameters: {'w1': 4.041851856091471, 'w4': 5.305953083177554, 'depth': 9, 'learning_rate': 0.032070403908736146, 'l2_leaf_reg': 2.197672232122904, 'bagging_temperature': 0.11546965146371879}. Best is trial 4 with value: 0.6222763046956766.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622276 | w1=4.041851856091471 | w4=5.305953083177554 | depth=9 | learning_rate=0.032070403908736146 | l2_leaf_reg=2.197672232122904 | bagging_temperature=0.11546965146371879\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5458196\ttest: 0.4959612\tbest: 0.4959612 (0)\ttotal: 169ms\tremaining: 2m 48s\nbestTest = 0.6303643382\nbestIteration = 25\nShrink model to first 26 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:49:23,519]\u001b[0m Trial 5 finished with value: 0.618599844369378 and parameters: {'w1': 3.8396502575968583, 'w4': 2.285385254476006, 'depth': 7, 'learning_rate': 0.10793536867290403, 'l2_leaf_reg': 5.235967049441985, 'bagging_temperature': 0.723659035106762}. Best is trial 4 with value: 0.6222763046956766.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.618600 | w1=3.8396502575968583 | w4=2.285385254476006 | depth=7 | learning_rate=0.10793536867290403 | l2_leaf_reg=5.235967049441985 | bagging_temperature=0.723659035106762\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5305889\ttest: 0.5233098\tbest: 0.5233098 (0)\ttotal: 146ms\tremaining: 2m 25s\n100:\tlearn: 0.6349339\ttest: 0.6201355\tbest: 0.6220316 (88)\ttotal: 11.2s\tremaining: 1m 39s\nbestTest = 0.6220316311\nbestIteration = 88\nShrink model to first 89 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:49:59,179]\u001b[0m Trial 6 finished with value: 0.600388910305376 and parameters: {'w1': 1.6546188272421427, 'w4': 2.946109774489112, 'depth': 6, 'learning_rate': 0.052581833894797064, 'l2_leaf_reg': 4.482051847648073, 'bagging_temperature': 0.21286318904021317}. Best is trial 4 with value: 0.6222763046956766.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.600389 | w1=1.6546188272421427 | w4=2.946109774489112 | depth=6 | learning_rate=0.052581833894797064 | l2_leaf_reg=4.482051847648073 | bagging_temperature=0.21286318904021317\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5298552\ttest: 0.5146680\tbest: 0.5146680 (0)\ttotal: 136ms\tremaining: 2m 15s\n100:\tlearn: 0.6347360\ttest: 0.6144684\tbest: 0.6190875 (67)\ttotal: 9.78s\tremaining: 1m 27s\nbestTest = 0.6190875228\nbestIteration = 67\nShrink model to first 68 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:50:30,817]\u001b[0m Trial 7 finished with value: 0.6203483392243275 and parameters: {'w1': 1.8024880400070238, 'w4': 3.9363871527578818, 'depth': 5, 'learning_rate': 0.060393380475855, 'l2_leaf_reg': 7.55283657703297, 'bagging_temperature': 0.03513390378716175}. Best is trial 4 with value: 0.6222763046956766.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.620348 | w1=1.8024880400070238 | w4=3.9363871527578818 | depth=5 | learning_rate=0.060393380475855 | l2_leaf_reg=7.55283657703297 | bagging_temperature=0.03513390378716175\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5344277\ttest: 0.4958435\tbest: 0.4958435 (0)\ttotal: 135ms\tremaining: 2m 15s\nbestTest = 0.6255308853\nbestIteration = 29\nShrink model to first 30 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:50:58,315]\u001b[0m Trial 8 finished with value: 0.6183687382505697 and parameters: {'w1': 2.905977898803286, 'w4': 3.5607895137012067, 'depth': 5, 'learning_rate': 0.1415957822724907, 'l2_leaf_reg': 7.794119749479293, 'bagging_temperature': 0.6587462569322245}. Best is trial 4 with value: 0.6222763046956766.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.618369 | w1=2.905977898803286 | w4=3.5607895137012067 | depth=5 | learning_rate=0.1415957822724907 | l2_leaf_reg=7.794119749479293 | bagging_temperature=0.6587462569322245\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5352894\ttest: 0.4955818\tbest: 0.4955818 (0)\ttotal: 152ms\tremaining: 2m 31s\n100:\tlearn: 0.6352585\ttest: 0.6043330\tbest: 0.6258475 (65)\ttotal: 11.3s\tremaining: 1m 40s\nbestTest = 0.625847538\nbestIteration = 65\nShrink model to first 66 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:51:31,452]\u001b[0m Trial 9 finished with value: 0.6215929449484145 and parameters: {'w1': 3.4364944991148763, 'w4': 4.543830573071585, 'depth': 6, 'learning_rate': 0.05514187644302009, 'l2_leaf_reg': 9.895293710043193, 'bagging_temperature': 0.34955482659640336}. Best is trial 4 with value: 0.6222763046956766.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.621593 | w1=3.4364944991148763 | w4=4.543830573071585 | depth=6 | learning_rate=0.05514187644302009 | l2_leaf_reg=9.895293710043193 | bagging_temperature=0.34955482659640336\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6253571\tbest: 0.6253571 (0)\ttotal: 217ms\tremaining: 3m 36s\nbestTest = 0.625364181\nbestIteration = 1\nShrink model to first 2 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:51:59,106]\u001b[0m Trial 10 finished with value: 0.6224705782049369 and parameters: {'w1': 5.736167212204467, 'w4': 5.982926870071127, 'depth': 9, 'learning_rate': 0.030167489577246295, 'l2_leaf_reg': 2.0834128123256805, 'bagging_temperature': 0.98691054578401}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622471 | w1=5.736167212204467 | w4=5.982926870071127 | depth=9 | learning_rate=0.030167489577246295 | l2_leaf_reg=2.0834128123256805 | bagging_temperature=0.98691054578401\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6252318\tbest: 0.6252318 (0)\ttotal: 242ms\tremaining: 4m 1s\nbestTest = 0.6252441241\nbestIteration = 1\nShrink model to first 2 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:52:26,870]\u001b[0m Trial 11 finished with value: 0.6224705782049369 and parameters: {'w1': 5.993678672640531, 'w4': 5.513873394022275, 'depth': 9, 'learning_rate': 0.03023427221849809, 'l2_leaf_reg': 2.2951459597692483, 'bagging_temperature': 0.9626328294986388}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622471 | w1=5.993678672640531 | w4=5.513873394022275 | depth=9 | learning_rate=0.03023427221849809 | l2_leaf_reg=2.2951459597692483 | bagging_temperature=0.9626328294986388\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6252616\tbest: 0.6252616 (0)\ttotal: 217ms\tremaining: 3m 37s\nbestTest = 0.6260083019\nbestIteration = 37\nShrink model to first 38 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:53:01,172]\u001b[0m Trial 12 finished with value: 0.6222870326194945 and parameters: {'w1': 5.919636850362585, 'w4': 5.972380427022581, 'depth': 9, 'learning_rate': 0.03227970182583358, 'l2_leaf_reg': 3.4025049836310832, 'bagging_temperature': 0.9854889352190476}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622287 | w1=5.919636850362585 | w4=5.972380427022581 | depth=9 | learning_rate=0.03227970182583358 | l2_leaf_reg=3.4025049836310832 | bagging_temperature=0.9854889352190476\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6252348\tbest: 0.6252348 (0)\ttotal: 222ms\tremaining: 3m 41s\nbestTest = 0.6252420554\nbestIteration = 1\nShrink model to first 2 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:53:28,980]\u001b[0m Trial 13 finished with value: 0.6224705782049369 and parameters: {'w1': 5.969173766061789, 'w4': 5.964085291122286, 'depth': 9, 'learning_rate': 0.040872766345537395, 'l2_leaf_reg': 3.2838268328941234, 'bagging_temperature': 0.9910169513555149}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622471 | w1=5.969173766061789 | w4=5.964085291122286 | depth=9 | learning_rate=0.040872766345537395 | l2_leaf_reg=3.2838268328941234 | bagging_temperature=0.9910169513555149\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6254747\tbest: 0.6254747 (0)\ttotal: 219ms\tremaining: 3m 39s\nbestTest = 0.6267130346\nbestIteration = 48\nShrink model to first 49 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:54:05,446]\u001b[0m Trial 14 finished with value: 0.6224579290400396 and parameters: {'w1': 5.160479364719077, 'w4': 4.85148811821969, 'depth': 9, 'learning_rate': 0.0404015458921903, 'l2_leaf_reg': 3.3985320935180914, 'bagging_temperature': 0.8392281281642492}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622458 | w1=5.160479364719077 | w4=4.85148811821969 | depth=9 | learning_rate=0.0404015458921903 | l2_leaf_reg=3.3985320935180914 | bagging_temperature=0.8392281281642492\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6254561\tbest: 0.6254561 (0)\ttotal: 197ms\tremaining: 3m 17s\nbestTest = 0.6254992505\nbestIteration = 1\nShrink model to first 2 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:54:31,919]\u001b[0m Trial 15 finished with value: 0.6221099447276225 and parameters: {'w1': 4.955043529596605, 'w4': 5.199914624497079, 'depth': 8, 'learning_rate': 0.030307618999206917, 'l2_leaf_reg': 2.0993000375946647, 'bagging_temperature': 0.8398696132673703}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622110 | w1=4.955043529596605 | w4=5.199914624497079 | depth=8 | learning_rate=0.030307618999206917 | l2_leaf_reg=2.0993000375946647 | bagging_temperature=0.8398696132673703\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5458196\ttest: 0.4816724\tbest: 0.4816724 (0)\ttotal: 169ms\tremaining: 2m 48s\n100:\tlearn: 0.6303703\ttest: 0.6044944\tbest: 0.6247473 (54)\ttotal: 12.7s\tremaining: 1m 53s\nbestTest = 0.6247472674\nbestIteration = 54\nShrink model to first 55 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:55:04,882]\u001b[0m Trial 16 finished with value: 0.6210526370934588 and parameters: {'w1': 5.591074553064514, 'w4': 5.471116479746963, 'depth': 7, 'learning_rate': 0.04134865499912778, 'l2_leaf_reg': 6.926371368024573, 'bagging_temperature': 0.8553265260465208}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.621053 | w1=5.591074553064514 | w4=5.471116479746963 | depth=7 | learning_rate=0.04134865499912778 | l2_leaf_reg=6.926371368024573 | bagging_temperature=0.8553265260465208\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5458196\ttest: 0.4895551\tbest: 0.4895551 (0)\ttotal: 169ms\tremaining: 2m 48s\n100:\tlearn: 0.6280503\ttest: 0.6137656\tbest: 0.6258918 (67)\ttotal: 12.6s\tremaining: 1m 52s\nbestTest = 0.6258918212\nbestIteration = 67\nShrink model to first 68 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:55:39,728]\u001b[0m Trial 17 finished with value: 0.6206541099295703 and parameters: {'w1': 4.5955444166216015, 'w4': 4.549463757436845, 'depth': 7, 'learning_rate': 0.03862611949203733, 'l2_leaf_reg': 3.5154589247472448, 'bagging_temperature': 0.6504801220480845}. Best is trial 10 with value: 0.6224705782049369.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.620654 | w1=4.5955444166216015 | w4=4.549463757436845 | depth=7 | learning_rate=0.03862611949203733 | l2_leaf_reg=3.5154589247472448 | bagging_temperature=0.6504801220480845\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6255422\tbest: 0.6255422 (0)\ttotal: 243ms\tremaining: 4m 3s\nbestTest = 0.6263162339\nbestIteration = 22\nShrink model to first 23 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:56:11,543]\u001b[0m Trial 18 finished with value: 0.6224837896192785 and parameters: {'w1': 5.386443514823416, 'w4': 5.586147671866693, 'depth': 9, 'learning_rate': 0.07395049293843245, 'l2_leaf_reg': 3.822297471309259, 'bagging_temperature': 0.9039027751255211}. Best is trial 18 with value: 0.6224837896192785.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622484 | w1=5.386443514823416 | w4=5.586147671866693 | depth=9 | learning_rate=0.07395049293843245 | l2_leaf_reg=3.822297471309259 | bagging_temperature=0.9039027751255211\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6160463\tbest: 0.6160463 (0)\ttotal: 197ms\tremaining: 3m 17s\nbestTest = 0.6305364961\nbestIteration = 34\nShrink model to first 35 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:56:43,627]\u001b[0m Trial 19 finished with value: 0.6150026318496781 and parameters: {'w1': 5.3165025673506285, 'w4': 1.97565663578755, 'depth': 8, 'learning_rate': 0.07224632560617361, 'l2_leaf_reg': 3.9528978153406205, 'bagging_temperature': 0.7579918308055194}. Best is trial 18 with value: 0.6224837896192785.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.615003 | w1=5.3165025673506285 | w4=1.97565663578755 | depth=8 | learning_rate=0.07224632560617361 | l2_leaf_reg=3.9528978153406205 | bagging_temperature=0.7579918308055194\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6253709\tbest: 0.6253709 (0)\ttotal: 218ms\tremaining: 3m 37s\nbestTest = 0.6272529212\nbestIteration = 26\nShrink model to first 27 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:57:16,195]\u001b[0m Trial 20 finished with value: 0.622055567254878 and parameters: {'w1': 4.4876815373493155, 'w4': 4.446077856875467, 'depth': 9, 'learning_rate': 0.07055029489432474, 'l2_leaf_reg': 6.430360634641575, 'bagging_temperature': 0.8642705450445435}. Best is trial 18 with value: 0.6224837896192785.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622056 | w1=4.4876815373493155 | w4=4.446077856875467 | depth=9 | learning_rate=0.07055029489432474 | l2_leaf_reg=6.430360634641575 | bagging_temperature=0.8642705450445435\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6254443\tbest: 0.6254443 (0)\ttotal: 244ms\tremaining: 4m 3s\nbestTest = 0.6262243227\nbestIteration = 37\nShrink model to first 38 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:57:50,600]\u001b[0m Trial 21 finished with value: 0.6225998558579171 and parameters: {'w1': 5.552046178107874, 'w4': 5.980427231157116, 'depth': 9, 'learning_rate': 0.03596782998335049, 'l2_leaf_reg': 3.036771428141212, 'bagging_temperature': 0.9596185612889777}. Best is trial 21 with value: 0.6225998558579171.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622600 | w1=5.552046178107874 | w4=5.980427231157116 | depth=9 | learning_rate=0.03596782998335049 | l2_leaf_reg=3.036771428141212 | bagging_temperature=0.9596185612889777\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6254764\tbest: 0.6254764 (0)\ttotal: 228ms\tremaining: 3m 47s\nbestTest = 0.6263984465\nbestIteration = 32\nShrink model to first 33 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:58:24,301]\u001b[0m Trial 22 finished with value: 0.6226357267112377 and parameters: {'w1': 5.510053045205501, 'w4': 5.872621205920762, 'depth': 9, 'learning_rate': 0.037421516723905195, 'l2_leaf_reg': 3.0028987484089007, 'bagging_temperature': 0.9109298731391929}. Best is trial 22 with value: 0.6226357267112377.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622636 | w1=5.510053045205501 | w4=5.872621205920762 | depth=9 | learning_rate=0.037421516723905195 | l2_leaf_reg=3.0028987484089007 | bagging_temperature=0.9109298731391929\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6254767\tbest: 0.6254767 (0)\ttotal: 201ms\tremaining: 3m 21s\nbestTest = 0.6260678517\nbestIteration = 42\nShrink model to first 43 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:58:57,681]\u001b[0m Trial 23 finished with value: 0.6216522044821756 and parameters: {'w1': 4.745931621039325, 'w4': 5.152604310400486, 'depth': 8, 'learning_rate': 0.049771772224239584, 'l2_leaf_reg': 2.9471138471935276, 'bagging_temperature': 0.7588808376944465}. Best is trial 22 with value: 0.6226357267112377.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.621652 | w1=4.745931621039325 | w4=5.152604310400486 | depth=8 | learning_rate=0.049771772224239584 | l2_leaf_reg=2.9471138471935276 | bagging_temperature=0.7588808376944465\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5906568\ttest: 0.6255645\tbest: 0.6255645 (0)\ttotal: 242ms\tremaining: 4m 1s\nbestTest = 0.6264692942\nbestIteration = 14\nShrink model to first 15 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:59:28,096]\u001b[0m Trial 24 finished with value: 0.6225707528120683 and parameters: {'w1': 5.327312394156717, 'w4': 5.654889915714894, 'depth': 9, 'learning_rate': 0.08081670900068762, 'l2_leaf_reg': 3.9967909237423305, 'bagging_temperature': 0.44285124373609336}. Best is trial 22 with value: 0.6226357267112377.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622571 | w1=5.327312394156717 | w4=5.654889915714894 | depth=9 | learning_rate=0.08081670900068762 | l2_leaf_reg=3.9967909237423305 | bagging_temperature=0.44285124373609336\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6252129\tbest: 0.6252129 (0)\ttotal: 206ms\tremaining: 3m 25s\nbestTest = 0.6266780525\nbestIteration = 13\nShrink model to first 14 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 09:59:56,601]\u001b[0m Trial 25 finished with value: 0.6226484137472658 and parameters: {'w1': 5.414985685518008, 'w4': 4.893891944937886, 'depth': 8, 'learning_rate': 0.11368733887054407, 'l2_leaf_reg': 4.176888037025979, 'bagging_temperature': 0.4237689075478037}. Best is trial 25 with value: 0.6226484137472658.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622648 | w1=5.414985685518008 | w4=4.893891944937886 | depth=8 | learning_rate=0.11368733887054407 | l2_leaf_reg=4.176888037025979 | bagging_temperature=0.4237689075478037\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6253522\tbest: 0.6253522 (0)\ttotal: 199ms\tremaining: 3m 19s\nbestTest = 0.626857531\nbestIteration = 12\nShrink model to first 13 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 10:00:25,232]\u001b[0m Trial 26 finished with value: 0.6226653916052056 and parameters: {'w1': 4.373361134673418, 'w4': 4.785402753592892, 'depth': 8, 'learning_rate': 0.11674784139741157, 'l2_leaf_reg': 2.7941734400739326, 'bagging_temperature': 0.44822342947876326}. Best is trial 26 with value: 0.6226653916052056.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622665 | w1=4.373361134673418 | w4=4.785402753592892 | depth=8 | learning_rate=0.11674784139741157 | l2_leaf_reg=2.7941734400739326 | bagging_temperature=0.44822342947876326\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6249065\tbest: 0.6249065 (0)\ttotal: 199ms\tremaining: 3m 19s\nbestTest = 0.6267035788\nbestIteration = 15\nShrink model to first 16 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 10:00:54,194]\u001b[0m Trial 27 finished with value: 0.6224001636303741 and parameters: {'w1': 4.176391848776233, 'w4': 4.182540989802282, 'depth': 8, 'learning_rate': 0.13047712112340862, 'l2_leaf_reg': 2.78538489247834, 'bagging_temperature': 0.43079441857029555}. Best is trial 26 with value: 0.6226653916052056.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622400 | w1=4.176391848776233 | w4=4.182540989802282 | depth=8 | learning_rate=0.13047712112340862 | l2_leaf_reg=2.78538489247834 | bagging_temperature=0.43079441857029555\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5458196\ttest: 0.5081040\tbest: 0.5081040 (0)\ttotal: 168ms\tremaining: 2m 47s\nbestTest = 0.6244724829\nbestIteration = 21\nShrink model to first 22 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 10:01:22,890]\u001b[0m Trial 28 finished with value: 0.6222216755378245 and parameters: {'w1': 2.912487488937776, 'w4': 4.745486162831782, 'depth': 7, 'learning_rate': 0.10634934547388318, 'l2_leaf_reg': 4.105633445902795, 'bagging_temperature': 0.6034017639061069}. Best is trial 26 with value: 0.6226653916052056.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622222 | w1=2.912487488937776 | w4=4.745486162831782 | depth=7 | learning_rate=0.10634934547388318 | l2_leaf_reg=4.105633445902795 | bagging_temperature=0.6034017639061069\n  CatBoost: GPU mode activated\n0:\tlearn: 0.5902393\ttest: 0.6254316\tbest: 0.6254316 (0)\ttotal: 202ms\tremaining: 3m 21s\nbestTest = 0.6268661218\nbestIteration = 12\nShrink model to first 13 iterations.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2026-01-14 10:01:51,429]\u001b[0m Trial 29 finished with value: 0.6226753377517147 and parameters: {'w1': 4.509194597384958, 'w4': 4.96455487505969, 'depth': 8, 'learning_rate': 0.12417373275177125, 'l2_leaf_reg': 5.779911380449872, 'bagging_temperature': 0.37002965644391456}. Best is trial 29 with value: 0.6226753377517147.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"F1=0.622675 | w1=4.509194597384958 | w4=4.96455487505969 | depth=8 | learning_rate=0.12417373275177125 | l2_leaf_reg=5.779911380449872 | bagging_temperature=0.37002965644391456\nBest Params: {'w1': 4.509194597384958, 'w4': 4.96455487505969, 'depth': 8, 'learning_rate': 0.12417373275177125, 'l2_leaf_reg': 5.779911380449872, 'bagging_temperature': 0.37002965644391456}\nBest F1: 0.6226753377517147\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"try:\n    from catboost import CatBoostClassifier\n    CATBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"CatBoost not available. Install with: pip install catboost\")\n    CATBOOST_AVAILABLE = False\n\n\ndef train_catboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n    print(\"\\n\" + \"=\" * 80)\n    print(\"Training CatBoost Models\")\n    print(\"=\" * 80)\n\n    num_classes = len(np.unique(y_train))\n\n    # === CLASS WEIGHT (ikut logic w1 & w4 kamu) ===\n    class_weights = np.ones(num_classes)\n    class_weights[1] = best_params[\"w1\"]\n    class_weights[4] = best_params[\"w4\"]\n\n    # === PARAMS ===\n    params = {\n        \"loss_function\": \"MultiClass\",\n        \"eval_metric\": \"TotalF1\",\n        \"iterations\": 3000,\n        \"learning_rate\": best_params[\"learning_rate\"],\n        \"depth\": best_params[\"depth\"],\n        \"l2_leaf_reg\": best_params[\"l2_leaf_reg\"],\n        \"bagging_temperature\": best_params[\"bagging_temperature\"],\n        \"class_weights\": class_weights.tolist(),\n        \"random_seed\": config.RANDOM_STATE,\n        \"early_stopping_rounds\": 100,\n        \"verbose\": 100,\n        \"task_type\": \"GPU\" if use_gpu else \"CPU\",\n    }\n\n    skf = StratifiedKFold(\n        n_splits=n_folds,\n        shuffle=True,\n        random_state=config.RANDOM_STATE\n    )\n\n    oof_predictions = np.zeros((len(X_train), num_classes))\n    test_predictions = np.zeros((len(X_test), num_classes))\n\n    fold_scores = []\n    models = []\n\n    pbar = tqdm(\n        enumerate(skf.split(X_train, y_train), 1),\n        total=n_folds,\n        desc=\"CatBoost Folds\"\n    )\n\n    for fold, (train_idx, val_idx) in pbar:\n        pbar.set_description(f\"CatBoost Fold {fold}/{n_folds}\")\n\n        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n\n        model = CatBoostClassifier(**params)\n\n        model.fit(\n            X_tr,\n            y_tr,\n            eval_set=(X_val, y_val),\n            use_best_model=True\n        )\n\n        oof_predictions[val_idx] = model.predict_proba(X_val)\n        test_predictions += model.predict_proba(X_test) / n_folds\n\n        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n        fold_score = f1_score(y_val, oof_pred_labels, average=\"macro\")\n        fold_scores.append(fold_score)\n\n        print(\"\\n\" + \"=\" * 60)\n        print(f\"FOLD {fold} SUMMARY:\")\n        print(\"=\" * 60)\n        print(f\"  Validation F1 (Macro): {fold_score:.6f}\")\n        print(f\"  Best Iteration: {model.get_best_iteration()}\")\n\n        print(\n            classification_report(\n                y_val,\n                oof_pred_labels,\n                target_names=[f\"Class_{i}\" for i in range(num_classes)],\n                digits=4\n            )\n        )\n        print(\"=\" * 60 + \"\\n\")\n\n        pbar.set_postfix({\"F1\": f\"{fold_score:.6f}\"})\n\n        models.append(model)\n        gc.collect()\n\n    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n    overall_score = f1_score(y_train, oof_pred_labels, average=\"macro\")\n\n    print(\"\\n\" + \"=\" * 80)\n    print(\"CATBOOST TRAINING SUMMARY\")\n    print(\"=\" * 80)\n    print(f\"Overall CV Score (Macro F1): {overall_score:.6f}\")\n    print(f\"Standard Deviation: {np.std(fold_scores):.6f}\")\n    print(f\"Min F1 Score: {np.min(fold_scores):.6f}\")\n    print(f\"Max F1 Score: {np.max(fold_scores):.6f}\")\n\n    return oof_predictions, test_predictions, models, overall_score\n\nif CATBOOST_AVAILABLE:\n    cb_oof_pred, cb_test_pred, cb_models, cb_cv_score = train_catboost(\n        X_train,\n        y_train,\n        X_test,\n        n_folds=config.N_FOLDS,\n        use_gpu=gpu_config['catboost_gpu']\n    )\n\nelse:\n    cb_oof_pred, cb_test_pred, cb_models, cb_cv_score = None, None, 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T10:17:46.545941Z","iopub.execute_input":"2026-01-14T10:17:46.546287Z","iopub.status.idle":"2026-01-14T10:28:28.492548Z","shell.execute_reply.started":"2026-01-14T10:17:46.546259Z","shell.execute_reply":"2026-01-14T10:28:28.491906Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nTraining CatBoost Models\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"CatBoost Folds:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df041c2bdba4962aad15005d69faa3a"}},"metadata":{}},{"name":"stdout","text":"0:\tlearn: 0.4272947\ttest: 0.4281549\tbest: 0.4281549 (0)\ttotal: 110ms\tremaining: 5m 30s\n100:\tlearn: 0.4699608\ttest: 0.4697722\tbest: 0.4697732 (99)\ttotal: 7.89s\tremaining: 3m 46s\n200:\tlearn: 0.4741527\ttest: 0.4717562\tbest: 0.4717562 (200)\ttotal: 16.4s\tremaining: 3m 47s\n300:\tlearn: 0.4785393\ttest: 0.4722303\tbest: 0.4723355 (294)\ttotal: 25.6s\tremaining: 3m 49s\n400:\tlearn: 0.4830399\ttest: 0.4728535\tbest: 0.4729747 (392)\ttotal: 35s\tremaining: 3m 46s\n500:\tlearn: 0.4872333\ttest: 0.4731926\tbest: 0.4732673 (486)\ttotal: 44.2s\tremaining: 3m 40s\n600:\tlearn: 0.4919702\ttest: 0.4736170\tbest: 0.4737791 (589)\ttotal: 53.4s\tremaining: 3m 33s\n700:\tlearn: 0.4969242\ttest: 0.4740465\tbest: 0.4741065 (695)\ttotal: 1m 2s\tremaining: 3m 25s\n800:\tlearn: 0.5017972\ttest: 0.4748827\tbest: 0.4748827 (800)\ttotal: 1m 11s\tremaining: 3m 17s\n900:\tlearn: 0.5062615\ttest: 0.4748411\tbest: 0.4750257 (840)\ttotal: 1m 21s\tremaining: 3m 9s\n1000:\tlearn: 0.5107265\ttest: 0.4750901\tbest: 0.4751585 (991)\ttotal: 1m 30s\tremaining: 3m 1s\n1100:\tlearn: 0.5152471\ttest: 0.4752881\tbest: 0.4753113 (1072)\ttotal: 1m 40s\tremaining: 2m 52s\n1200:\tlearn: 0.5196689\ttest: 0.4755955\tbest: 0.4756077 (1198)\ttotal: 1m 49s\tremaining: 2m 44s\n1300:\tlearn: 0.5239759\ttest: 0.4759048\tbest: 0.4759485 (1299)\ttotal: 1m 59s\tremaining: 2m 35s\n1400:\tlearn: 0.5282331\ttest: 0.4760046\tbest: 0.4760253 (1399)\ttotal: 2m 8s\tremaining: 2m 26s\n1500:\tlearn: 0.5323151\ttest: 0.4759790\tbest: 0.4762769 (1428)\ttotal: 2m 18s\tremaining: 2m 17s\nbestTest = 0.476276906\nbestIteration = 1428\nShrink model to first 1429 iterations.\n\n============================================================\nFOLD 1 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.623596\n  Best Iteration: 1428\n              precision    recall  f1-score   support\n\n     Class_0     0.9947    0.9807    0.9876     80062\n     Class_1     0.2288    0.1570    0.1862    160358\n     Class_2     0.7403    0.6727    0.7049    879522\n     Class_3     0.9944    0.9522    0.9728    320319\n     Class_4     0.2029    0.3876    0.2664    159739\n\n    accuracy                         0.6639   1600000\n   macro avg     0.6322    0.6300    0.6236   1600000\nweighted avg     0.6990    0.6639    0.6769   1600000\n\n============================================================\n\n0:\tlearn: 0.4272344\ttest: 0.4271756\tbest: 0.4271756 (0)\ttotal: 111ms\tremaining: 5m 33s\n100:\tlearn: 0.4695930\ttest: 0.4693189\tbest: 0.4693416 (99)\ttotal: 8.01s\tremaining: 3m 49s\n200:\tlearn: 0.4735255\ttest: 0.4714848\tbest: 0.4715024 (199)\ttotal: 16.1s\tremaining: 3m 44s\n300:\tlearn: 0.4776681\ttest: 0.4723720\tbest: 0.4723928 (277)\ttotal: 25s\tremaining: 3m 44s\n400:\tlearn: 0.4820682\ttest: 0.4728107\tbest: 0.4730043 (381)\ttotal: 34.5s\tremaining: 3m 43s\n500:\tlearn: 0.4865312\ttest: 0.4732333\tbest: 0.4732485 (488)\ttotal: 43.8s\tremaining: 3m 38s\n600:\tlearn: 0.4912990\ttest: 0.4737376\tbest: 0.4737376 (600)\ttotal: 53.2s\tremaining: 3m 32s\n700:\tlearn: 0.4959434\ttest: 0.4740851\tbest: 0.4742329 (696)\ttotal: 1m 2s\tremaining: 3m 24s\n800:\tlearn: 0.5007143\ttest: 0.4744774\tbest: 0.4744774 (800)\ttotal: 1m 11s\tremaining: 3m 17s\n900:\tlearn: 0.5054688\ttest: 0.4747144\tbest: 0.4747144 (900)\ttotal: 1m 21s\tremaining: 3m 9s\n1000:\tlearn: 0.5099453\ttest: 0.4746968\tbest: 0.4748303 (994)\ttotal: 1m 30s\tremaining: 3m\n1100:\tlearn: 0.5142910\ttest: 0.4748378\tbest: 0.4749293 (1043)\ttotal: 1m 39s\tremaining: 2m 52s\n1200:\tlearn: 0.5188693\ttest: 0.4750526\tbest: 0.4751062 (1197)\ttotal: 1m 49s\tremaining: 2m 43s\n1300:\tlearn: 0.5230895\ttest: 0.4751823\tbest: 0.4752841 (1276)\ttotal: 1m 58s\tremaining: 2m 35s\nbestTest = 0.4752840608\nbestIteration = 1276\nShrink model to first 1277 iterations.\n\n============================================================\nFOLD 2 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.623572\n  Best Iteration: 1276\n              precision    recall  f1-score   support\n\n     Class_0     0.9949    0.9806    0.9877     80062\n     Class_1     0.2324    0.1536    0.1850    160358\n     Class_2     0.7396    0.6764    0.7066    879522\n     Class_3     0.9946    0.9522    0.9730    320319\n     Class_4     0.2026    0.3857    0.2657    159739\n\n    accuracy                         0.6654   1600000\n   macro avg     0.6328    0.6297    0.6236   1600000\nweighted avg     0.6990    0.6654    0.6777   1600000\n\n============================================================\n\n0:\tlearn: 0.4278919\ttest: 0.4270996\tbest: 0.4270996 (0)\ttotal: 111ms\tremaining: 5m 33s\n100:\tlearn: 0.4699422\ttest: 0.4688464\tbest: 0.4688464 (100)\ttotal: 8.01s\tremaining: 3m 49s\n200:\tlearn: 0.4741922\ttest: 0.4706731\tbest: 0.4708060 (196)\ttotal: 16.2s\tremaining: 3m 45s\n300:\tlearn: 0.4782025\ttest: 0.4714065\tbest: 0.4714966 (288)\ttotal: 25.3s\tremaining: 3m 46s\n400:\tlearn: 0.4827709\ttest: 0.4719047\tbest: 0.4719881 (396)\ttotal: 34.7s\tremaining: 3m 44s\n500:\tlearn: 0.4874058\ttest: 0.4724222\tbest: 0.4724222 (500)\ttotal: 44.2s\tremaining: 3m 40s\n600:\tlearn: 0.4922960\ttest: 0.4725019\tbest: 0.4725562 (598)\ttotal: 53.6s\tremaining: 3m 33s\n700:\tlearn: 0.4968447\ttest: 0.4725291\tbest: 0.4727993 (617)\ttotal: 1m 2s\tremaining: 3m 26s\nbestTest = 0.4727993294\nbestIteration = 617\nShrink model to first 618 iterations.\n\n============================================================\nFOLD 3 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.624057\n  Best Iteration: 617\n              precision    recall  f1-score   support\n\n     Class_0     0.9942    0.9812    0.9877     80063\n     Class_1     0.2502    0.1385    0.1783    160358\n     Class_2     0.7400    0.6922    0.7153    879521\n     Class_3     0.9940    0.9517    0.9724    320319\n     Class_4     0.2036    0.3860    0.2666    159739\n\n    accuracy                         0.6725   1600000\n   macro avg     0.6364    0.6299    0.6241   1600000\nweighted avg     0.7009    0.6725    0.6818   1600000\n\n============================================================\n\n0:\tlearn: 0.4272886\ttest: 0.4272181\tbest: 0.4272181 (0)\ttotal: 110ms\tremaining: 5m 30s\n100:\tlearn: 0.4694897\ttest: 0.4688480\tbest: 0.4688480 (100)\ttotal: 7.86s\tremaining: 3m 45s\n200:\tlearn: 0.4737736\ttest: 0.4707293\tbest: 0.4707421 (199)\ttotal: 15.9s\tremaining: 3m 41s\n300:\tlearn: 0.4781105\ttest: 0.4715312\tbest: 0.4715992 (296)\ttotal: 24.9s\tremaining: 3m 43s\n400:\tlearn: 0.4826853\ttest: 0.4723377\tbest: 0.4723404 (398)\ttotal: 34s\tremaining: 3m 40s\n500:\tlearn: 0.4873114\ttest: 0.4727448\tbest: 0.4727569 (499)\ttotal: 43.5s\tremaining: 3m 37s\n600:\tlearn: 0.4919025\ttest: 0.4731127\tbest: 0.4731528 (598)\ttotal: 52.9s\tremaining: 3m 31s\n700:\tlearn: 0.4964836\ttest: 0.4734131\tbest: 0.4734426 (665)\ttotal: 1m 2s\tremaining: 3m 23s\n800:\tlearn: 0.5011502\ttest: 0.4736104\tbest: 0.4737058 (784)\ttotal: 1m 11s\tremaining: 3m 16s\n900:\tlearn: 0.5059017\ttest: 0.4741499\tbest: 0.4741499 (900)\ttotal: 1m 20s\tremaining: 3m 8s\n1000:\tlearn: 0.5104609\ttest: 0.4741939\tbest: 0.4743710 (981)\ttotal: 1m 30s\tremaining: 3m\n1100:\tlearn: 0.5148650\ttest: 0.4744248\tbest: 0.4745756 (1086)\ttotal: 1m 39s\tremaining: 2m 51s\n1200:\tlearn: 0.5192812\ttest: 0.4747280\tbest: 0.4749310 (1177)\ttotal: 1m 48s\tremaining: 2m 43s\n1300:\tlearn: 0.5235137\ttest: 0.4752049\tbest: 0.4752419 (1298)\ttotal: 1m 58s\tremaining: 2m 34s\n1400:\tlearn: 0.5278832\ttest: 0.4752234\tbest: 0.4754833 (1377)\ttotal: 2m 8s\tremaining: 2m 26s\nbestTest = 0.4754833337\nbestIteration = 1377\nShrink model to first 1378 iterations.\n\n============================================================\nFOLD 4 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.623864\n  Best Iteration: 1377\n              precision    recall  f1-score   support\n\n     Class_0     0.9942    0.9822    0.9882     80063\n     Class_1     0.2302    0.1564    0.1863    160358\n     Class_2     0.7404    0.6765    0.7070    879521\n     Class_3     0.9939    0.9527    0.9729    320319\n     Class_4     0.2027    0.3824    0.2650    159739\n\n    accuracy                         0.6656   1600000\n   macro avg     0.6323    0.6300    0.6239   1600000\nweighted avg     0.6991    0.6656    0.6780   1600000\n\n============================================================\n\n0:\tlearn: 0.4275133\ttest: 0.4275542\tbest: 0.4275542 (0)\ttotal: 109ms\tremaining: 5m 26s\n100:\tlearn: 0.4699338\ttest: 0.4692700\tbest: 0.4692700 (100)\ttotal: 7.98s\tremaining: 3m 49s\n200:\tlearn: 0.4739010\ttest: 0.4709508\tbest: 0.4709508 (200)\ttotal: 16.2s\tremaining: 3m 44s\n300:\tlearn: 0.4781796\ttest: 0.4718455\tbest: 0.4718455 (300)\ttotal: 25.3s\tremaining: 3m 46s\n400:\tlearn: 0.4823887\ttest: 0.4722131\tbest: 0.4722847 (387)\ttotal: 34.7s\tremaining: 3m 44s\n500:\tlearn: 0.4869292\ttest: 0.4727747\tbest: 0.4728234 (499)\ttotal: 44.2s\tremaining: 3m 40s\n600:\tlearn: 0.4916343\ttest: 0.4730320\tbest: 0.4730491 (535)\ttotal: 53.5s\tremaining: 3m 33s\nbestTest = 0.4730491186\nbestIteration = 535\nShrink model to first 536 iterations.\n\n============================================================\nFOLD 5 SUMMARY:\n============================================================\n  Validation F1 (Macro): 0.624851\n  Best Iteration: 535\n              precision    recall  f1-score   support\n\n     Class_0     0.9943    0.9811    0.9876     80063\n     Class_1     0.2516    0.1373    0.1777    160358\n     Class_2     0.7403    0.6972    0.7181    879521\n     Class_3     0.9943    0.9527    0.9730    320319\n     Class_4     0.2056    0.3840    0.2678    159739\n\n    accuracy                         0.6751   1600000\n   macro avg     0.6372    0.6304    0.6249   1600000\nweighted avg     0.7015    0.6751    0.6835   1600000\n\n============================================================\n\n\n================================================================================\nCATBOOST TRAINING SUMMARY\n================================================================================\nOverall CV Score (Macro F1): 0.624024\nStandard Deviation: 0.000467\nMin F1 Score: 0.623572\nMax F1 Score: 0.624851\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*80)\nprint(\"MODEL EVALUATION\")\nprint(\"=\"*80)\n\nif cb_test_pred is not None:\n    print(f\"\\n CatBoost Model Successfully Trained\")\n    print(f\"  Cross-Validation Score: {cb_cv_score:.6f}\")\n    print(f\"  Model Type: CatBoost with {'GPU' if gpu_config['catboost_gpu'] else 'CPU'} acceleration\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"GENERATING PREDICTIONS ON TEST SET\")\n    print(\"=\"*80)\n\n    final_predictions = cb_test_pred\n    final_pred_labels = np.argmax(final_predictions, axis=1)\n\n    print(f\"\\n Predictions Generated Successfully\")\n    print(f\"  Total test samples: {len(final_pred_labels):,}\")\n    print(f\"  Prediction shape: {final_predictions.shape}\")\n    print(f\"  Classes predicted: {len(np.unique(final_pred_labels))}\")\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"PREDICTION DISTRIBUTION\")\n    print(\"=\"*80)\n\n    unique, counts = np.unique(final_pred_labels, return_counts=True)\n    for class_idx, count in zip(unique, counts):\n        percentage = (count / len(final_pred_labels)) * 100\n        print(f\"  Class {class_idx}: {count:,} samples ({percentage:.2f}%)\")\n\nelse:\n    raise ValueError(\"CatBoost model training failed! Cannot generate predictions.\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T10:28:28.494045Z","iopub.execute_input":"2026-01-14T10:28:28.494627Z","iopub.status.idle":"2026-01-14T10:28:28.609447Z","shell.execute_reply.started":"2026-01-14T10:28:28.494603Z","shell.execute_reply":"2026-01-14T10:28:28.608657Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nMODEL EVALUATION\n================================================================================\n\n CatBoost Model Successfully Trained\n  Cross-Validation Score: 0.624024\n  Model Type: CatBoost with GPU acceleration\n\n================================================================================\nGENERATING PREDICTIONS ON TEST SET\n================================================================================\n\n Predictions Generated Successfully\n  Total test samples: 4,000,000\n  Prediction shape: (4000000, 5)\n  Classes predicted: 5\n\n================================================================================\nPREDICTION DISTRIBUTION\n================================================================================\n  Class 0: 198,190 samples (4.95%)\n  Class 1: 228,760 samples (5.72%)\n  Class 2: 2,048,676 samples (51.22%)\n  Class 3: 791,126 samples (19.78%)\n  Class 4: 733,248 samples (18.33%)\n\n================================================================================\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n    pred_labels = le_target.inverse_transform(predictions)\n    \n    submission = pd.DataFrame({\n        config.ID_COL: test_ids,\n        config.TARGET_COL: pred_labels\n    })\n    \n    submission.to_csv(filename, index=False)\n    \n    print(f\"\\nSubmission saved to: {filename}\")\n    print(f\"Submission shape: {submission.shape}\")\n    print(f\"\\nPrediction distribution:\")\n    print(submission[config.TARGET_COL].value_counts())\n    \n    return submission\n\ntest_ids = test[config.ID_COL].values\nsubmission = create_submission(test_ids, final_pred_labels, le_target, 'anava_deira_12.csv')\nsubmission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T10:28:28.610568Z","iopub.execute_input":"2026-01-14T10:28:28.610927Z","iopub.status.idle":"2026-01-14T10:28:33.370653Z","shell.execute_reply.started":"2026-01-14T10:28:28.610894Z","shell.execute_reply":"2026-01-14T10:28:33.370002Z"}},"outputs":[{"name":"stdout","text":"\nSubmission saved to: anava_deira_12.csv\nSubmission shape: (4000000, 2)\n\nPrediction distribution:\nTrip_Label\nPerfect_Trip         2048676\nSafety_Violation      791126\nService_Complaint     733248\nNavigation_Issue      228760\nFraud_Indication      198190\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"               Trip_ID         Trip_Label\n0        TRIP-06583736       Perfect_Trip\n1        TRIP-11356251  Service_Complaint\n2        TRIP-03320505  Service_Complaint\n3        TRIP-07188814       Perfect_Trip\n4        TRIP-06994869       Perfect_Trip\n...                ...                ...\n3999995  TRIP-02234490       Perfect_Trip\n3999996  TRIP-04304573       Perfect_Trip\n3999997  TRIP-10081352  Service_Complaint\n3999998  TRIP-06550635  Service_Complaint\n3999999  TRIP-06423389   Safety_Violation\n\n[4000000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Trip_ID</th>\n      <th>Trip_Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRIP-06583736</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TRIP-11356251</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TRIP-03320505</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TRIP-07188814</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TRIP-06994869</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3999995</th>\n      <td>TRIP-02234490</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999996</th>\n      <td>TRIP-04304573</td>\n      <td>Perfect_Trip</td>\n    </tr>\n    <tr>\n      <th>3999997</th>\n      <td>TRIP-10081352</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3999998</th>\n      <td>TRIP-06550635</td>\n      <td>Service_Complaint</td>\n    </tr>\n    <tr>\n      <th>3999999</th>\n      <td>TRIP-06423389</td>\n      <td>Safety_Violation</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000000 rows  2 columns</p>\n</div>"},"metadata":{}}],"execution_count":31}]}