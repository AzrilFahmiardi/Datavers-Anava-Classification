{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4cb422",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba4bde3",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True  \n",
    "\n",
    "gpu_config = {\n",
    "    'catboost_gpu': USE_GPU,\n",
    "    'lightgbm_gpu': USE_GPU,\n",
    "    'xgboost_gpu': USE_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd27c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T13:08:32.517061Z",
     "iopub.status.busy": "2026-01-10T13:08:32.516719Z",
     "iopub.status.idle": "2026-01-10T13:08:32.525317Z",
     "shell.execute_reply": "2026-01-10T13:08:32.524034Z",
     "shell.execute_reply.started": "2026-01-10T13:08:32.517037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    DATA_PATH = '/kaggle/input/ride-hailing-trip-classification-dataset/'\n",
    "    \n",
    "    N_FOLDS = 5\n",
    "    RANDOM_STATE = 42\n",
    "    TARGET_COL = 'Trip_Label'\n",
    "    ID_COL = 'Trip_ID'\n",
    "    \n",
    "    USE_TEMPORAL = False\n",
    "    USE_DISTANCE = True\n",
    "    USE_SENSOR_AGG = True\n",
    "    USE_ECONOMIC = False\n",
    "    USE_INTERACTION = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_catboost_params(use_gpu=False):\n",
    "        params = {\n",
    "            'iterations': 1000,\n",
    "            'learning_rate': 0.05,\n",
    "            'depth': 6,\n",
    "            'loss_function': 'MultiClass',\n",
    "            'eval_metric': 'TotalF1:average=Macro',\n",
    "            'auto_class_weights': 'Balanced',\n",
    "            'random_seed': 42,\n",
    "            'verbose': 100,\n",
    "            'early_stopping_rounds': 50\n",
    "        }\n",
    "        if use_gpu:\n",
    "            params['task_type'] = 'GPU'\n",
    "            params['devices'] = '0'\n",
    "            print(\"  CatBoost: GPU mode activated\")\n",
    "        else:\n",
    "            params['task_type'] = 'CPU'\n",
    "            print(\"  CatBoost: CPU mode\")\n",
    "        return params\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_lightgbm_params(use_gpu=False):\n",
    "        params = {\n",
    "            'objective': 'multiclass',\n",
    "            'metric': 'multi_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'random_state': 42,\n",
    "            'verbose': -1,\n",
    "            'min_data_in_leaf': 20,\n",
    "            'min_sum_hessian_in_leaf': 1e-3\n",
    "        }\n",
    "        if use_gpu:\n",
    "            params['device'] = 'gpu'\n",
    "            print(\"  LightGBM: GPU mode activated\")\n",
    "        else:\n",
    "            params['device'] = 'cpu'\n",
    "            print(\"  LightGBM: CPU mode\")\n",
    "        return params\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_xgboost_params(use_gpu=False):\n",
    "        params = {\n",
    "            'objective': 'multi:softprob',\n",
    "            'eval_metric': 'mlogloss',\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'verbosity': 1\n",
    "        }\n",
    "        if use_gpu:\n",
    "            params['device'] = 'cuda'\n",
    "            print(\"  XGBoost: GPU mode activated\")\n",
    "        else:\n",
    "            params['device'] = 'cpu'\n",
    "            print(\"  XGBoost: CPU mode\")\n",
    "        return params\n",
    "\n",
    "config = Config()\n",
    "print(\"\\nConfiguration loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134a05c",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37144dad",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print(\"Loading data...\")\n",
    "    files = ['train.csv', 'test.csv', 'sample_submission.csv']\n",
    "    data = {}\n",
    "    \n",
    "    for file in tqdm(files, desc=\"Loading files\"):\n",
    "        data[file.replace('.csv', '')] = pd.read_csv(config.DATA_PATH + file)\n",
    "    \n",
    "    train = data['train']\n",
    "    test = data['test']\n",
    "    sample_submission = data['sample_submission']\n",
    "    \n",
    "    print(f\"Train shape: {train.shape}\")\n",
    "    print(f\"Test shape: {test.shape}\")\n",
    "    print(f\"Sample submission shape: {sample_submission.shape}\")\n",
    "    \n",
    "    if config.TARGET_COL in train.columns:\n",
    "        print(f\"\\nTarget distribution:\")\n",
    "        print(train[config.TARGET_COL].value_counts())\n",
    "    \n",
    "    return train, test, sample_submission\n",
    "\n",
    "train, test, sample_submission = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d1d42f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-10T14:41:09.903123Z",
     "iopub.status.idle": "2026-01-10T14:41:09.903410Z",
     "shell.execute_reply": "2026-01-10T14:41:09.903287Z",
     "shell.execute_reply.started": "2026-01-10T14:41:09.903273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def optimize_memory(df):\n",
    "    print(f\"Optimizing memory for dataframe with {len(df.columns)} columns...\")\n",
    "    for col in tqdm(df.columns, desc=\"Optimizing columns\"):\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    return df\n",
    "\n",
    "print(\"Optimizing memory...\")\n",
    "train = optimize_memory(train)\n",
    "test = optimize_memory(test)\n",
    "print(\"Memory optimization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7bf178",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb072add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T13:08:35.952074Z",
     "iopub.status.busy": "2026-01-10T13:08:35.951700Z",
     "iopub.status.idle": "2026-01-10T13:08:47.394882Z",
     "shell.execute_reply": "2026-01-10T13:08:47.393919Z",
     "shell.execute_reply.started": "2026-01-10T13:08:35.952049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for train set...\n",
      "  - Creating distance features...\n",
      "  - Creating sensor aggregation features...\n",
      "  - Creating interaction features...\n",
      "Feature engineering completed. Shape: (8000000, 37)\n",
      "Engineering features for test set...\n",
      "  - Creating distance features...\n",
      "  - Creating sensor aggregation features...\n",
      "  - Creating interaction features...\n",
      "Feature engineering completed. Shape: (4000000, 36)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    delta_lat = np.radians(lat2 - lat1)\n",
    "    delta_lon = np.radians(lon2 - lon1)\n",
    "    \n",
    "    a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "    return R * c\n",
    "\n",
    "def engineer_features(df, is_train=True):\n",
    "    print(f\"Engineering features for {'train' if is_train else 'test'} set...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    if config.USE_TEMPORAL and 'Timestamp' in df.columns:\n",
    "        print(\"  - Creating temporal features...\")\n",
    "        df['Timestamp_parsed'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Hour'] = df['Timestamp_parsed'].dt.hour.astype(np.int8)\n",
    "        df['DayOfWeek'] = df['Timestamp_parsed'].dt.dayofweek.astype(np.int8)\n",
    "        df['Month'] = df['Timestamp_parsed'].dt.month.astype(np.int8)\n",
    "        df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(np.int8)\n",
    "        df['IsRushHour'] = ((df['Hour'] >= 7) & (df['Hour'] <= 9) | \n",
    "                            (df['Hour'] >= 17) & (df['Hour'] <= 19)).astype(np.int8)\n",
    "        df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 5)).astype(np.int8)\n",
    "        df.drop('Timestamp_parsed', axis=1, inplace=True)\n",
    "    \n",
    "    if config.USE_DISTANCE:\n",
    "        print(\"  - Creating distance features...\")\n",
    "        if all(col in df.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n",
    "            df['Haversine_Distance'] = haversine_distance(\n",
    "                df['Pickup_Lat'], df['Pickup_Long'],\n",
    "                df['Dropoff_Lat'], df['Dropoff_Long']\n",
    "            )\n",
    "            \n",
    "            if 'Distance_KM' in df.columns:\n",
    "                df['Distance_Ratio'] = df['Distance_KM'] / (df['Haversine_Distance'] + 1e-6)\n",
    "                df['Distance_Difference'] = np.abs(df['Distance_KM'] - df['Haversine_Distance'])\n",
    "        \n",
    "        if 'Pickup_Zone' in df.columns and 'Dropoff_Zone' in df.columns:\n",
    "            df['Is_Same_Zone'] = (df['Pickup_Zone'] == df['Dropoff_Zone']).astype(np.int8)\n",
    "    \n",
    "    if config.USE_SENSOR_AGG:\n",
    "        print(\"  - Creating sensor aggregation features...\")\n",
    "        if all(col in df.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n",
    "            df['Accel_Magnitude'] = np.sqrt(df['Accel_X']**2 + df['Accel_Y']**2 + df['Accel_Z']**2)\n",
    "            df['Accel_Max'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].max(axis=1)\n",
    "            df['Accel_Min'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].min(axis=1)\n",
    "            df['Accel_Std'] = df[['Accel_X', 'Accel_Y', 'Accel_Z']].std(axis=1)\n",
    "            df['Accel_Range'] = df['Accel_Max'] - df['Accel_Min']\n",
    "        \n",
    "        if 'Gyro_Z' in df.columns:\n",
    "            df['Gyro_Abs'] = np.abs(df['Gyro_Z'])\n",
    "    \n",
    "    if config.USE_ECONOMIC:\n",
    "        print(\"  - Creating economic features...\")\n",
    "        if 'Est_Price_IDR' in df.columns and 'Distance_KM' in df.columns:\n",
    "            df['Price_per_KM'] = df['Est_Price_IDR'] / (df['Distance_KM'] + 1e-6)\n",
    "        \n",
    "        if 'Promo_Code' in df.columns:\n",
    "            df['Has_Promo'] = (df['Promo_Code'].notna()).astype(np.int8)\n",
    "        \n",
    "        if 'Surge_Multiplier' in df.columns:\n",
    "            df['Surge_Category'] = pd.cut(df['Surge_Multiplier'], \n",
    "                                          bins=[0, 1, 1.5, 2, 10], \n",
    "                                          labels=[0, 1, 2, 3]).astype(np.int8)\n",
    "    \n",
    "    if config.USE_INTERACTION:\n",
    "        print(\"  - Creating interaction features...\")\n",
    "        if 'Surge_Multiplier' in df.columns and 'Hour' in df.columns:\n",
    "            df['Surge_Hour_Interaction'] = df['Surge_Multiplier'] * df['Hour']\n",
    "        \n",
    "        if 'Distance_KM' in df.columns and 'Traffic' in df.columns:\n",
    "            traffic_map = {'Light': 1, 'Moderate': 2, 'Heavy': 3}\n",
    "            df['Traffic_Numeric'] = df['Traffic'].map(traffic_map).fillna(0).astype(np.int8)\n",
    "            df['Distance_Traffic'] = df['Distance_KM'] * df['Traffic_Numeric']\n",
    "    \n",
    "    print(f\"Feature engineering completed. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "train = engineer_features(train, is_train=True)\n",
    "test = engineer_features(test, is_train=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23f1e9",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9713440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_frequency(train, test, categorical_cols):\n",
    "    \"\"\"\n",
    "    Encodes based on value frequency in training data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FREQUENCY ENCODING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    encoders = {}\n",
    "    \n",
    "    for col in tqdm(categorical_cols, desc=\"Frequency encoding\"):\n",
    "        freq_map = train[col].value_counts(dropna=False).to_dict()\n",
    "        \n",
    "        train[col] = train[col].map(freq_map).fillna(0).astype(np.int32)\n",
    "        test[col] = test[col].map(freq_map).fillna(0).astype(np.int32)\n",
    "        \n",
    "        encoders[col] = {\n",
    "            'type': 'frequency',\n",
    "            'unique_values': len(freq_map),\n",
    "            'unseen_in_test': (test[col] == 0).sum()\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nEncoded {len(categorical_cols)} categorical features\")\n",
    "    return train, test, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_target(train, test, categorical_cols, y_train, smoothing=10):\n",
    "    \"\"\"\n",
    "    Encodes based on target mean, with smoothing to prevent overfitting\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TARGET ENCODING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    encoders = {}\n",
    "    global_mean = y_train.mean()\n",
    "    \n",
    "    for col in tqdm(categorical_cols, desc=\"Target encoding\"):\n",
    "        temp_df = pd.DataFrame({col: train[col], 'target': y_train})\n",
    "        \n",
    "        agg = temp_df.groupby(col)['target'].agg(['mean', 'count'])\n",
    "        smoothed_mean = (agg['mean'] * agg['count'] + global_mean * smoothing) / (agg['count'] + smoothing)\n",
    "        \n",
    "        encoding_map = smoothed_mean.to_dict()\n",
    "        \n",
    "        train[col] = train[col].map(encoding_map).fillna(global_mean).astype(np.float32)\n",
    "        test[col] = test[col].map(encoding_map).fillna(global_mean).astype(np.float32)\n",
    "        \n",
    "        encoders[col] = {\n",
    "            'type': 'target',\n",
    "            'unique_values': len(encoding_map),\n",
    "            'global_mean': global_mean\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nEncoded {len(categorical_cols)} categorical features\")\n",
    "    return train, test, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196940cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_label_optimized(train, test, categorical_cols):\n",
    "    \"\"\"\n",
    "    Uses map() for vectorized operations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LABEL ENCODING \")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    encoders = {}\n",
    "    \n",
    "    for col in tqdm(categorical_cols, desc=\"Label encoding\"):\n",
    "        train[col] = train[col].astype(str)\n",
    "        test[col] = test[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        train[col] = le.fit_transform(train[col])\n",
    "        \n",
    "        mapping = {label: idx for idx, label in enumerate(le.classes_)}\n",
    "        test[col] = test[col].map(mapping).fillna(-1).astype(np.int32)\n",
    "        \n",
    "        encoders[col] = {\n",
    "            'type': 'label',\n",
    "            'encoder': le,\n",
    "            'unique_values': len(le.classes_),\n",
    "            'unseen_in_test': (test[col] == -1).sum()\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nEncoded {len(categorical_cols)} categorical features\")\n",
    "    return train, test, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445248f0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-10T14:41:09.905550Z",
     "iopub.status.idle": "2026-01-10T14:41:09.906052Z",
     "shell.execute_reply": "2026-01-10T14:41:09.905853Z",
     "shell.execute_reply.started": "2026-01-10T14:41:09.905832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train, test, encoding_method='frequency'):\n",
    "    \"\"\"\n",
    "    Main preprocessing pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train : pd.DataFrame\n",
    "        Training dataset\n",
    "    test : pd.DataFrame\n",
    "        Test dataset\n",
    "    encoding_method : str\n",
    "        Encoding method to use: 'frequency', 'target', or 'label'\n",
    "    Returns:\n",
    "    --------\n",
    "    X_train, X_test, y_train, le_target, encoders\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA PREPROCESSING PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Encoding method: {encoding_method.upper()}\")\n",
    "    \n",
    "    cols_to_drop = [config.ID_COL, 'Timestamp']\n",
    "    if config.TARGET_COL in train.columns:\n",
    "        y = train[config.TARGET_COL].copy()\n",
    "        cols_to_drop.append(config.TARGET_COL)\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    cols_to_drop = [col for col in cols_to_drop if col in train.columns]\n",
    "    X_train = train.drop(cols_to_drop, axis=1).copy()\n",
    "    X_test = test.drop([col for col in cols_to_drop if col in test.columns], axis=1).copy()\n",
    "    \n",
    "    print(f\"\\nInitial shapes:\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  X_test: {X_test.shape}\")\n",
    "    \n",
    "    print(f\"\\nMissing values before imputation:\")\n",
    "    train_missing = X_train.isnull().sum()\n",
    "    if train_missing.sum() > 0:\n",
    "        print(train_missing[train_missing > 0])\n",
    "    else:\n",
    "        print(\"  No missing values found\")\n",
    "    \n",
    "    numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    print(f\"\\nFeature types detected:\")\n",
    "    print(f\"  Numeric features: {len(numeric_cols)}\")\n",
    "    print(f\"  Categorical features: {len(categorical_cols)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 1: Missing Value Imputation\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for col in tqdm(numeric_cols, desc=\"Imputing numeric features\"):\n",
    "        if X_train[col].isnull().sum() > 0:\n",
    "            median_val = X_train[col].median()\n",
    "            X_train[col].fillna(median_val, inplace=True)\n",
    "            X_test[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    for col in tqdm(categorical_cols, desc=\"Imputing categorical features\"):\n",
    "        if X_train[col].isnull().sum() > 0:\n",
    "            X_train[col].fillna('Unknown', inplace=True)\n",
    "            X_test[col].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 2: Outlier Clipping\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for col in tqdm(numeric_cols, desc=\"Clipping outliers\"):\n",
    "        q99 = X_train[col].quantile(0.99)\n",
    "        q01 = X_train[col].quantile(0.01)\n",
    "        X_train[col] = X_train[col].clip(q01, q99)\n",
    "        X_test[col] = X_test[col].clip(q01, q99)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 3: Categorical Encoding\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(categorical_cols) > 0:\n",
    "        if encoding_method == 'frequency':\n",
    "            X_train, X_test, encoders = encode_categorical_frequency(\n",
    "                X_train, X_test, categorical_cols\n",
    "            )\n",
    "        elif encoding_method == 'target':\n",
    "            if y is None:\n",
    "                raise ValueError(\"Target encoding requires target variable\")\n",
    "            le_target_temp = LabelEncoder()\n",
    "            y_temp = le_target_temp.fit_transform(y)\n",
    "            X_train, X_test, encoders = encode_categorical_target(\n",
    "                X_train, X_test, categorical_cols, y_temp\n",
    "            )\n",
    "        elif encoding_method == 'label':\n",
    "            X_train, X_test, encoders = encode_categorical_label_optimized(\n",
    "                X_train, X_test, categorical_cols\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown encoding method: {encoding_method}\")\n",
    "    else:\n",
    "        encoders = {}\n",
    "        print(\"No categorical features to encode\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEP 4: Target Encoding\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if y is not None:\n",
    "        le_target = LabelEncoder()\n",
    "        y_encoded = le_target.fit_transform(y)\n",
    "        print(f\"\\nTarget classes encoded:\")\n",
    "        for i, label in enumerate(le_target.classes_):\n",
    "            count = (y_encoded == i).sum()\n",
    "            print(f\"  {i}: {label:20s} - {count:,} samples ({count/len(y_encoded)*100:.2f}%)\")\n",
    "    else:\n",
    "        y_encoded = None\n",
    "        le_target = None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREPROCESSING COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Final shapes:\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  X_test: {X_test.shape}\")\n",
    "    if y_encoded is not None:\n",
    "        print(f\"  y_train: {y_encoded.shape}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return X_train, X_test, y_encoded, le_target, encoders\n",
    "\n",
    "X_train, X_test, y_train, le_target, encoders = preprocess_data(train, test, encoding_method='frequency')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd652a6",
   "metadata": {},
   "source": [
    "## 5. Model Training - CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7052f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-10T14:39:08.701423Z",
     "iopub.status.idle": "2026-01-10T14:39:08.701871Z",
     "shell.execute_reply": "2026-01-10T14:39:08.701702Z",
     "shell.execute_reply.started": "2026-01-10T14:39:08.701683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from catboost import CatBoostClassifier, Pool\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"CatBoost not available. Install with: pip install catboost\")\n",
    "    CATBOOST_AVAILABLE = False\n",
    "\n",
    "def train_catboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n",
    "    if not CATBOOST_AVAILABLE:\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training CatBoost Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    params = config.get_catboost_params(use_gpu=use_gpu)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n",
    "    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n",
    "    \n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"CatBoost Folds\")\n",
    "    for fold, (train_idx, val_idx) in pbar:\n",
    "        pbar.set_description(f\"CatBoost Fold {fold}/{n_folds}\")\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        train_pool = Pool(X_tr, y_tr)\n",
    "        val_pool = Pool(X_val, y_val)\n",
    "        \n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=val_pool, use_best_model=True, plot=False)\n",
    "        \n",
    "        oof_predictions[val_idx] = model.predict_proba(X_val)\n",
    "        test_predictions += model.predict_proba(X_test) / n_folds\n",
    "        \n",
    "        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n",
    "        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n",
    "        \n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"CatBoost Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_predictions, models, overall_score\n",
    "\n",
    "if CATBOOST_AVAILABLE:\n",
    "    catboost_test_pred, catboost_models, catboost_cv_score = train_catboost(\n",
    "        X_train, y_train, X_test, \n",
    "        n_folds=config.N_FOLDS,\n",
    "        use_gpu=gpu_config['catboost_gpu']\n",
    "    )\n",
    "else:\n",
    "    catboost_test_pred, catboost_models, catboost_cv_score = None, None, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ce325",
   "metadata": {},
   "source": [
    "## 6. Model Training - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"LightGBM not available. Install with: pip install lightgbm\")\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "\n",
    "def train_lightgbm(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n",
    "    if not LIGHTGBM_AVAILABLE:\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training LightGBM Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    params = config.get_lightgbm_params(use_gpu=use_gpu)\n",
    "    params['num_class'] = len(np.unique(y_train))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n",
    "    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n",
    "    \n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"LightGBM Folds\")\n",
    "    for fold, (train_idx, val_idx) in pbar:\n",
    "        pbar.set_description(f\"LightGBM Fold {fold}/{n_folds}\")\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[train_data, val_data],\n",
    "            valid_names=['train', 'valid'],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
    "        )\n",
    "        \n",
    "        oof_predictions[val_idx] = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "        test_predictions += model.predict(X_test, num_iteration=model.best_iteration) / n_folds\n",
    "        \n",
    "        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n",
    "        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n",
    "        \n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"LightGBM Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_predictions, models, overall_score\n",
    "\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    lightgbm_test_pred, lightgbm_models, lightgbm_cv_score = train_lightgbm(\n",
    "        X_train, y_train, X_test,\n",
    "        n_folds=config.N_FOLDS,\n",
    "        use_gpu=gpu_config['lightgbm_gpu']\n",
    "    )\n",
    "else:\n",
    "    lightgbm_test_pred, lightgbm_models, lightgbm_cv_score = None, None, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80430d8d",
   "metadata": {},
   "source": [
    "## 7. Model Training - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "def train_xgboost(X_train, y_train, X_test, n_folds=5, use_gpu=False):\n",
    "    if not XGBOOST_AVAILABLE:\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Training XGBoost Models\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    params = config.get_xgboost_params(use_gpu=use_gpu)\n",
    "    params['num_class'] = len(np.unique(y_train))\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "    \n",
    "    oof_predictions = np.zeros((len(X_train), len(np.unique(y_train))))\n",
    "    test_predictions = np.zeros((len(X_test), len(np.unique(y_train))))\n",
    "    \n",
    "    fold_scores = []\n",
    "    models = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(skf.split(X_train, y_train), 1), total=n_folds, desc=\"XGBoost Folds\")\n",
    "    for fold, (train_idx, val_idx) in pbar:\n",
    "        pbar.set_description(f\"XGBoost Fold {fold}/{n_folds}\")\n",
    "        \n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(dtrain, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "        \n",
    "        oof_predictions[val_idx] = model.predict(dval)\n",
    "        test_predictions += model.predict(dtest) / n_folds\n",
    "        \n",
    "        oof_pred_labels = np.argmax(oof_predictions[val_idx], axis=1)\n",
    "        fold_score = f1_score(y_val, oof_pred_labels, average='macro')\n",
    "        fold_scores.append(fold_score)\n",
    "        \n",
    "        pbar.set_postfix({'F1': f'{fold_score:.6f}'})\n",
    "        \n",
    "        models.append(model)\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_pred_labels = np.argmax(oof_predictions, axis=1)\n",
    "    overall_score = f1_score(y_train, oof_pred_labels, average='macro')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"XGBoost Overall CV Score: {overall_score:.6f} (+/- {np.std(fold_scores):.6f})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return test_predictions, models, overall_score\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    xgboost_test_pred, xgboost_models, xgboost_cv_score = train_xgboost(\n",
    "        X_train, y_train, X_test,\n",
    "        n_folds=config.N_FOLDS,\n",
    "        use_gpu=gpu_config['xgboost_gpu']\n",
    "    )\n",
    "else:\n",
    "    xgboost_test_pred, xgboost_models, xgboost_cv_score = None, None, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abb317",
   "metadata": {},
   "source": [
    "## 8. Model Selection & Prediction Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a333a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON & SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_results = []\n",
    "\n",
    "if catboost_test_pred is not None:\n",
    "    model_results.append({\n",
    "        'name': 'CatBoost',\n",
    "        'cv_score': catboost_cv_score,\n",
    "        'predictions': catboost_test_pred\n",
    "    })\n",
    "\n",
    "if lightgbm_test_pred is not None:\n",
    "    model_results.append({\n",
    "        'name': 'LightGBM',\n",
    "        'cv_score': lightgbm_cv_score,\n",
    "        'predictions': lightgbm_test_pred\n",
    "    })\n",
    "\n",
    "if xgboost_test_pred is not None:\n",
    "    model_results.append({\n",
    "        'name': 'XGBoost',\n",
    "        'cv_score': xgboost_cv_score,\n",
    "        'predictions': xgboost_test_pred\n",
    "    })\n",
    "\n",
    "if len(model_results) == 0:\n",
    "    raise ValueError(\"No models trained successfully!\")\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "for result in sorted(model_results, key=lambda x: x['cv_score'], reverse=True):\n",
    "    print(f\"  {result['name']:15s}: CV Score = {result['cv_score']:.6f}\")\n",
    "\n",
    "best_model = max(model_results, key=lambda x: x['cv_score'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"BEST MODEL: {best_model['name']} (CV Score: {best_model['cv_score']:.6f})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION STRATEGY SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "USE_ENSEMBLE = False  \n",
    "\n",
    "if USE_ENSEMBLE and len(model_results) > 1:\n",
    "    print(\"\\n✓ Using ENSEMBLE of all models (equal weights)\")\n",
    "    \n",
    "    ensemble_pred = np.zeros_like(model_results[0]['predictions'])\n",
    "    for result in model_results:\n",
    "        ensemble_pred += result['predictions'] / len(model_results)\n",
    "    \n",
    "    final_predictions = ensemble_pred\n",
    "    strategy_name = f\"Ensemble of {len(model_results)} models\"\n",
    "else:\n",
    "    print(f\"\\n✓ Using BEST INDIVIDUAL MODEL: {best_model['name']}\")\n",
    "    final_predictions = best_model['predictions']\n",
    "    strategy_name = best_model['name']\n",
    "\n",
    "final_pred_labels = np.argmax(final_predictions, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Final Strategy: {strategy_name}\")\n",
    "print(f\"Predictions shape: {final_predictions.shape}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebc841",
   "metadata": {},
   "source": [
    "## 9. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd660f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(test_ids, predictions, le_target, filename='submission.csv'):\n",
    "    pred_labels = le_target.inverse_transform(predictions)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        config.ID_COL: test_ids,\n",
    "        config.TARGET_COL: pred_labels\n",
    "    })\n",
    "    \n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission saved to: {filename}\")\n",
    "    print(f\"Submission shape: {submission.shape}\")\n",
    "    print(f\"\\nPrediction distribution:\")\n",
    "    print(submission[config.TARGET_COL].value_counts())\n",
    "    \n",
    "    return submission\n",
    "\n",
    "test_ids = test[config.ID_COL].values\n",
    "submission = create_submission(test_ids, final_pred_labels, le_target, 'submission.csv')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c9f05",
   "metadata": {},
   "source": [
    "## 10. Validation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Final Validation Checks\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "assert submission.shape[0] == test.shape[0], \"Submission size mismatch!\"\n",
    "assert submission.columns.tolist() == [config.ID_COL, config.TARGET_COL], \"Column names mismatch!\"\n",
    "assert submission[config.TARGET_COL].isnull().sum() == 0, \"Null predictions found!\"\n",
    "\n",
    "expected_labels = set(le_target.classes_)\n",
    "submission_labels = set(submission[config.TARGET_COL].unique())\n",
    "assert submission_labels.issubset(expected_labels), \"Invalid labels in submission!\"\n",
    "\n",
    "print(\"All validation checks passed!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "if catboost_models and len(catboost_models) > 0:\n",
    "    print(\"\\nTop 20 Important Features (CatBoost):\")\n",
    "    feature_importance = catboost_models[0].get_feature_importance()\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(importance_df.head(20).to_string(index=False))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Feature Importances', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9230974,
     "sourceId": 14452162,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
