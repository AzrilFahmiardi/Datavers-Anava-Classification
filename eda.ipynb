{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbb47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac71ce2",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/kaggle/input/ride-hailing-trip-classification-dataset/'\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "test = pd.read_csv(DATA_PATH + 'test.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04156933",
   "metadata": {},
   "source": [
    "## 2. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a812a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c20e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc9eba",
   "metadata": {},
   "source": [
    "### 2.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d242596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df, name='Dataset'):\n",
    "    missing = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "    }).sort_values('Missing_Count', ascending=False)\n",
    "    \n",
    "    missing = missing[missing['Missing_Count'] > 0]\n",
    "    \n",
    "    if len(missing) > 0:\n",
    "        print(f\"\\n{name} - Missing Values:\")\n",
    "        print(missing.to_string(index=False))\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.barh(missing['Column'], missing['Missing_Percentage'])\n",
    "        plt.xlabel('Missing Percentage (%)')\n",
    "        plt.title(f'{name} - Missing Values Distribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"\\n{name} - No missing values detected.\")\n",
    "    \n",
    "    return missing\n",
    "\n",
    "missing_train = analyze_missing_values(train, 'Training Set')\n",
    "missing_test = analyze_missing_values(test, 'Test Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342159b",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Trip_Label'\n",
    "\n",
    "if target_col in train.columns:\n",
    "    target_counts = train[target_col].value_counts()\n",
    "    target_pct = train[target_col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    target_summary = pd.DataFrame({\n",
    "        'Count': target_counts,\n",
    "        'Percentage': target_pct.round(2)\n",
    "    })\n",
    "    \n",
    "    print(\"\\nTarget Variable Distribution:\")\n",
    "    print(target_summary)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    target_counts.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "    axes[0].set_title('Trip Label Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Trip Label')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    axes[1].pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Trip Label Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    imbalance_ratio = target_counts.max() / target_counts.min()\n",
    "    print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "else:\n",
    "    print(f\"\\nTarget column '{target_col}' not found in training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066278e",
   "metadata": {},
   "source": [
    "## 4. Spatio-Temporal Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f680c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_cols = ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long', \n",
    "                'Pickup_Zone', 'Dropoff_Zone', 'Distance_KM']\n",
    "\n",
    "print(\"Spatio-Temporal Features Summary:\")\n",
    "for col in spatial_cols:\n",
    "    if col in train.columns:\n",
    "        if train[col].dtype in ['float64', 'int64']:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Min: {train[col].min()}\")\n",
    "            print(f\"  Max: {train[col].max()}\")\n",
    "            print(f\"  Mean: {train[col].mean():.2f}\")\n",
    "            print(f\"  Median: {train[col].median():.2f}\")\n",
    "        else:\n",
    "            print(f\"\\n{col}: {train[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d70c7",
   "metadata": {},
   "source": [
    "### 4.1 Timestamp Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Timestamp' in train.columns:\n",
    "    train['Timestamp_parsed'] = pd.to_datetime(train['Timestamp'])\n",
    "    train['Hour'] = train['Timestamp_parsed'].dt.hour\n",
    "    train['DayOfWeek'] = train['Timestamp_parsed'].dt.dayofweek\n",
    "    train['DayName'] = train['Timestamp_parsed'].dt.day_name()\n",
    "    train['Month'] = train['Timestamp_parsed'].dt.month\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    train['Hour'].value_counts().sort_index().plot(kind='bar', ax=axes[0, 0], color='coral')\n",
    "    axes[0, 0].set_title('Trip Distribution by Hour of Day', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Hour')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    \n",
    "    train['DayName'].value_counts()[['Monday', 'Tuesday', 'Wednesday', 'Thursday', \n",
    "                                      'Friday', 'Saturday', 'Sunday']].plot(kind='bar', \n",
    "                                      ax=axes[0, 1], color='skyblue')\n",
    "    axes[0, 1].set_title('Trip Distribution by Day of Week', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Day')\n",
    "    axes[0, 1].set_ylabel('Count')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    if target_col in train.columns:\n",
    "        hour_label = pd.crosstab(train['Hour'], train[target_col], normalize='index') * 100\n",
    "        hour_label.plot(kind='bar', stacked=True, ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Trip Label Distribution by Hour (%)', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Hour')\n",
    "        axes[1, 0].set_ylabel('Percentage')\n",
    "        axes[1, 0].legend(title='Trip Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        day_label = pd.crosstab(train['DayOfWeek'], train[target_col], normalize='index') * 100\n",
    "        day_label.plot(kind='bar', stacked=True, ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Trip Label Distribution by Day of Week (%)', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Day of Week')\n",
    "        axes[1, 1].set_ylabel('Percentage')\n",
    "        axes[1, 1].set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], rotation=45)\n",
    "        axes[1, 1].legend(title='Trip Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356481e",
   "metadata": {},
   "source": [
    "### 4.2 Distance and Location Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aeeb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Distance_KM' in train.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    train['Distance_KM'].hist(bins=50, ax=axes[0], edgecolor='black')\n",
    "    axes[0].set_title('Distance Distribution', fontweight='bold')\n",
    "    axes[0].set_xlabel('Distance (KM)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    if target_col in train.columns:\n",
    "        train.boxplot(column='Distance_KM', by=target_col, ax=axes[1])\n",
    "        axes[1].set_title('Distance Distribution by Trip Label', fontweight='bold')\n",
    "        axes[1].set_xlabel('Trip Label')\n",
    "        axes[1].set_ylabel('Distance (KM)')\n",
    "        plt.suptitle('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDistance Statistics:\")\n",
    "    print(f\"Mean: {train['Distance_KM'].mean():.2f} KM\")\n",
    "    print(f\"Median: {train['Distance_KM'].median():.2f} KM\")\n",
    "    print(f\"Min: {train['Distance_KM'].min():.2f} KM\")\n",
    "    print(f\"Max: {train['Distance_KM'].max():.2f} KM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(col in train.columns for col in ['Pickup_Lat', 'Pickup_Long', 'Dropoff_Lat', 'Dropoff_Long']):\n",
    "    def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "        R = 6371\n",
    "        lat1_rad = np.radians(lat1)\n",
    "        lat2_rad = np.radians(lat2)\n",
    "        delta_lat = np.radians(lat2 - lat1)\n",
    "        delta_lon = np.radians(lon2 - lon1)\n",
    "        \n",
    "        a = np.sin(delta_lat/2)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(delta_lon/2)**2\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "        \n",
    "        return R * c\n",
    "    \n",
    "    train['Haversine_Distance'] = haversine_distance(\n",
    "        train['Pickup_Lat'], train['Pickup_Long'],\n",
    "        train['Dropoff_Lat'], train['Dropoff_Long']\n",
    "    )\n",
    "    \n",
    "    if 'Distance_KM' in train.columns:\n",
    "        train['Distance_Ratio'] = train['Distance_KM'] / (train['Haversine_Distance'] + 1e-6)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].scatter(train['Haversine_Distance'], train['Distance_KM'], alpha=0.3)\n",
    "        axes[0].plot([0, train['Distance_KM'].max()], [0, train['Distance_KM'].max()], \n",
    "                     'r--', label='Perfect Match')\n",
    "        axes[0].set_xlabel('Haversine Distance (KM)')\n",
    "        axes[0].set_ylabel('Actual Distance (KM)')\n",
    "        axes[0].set_title('Haversine vs Actual Distance', fontweight='bold')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        train['Distance_Ratio'].hist(bins=50, ax=axes[1], edgecolor='black')\n",
    "        axes[1].set_title('Distance Ratio Distribution', fontweight='bold')\n",
    "        axes[1].set_xlabel('Actual Distance / Haversine Distance')\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "        axes[1].axvline(x=1, color='r', linestyle='--', label='Ratio = 1')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nDistance Ratio Statistics:\")\n",
    "        print(f\"Mean: {train['Distance_Ratio'].mean():.2f}\")\n",
    "        print(f\"Median: {train['Distance_Ratio'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5788b793",
   "metadata": {},
   "source": [
    "### 4.3 Zone Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75decf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Pickup_Zone' in train.columns and 'Dropoff_Zone' in train.columns:\n",
    "    print(f\"\\nNumber of unique Pickup Zones: {train['Pickup_Zone'].nunique()}\")\n",
    "    print(f\"Number of unique Dropoff Zones: {train['Dropoff_Zone'].nunique()}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    top_pickup = train['Pickup_Zone'].value_counts().head(15)\n",
    "    top_pickup.plot(kind='barh', ax=axes[0], color='lightgreen')\n",
    "    axes[0].set_title('Top 15 Pickup Zones', fontweight='bold')\n",
    "    axes[0].set_xlabel('Count')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    top_dropoff = train['Dropoff_Zone'].value_counts().head(15)\n",
    "    top_dropoff.plot(kind='barh', ax=axes[1], color='lightcoral')\n",
    "    axes[1].set_title('Top 15 Dropoff Zones', fontweight='bold')\n",
    "    axes[1].set_xlabel('Count')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91a4b1",
   "metadata": {},
   "source": [
    "## 5. Telematics (Sensor) Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = ['Accel_X', 'Accel_Y', 'Accel_Z', 'Gyro_Z', 'GPS_Accuracy_M']\n",
    "\n",
    "if all(col in train.columns for col in ['Accel_X', 'Accel_Y', 'Accel_Z']):\n",
    "    train['Accel_Magnitude'] = np.sqrt(train['Accel_X']**2 + train['Accel_Y']**2 + train['Accel_Z']**2)\n",
    "    sensor_cols.append('Accel_Magnitude')\n",
    "\n",
    "available_sensors = [col for col in sensor_cols if col in train.columns]\n",
    "\n",
    "if available_sensors:\n",
    "    print(\"Sensor Data Summary:\")\n",
    "    print(train[available_sensors].describe())\n",
    "    \n",
    "    n_cols = 3\n",
    "    n_rows = (len(available_sensors) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 4))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    for idx, col in enumerate(available_sensors):\n",
    "        train[col].hist(bins=50, ax=axes[idx], edgecolor='black')\n",
    "        axes[idx].set_title(f'{col} Distribution', fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "    \n",
    "    for idx in range(len(available_sensors), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ae468",
   "metadata": {},
   "source": [
    "### 5.1 Sensor Data by Trip Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_col in train.columns and available_sensors:\n",
    "    n_cols = 2\n",
    "    n_rows = (len(available_sensors) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    for idx, col in enumerate(available_sensors):\n",
    "        train.boxplot(column=col, by=target_col, ax=axes[idx])\n",
    "        axes[idx].set_title(f'{col} by Trip Label', fontweight='bold')\n",
    "        axes[idx].set_xlabel('Trip Label')\n",
    "        axes[idx].set_ylabel(col)\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "        plt.suptitle('')\n",
    "    \n",
    "    for idx in range(len(available_sensors), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9b11a",
   "metadata": {},
   "source": [
    "## 6. Transaction and Economics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_cols = ['Est_Price_IDR', 'Surge_Multiplier', 'Promo_Code', 'Payment_Method']\n",
    "\n",
    "available_transaction = [col for col in transaction_cols if col in train.columns]\n",
    "\n",
    "if available_transaction:\n",
    "    print(\"Transaction Features Summary:\")\n",
    "    for col in available_transaction:\n",
    "        if train[col].dtype in ['float64', 'int64']:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Mean: {train[col].mean():.2f}\")\n",
    "            print(f\"  Median: {train[col].median():.2f}\")\n",
    "            print(f\"  Min: {train[col].min():.2f}\")\n",
    "            print(f\"  Max: {train[col].max():.2f}\")\n",
    "        else:\n",
    "            print(f\"\\n{col}: {train[col].nunique()} unique values\")\n",
    "            print(train[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Est_Price_IDR' in train.columns and 'Distance_KM' in train.columns:\n",
    "    train['Price_per_KM'] = train['Est_Price_IDR'] / (train['Distance_KM'] + 1e-6)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    train['Est_Price_IDR'].hist(bins=50, ax=axes[0, 0], edgecolor='black')\n",
    "    axes[0, 0].set_title('Price Distribution', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Price (IDR)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    axes[0, 1].scatter(train['Distance_KM'], train['Est_Price_IDR'], alpha=0.3)\n",
    "    axes[0, 1].set_title('Price vs Distance', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Distance (KM)')\n",
    "    axes[0, 1].set_ylabel('Price (IDR)')\n",
    "    \n",
    "    train['Price_per_KM'].hist(bins=50, ax=axes[1, 0], edgecolor='black')\n",
    "    axes[1, 0].set_title('Price per KM Distribution', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Price per KM (IDR)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    if target_col in train.columns:\n",
    "        train.boxplot(column='Price_per_KM', by=target_col, ax=axes[1, 1])\n",
    "        axes[1, 1].set_title('Price per KM by Trip Label', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Trip Label')\n",
    "        axes[1, 1].set_ylabel('Price per KM (IDR)')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        plt.suptitle('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e45272",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Surge_Multiplier' in train.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    train['Surge_Multiplier'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='orange')\n",
    "    axes[0].set_title('Surge Multiplier Distribution', fontweight='bold')\n",
    "    axes[0].set_xlabel('Surge Multiplier')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    \n",
    "    if target_col in train.columns:\n",
    "        surge_label = pd.crosstab(train['Surge_Multiplier'], train[target_col], normalize='index') * 100\n",
    "        surge_label.plot(kind='bar', stacked=True, ax=axes[1])\n",
    "        axes[1].set_title('Trip Label Distribution by Surge Multiplier (%)', fontweight='bold')\n",
    "        axes[1].set_xlabel('Surge Multiplier')\n",
    "        axes[1].set_ylabel('Percentage')\n",
    "        axes[1].legend(title='Trip Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transaction = ['Promo_Code', 'Payment_Method']\n",
    "\n",
    "for col in categorical_transaction:\n",
    "    if col in train.columns:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        train[col].value_counts().plot(kind='bar', ax=axes[0], color='teal')\n",
    "        axes[0].set_title(f'{col} Distribution', fontweight='bold')\n",
    "        axes[0].set_xlabel(col)\n",
    "        axes[0].set_ylabel('Count')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        if target_col in train.columns:\n",
    "            cat_label = pd.crosstab(train[col], train[target_col], normalize='index') * 100\n",
    "            cat_label.plot(kind='bar', stacked=True, ax=axes[1])\n",
    "            axes[1].set_title(f'Trip Label Distribution by {col} (%)', fontweight='bold')\n",
    "            axes[1].set_xlabel(col)\n",
    "            axes[1].set_ylabel('Percentage')\n",
    "            axes[1].tick_params(axis='x', rotation=45)\n",
    "            axes[1].legend(title='Trip Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef5b9c",
   "metadata": {},
   "source": [
    "## 7. Device and Environment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_env_cols = ['Device_FP', 'Car_Model', 'Weather', 'Traffic', 'Battery_Level', 'Signal_Strength']\n",
    "\n",
    "available_device_env = [col for col in device_env_cols if col in train.columns]\n",
    "\n",
    "if available_device_env:\n",
    "    print(\"Device and Environment Features Summary:\")\n",
    "    for col in available_device_env:\n",
    "        if train[col].dtype in ['float64', 'int64']:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Mean: {train[col].mean():.2f}\")\n",
    "            print(f\"  Median: {train[col].median():.2f}\")\n",
    "            print(f\"  Min: {train[col].min():.2f}\")\n",
    "            print(f\"  Max: {train[col].max():.2f}\")\n",
    "        else:\n",
    "            print(f\"\\n{col}: {train[col].nunique()} unique values\")\n",
    "            if train[col].nunique() < 20:\n",
    "                print(train[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_device = ['Weather', 'Traffic', 'Signal_Strength', 'Car_Model']\n",
    "\n",
    "for col in categorical_device:\n",
    "    if col in train.columns and train[col].nunique() < 50:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        top_values = train[col].value_counts().head(15)\n",
    "        top_values.plot(kind='barh', ax=axes[0], color='purple')\n",
    "        axes[0].set_title(f'{col} Distribution (Top 15)', fontweight='bold')\n",
    "        axes[0].set_xlabel('Count')\n",
    "        axes[0].invert_yaxis()\n",
    "        \n",
    "        if target_col in train.columns:\n",
    "            top_cats = train[col].value_counts().head(10).index\n",
    "            filtered_data = train[train[col].isin(top_cats)]\n",
    "            cat_label = pd.crosstab(filtered_data[col], filtered_data[target_col], normalize='index') * 100\n",
    "            cat_label.plot(kind='barh', stacked=True, ax=axes[1])\n",
    "            axes[1].set_title(f'Trip Label Distribution by {col} (%) - Top 10', fontweight='bold')\n",
    "            axes[1].set_xlabel('Percentage')\n",
    "            axes[1].invert_yaxis()\n",
    "            axes[1].legend(title='Trip Label', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe84ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Battery_Level' in train.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    train['Battery_Level'].hist(bins=30, ax=axes[0], edgecolor='black', color='green')\n",
    "    axes[0].set_title('Battery Level Distribution', fontweight='bold')\n",
    "    axes[0].set_xlabel('Battery Level (%)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    \n",
    "    if target_col in train.columns:\n",
    "        train.boxplot(column='Battery_Level', by=target_col, ax=axes[1])\n",
    "        axes[1].set_title('Battery Level by Trip Label', fontweight='bold')\n",
    "        axes[1].set_xlabel('Trip Label')\n",
    "        axes[1].set_ylabel('Battery Level (%)')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        plt.suptitle('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8748d",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "if 'Trip_ID' in numeric_cols:\n",
    "    numeric_cols.remove('Trip_ID')\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "if numeric_cols:\n",
    "    correlation_matrix = train[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Correlation Matrix of Numeric Features', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nHighly Correlated Feature Pairs (|correlation| > 0.7):\")\n",
    "    high_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr.append([\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j]\n",
    "                ])\n",
    "    \n",
    "    if high_corr:\n",
    "        high_corr_df = pd.DataFrame(high_corr, columns=['Feature 1', 'Feature 2', 'Correlation'])\n",
    "        print(high_corr_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No highly correlated feature pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c3a2a",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Initial Assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if target_col in train.columns:\n",
    "    analysis_df = train.copy()\n",
    "    \n",
    "    label_encoders = {}\n",
    "    categorical_cols = analysis_df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if 'Trip_ID' in categorical_cols:\n",
    "        categorical_cols.remove('Trip_ID')\n",
    "    if target_col in categorical_cols:\n",
    "        categorical_cols.remove(target_col)\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        analysis_df[col] = le.fit_transform(analysis_df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    feature_cols = [col for col in analysis_df.columns if col not in ['Trip_ID', target_col, \n",
    "                                                                       'Timestamp', 'Timestamp_parsed',\n",
    "                                                                       'DayName']]\n",
    "    \n",
    "    X = analysis_df[feature_cols].fillna(-999)\n",
    "    y = analysis_df[target_col]\n",
    "    \n",
    "    le_target = LabelEncoder()\n",
    "    y_encoded = le_target.fit_transform(y)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10)\n",
    "    rf_model.fit(X, y_encoded)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features (Random Forest):\")\n",
    "    print(feature_importance.head(20).to_string(index=False))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 20 Feature Importances (Random Forest)', fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e922a",
   "metadata": {},
   "source": [
    "## 10. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return len(outliers), (len(outliers) / len(df)) * 100\n",
    "\n",
    "numeric_features = train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "if 'Trip_ID' in numeric_features:\n",
    "    numeric_features.remove('Trip_ID')\n",
    "\n",
    "outlier_summary = []\n",
    "for col in numeric_features:\n",
    "    count, pct = detect_outliers_iqr(train, col)\n",
    "    outlier_summary.append({\n",
    "        'Feature': col,\n",
    "        'Outlier_Count': count,\n",
    "        'Outlier_Percentage': round(pct, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Outlier_Percentage', ascending=False)\n",
    "\n",
    "print(\"\\nOutlier Analysis (IQR Method):\")\n",
    "print(outlier_df.head(15).to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_outliers = outlier_df.head(15)\n",
    "plt.barh(range(len(top_outliers)), top_outliers['Outlier_Percentage'])\n",
    "plt.yticks(range(len(top_outliers)), top_outliers['Feature'])\n",
    "plt.xlabel('Outlier Percentage (%)')\n",
    "plt.title('Top 15 Features with Outliers', fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1df69",
   "metadata": {},
   "source": [
    "## 11. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. Dataset Size:\")\n",
    "print(f\"   Training samples: {len(train):,}\")\n",
    "print(f\"   Test samples: {len(test):,}\")\n",
    "print(f\"   Total features: {train.shape[1]}\")\n",
    "\n",
    "if target_col in train.columns:\n",
    "    print(f\"\\n2. Target Distribution:\")\n",
    "    for label, count in train[target_col].value_counts().items():\n",
    "        pct = (count / len(train)) * 100\n",
    "        print(f\"   {label}: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\n3. Missing Values:\")\n",
    "if len(missing_train) > 0:\n",
    "    print(f\"   Features with missing values: {len(missing_train)}\")\n",
    "    print(f\"   Total missing cells: {missing_train['Missing_Count'].sum():,}\")\n",
    "else:\n",
    "    print(\"   No missing values in training set\")\n",
    "\n",
    "print(f\"\\n4. Data Types:\")\n",
    "print(f\"   Numeric features: {len(train.select_dtypes(include=['float64', 'int64']).columns)}\")\n",
    "print(f\"   Categorical features: {len(train.select_dtypes(include=['object']).columns)}\")\n",
    "\n",
    "print(f\"\\n5. Cardinality:\")\n",
    "high_card = [col for col in train.select_dtypes(include=['object']).columns \n",
    "             if train[col].nunique() > 50]\n",
    "if high_card:\n",
    "    print(f\"   High cardinality features (>50 unique): {', '.join(high_card)}\")\n",
    "else:\n",
    "    print(\"   No high cardinality features detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9d643",
   "metadata": {},
   "source": [
    "## 12. Key Findings and Recommendations\n",
    "\n",
    "**Key Insights from EDA:**\n",
    "\n",
    "1. **Class Imbalance**: Review target distribution to determine if class weighting or sampling techniques are needed\n",
    "2. **Feature Engineering Opportunities**:\n",
    "   - Haversine distance vs actual distance ratio (Navigation issues detection)\n",
    "   - Price per kilometer (Fraud detection)\n",
    "   - Accelerometer magnitude and extremes (Safety violations)\n",
    "   - Temporal features (hour, day of week, rush hour indicators)\n",
    "   - GPS accuracy thresholds (Navigation issues)\n",
    "\n",
    "3. **Data Quality Considerations**:\n",
    "   - Check for missing values and decide on imputation strategy\n",
    "   - Identify and handle outliers appropriately\n",
    "   - High cardinality features may need encoding strategies\n",
    "\n",
    "4. **Modeling Strategy**:\n",
    "   - Use Stratified K-Fold for cross-validation\n",
    "   - Consider class weights in tree-based models\n",
    "   - Gradient Boosted Trees (CatBoost, LightGBM, XGBoost) recommended\n",
    "   - Threshold optimization for Macro F1-Score\n",
    "\n",
    "5. **Feature Selection**:\n",
    "   - Focus on top features identified by Random Forest\n",
    "   - Consider feature interactions (e.g., surge multiplier with time features)\n",
    "   - Sensor extremes (max, min, variance) for safety violations"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15270944,
     "sourceId": 127383,
     "sourceType": "competition"
    },
    {
     "datasetId": 9230974,
     "sourceId": 14452162,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
